[
{
	"uri": "http://localhost:1313/workshop-template/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập ⚠️ Lưu ý: Thông tin dưới đây chỉ dành cho mục đích tham khảo. Vui lòng không sao chép nguyên văn cho báo cáo của bạn, bao gồm cả cảnh báo này.\nThông tin sinh viên: Họ và tên: Quách Nguyễn Chí Hùng\nSố điện thoại: 076551890\nEmail: bacon3632@gmail.com\nTrường: Đại học FPT\nNgành: Công nghệ thông tin\nLớp: AWS082025\nCông ty thực tập: Amazon Web Services Vietnam Co., Ltd.\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 08/09/2025 đến ngày 12/09/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": "Các mô hình OpenAI open-weight hiện đã có trên AWS Vào ngày 5 tháng 8 năm 2025, AWS đã công bố hai mô hình open-weight mới nhất của OpenAI — gpt-oss-120b và gpt-oss-20b — hiện đã có thể truy cập thông qua Amazon Bedrock và Amazon SageMaker JumpStart. Đây là một cột mốc quan trọng, vì đây là lần đầu tiên OpenAI cung cấp quyền truy cập công khai vào trọng số mô hình kể từ GPT-2, mở ra nhiều cơ hội tùy chỉnh và linh hoạt hơn.\nChuyên môn hóa nhiệm vụ Các mô hình open-weight mới của OpenAI được thiết kế cho các trường hợp sử dụng cụ thể. Chúng vượt trội trong các nhiệm vụ lập trình, phân tích dữ liệu khoa học và lý luận toán học, rất phù hợp cho các ngành và nhóm cần khả năng giải quyết vấn đề kỹ thuật nâng cao.\nNgữ cảnh mở rộng Cả hai mô hình đều hỗ trợ cửa sổ ngữ cảnh mở rộng lên đến 128.000 token. Điều này cho phép chúng xử lý các tài liệu, cuộc trò chuyện hoặc mã nguồn rất dài trong một lần chạy. Đối với các ứng dụng như phân tích pháp lý, bài nghiên cứu hoặc hội thoại kéo dài, kích thước ngữ cảnh lớn này mang lại lợi thế rõ rệt.\nTùy chọn triển khai AWS cung cấp hai cách chính để triển khai các mô hình này. Với Amazon Bedrock, khách hàng có thể truy cập mô hình như một dịch vụ được quản lý hoàn toàn, không cần lo về hạ tầng. Ngược lại, SageMaker JumpStart cho phép kiểm soát sâu hơn, hỗ trợ khám phá, triển khai và tinh chỉnh thông qua SageMaker Studio hoặc Python SDK. Cách tiếp cận kép này đáp ứng cả sự tiện lợi và tính linh hoạt tùy theo nhu cầu người dùng.\nKiểm soát bảo mật Bảo mật là trọng tâm trong các dịch vụ của AWS. Khách hàng có thể triển khai mô hình trong VPC riêng, đảm bảo cách ly dữ liệu và bảo vệ mạnh mẽ hơn. AWS cũng cung cấp Guardrails để giúp tổ chức sử dụng AI một cách có trách nhiệm bằng cách lọc đầu ra, áp dụng quy tắc tuân thủ và ngăn chặn phản hồi gây hại. Các kiểm soát tích hợp này giúp doanh nghiệp yên tâm hơn khi triển khai mô hình open-weight.\nHiệu năng theo công bố Theo AWS, mô hình gpt-oss-120b mang lại hiệu quả vượt trội khi chạy trên Bedrock. Công ty cho biết nó tiết kiệm chi phí gấp 3 lần Gemini, gấp 5 lần DeepSeek-R1 và gấp 2 lần so với o4 của chính OpenAI. Dù các chỉ số này rất ấn tượng, chúng dựa trên thử nghiệm nội bộ của AWS. Như mọi tuyên bố tiếp thị, các tổ chức nên tự kiểm chứng hiệu năng với khối lượng công việc thực tế trước khi tin tưởng hoàn toàn.\nMinh bạch với Chain-of-Thought Một tính năng nổi bật khác là khả năng xuất chuỗi suy luận (chain-of-thought). Tính năng này cho phép người dùng xem quá trình suy luận từng bước phía sau phản hồi của mô hình. Với các ứng dụng cần giải thích hoặc xác minh, đây là công cụ hữu ích. Tuy nhiên, trên thực tế, đầu ra dạng này có thể làm tăng độ phức tạp và không phải lúc nào cũng phù hợp với môi trường sản xuất.\nHạn chế và lưu ý Dù tiềm năng lớn, các mô hình này vẫn có hạn chế. Khi ra mắt, chúng chỉ có ở một số khu vực AWS: US West (Oregon) cho Bedrock, và US East (Ohio, Virginia) cùng Châu Á (Mumbai, Tokyo) cho SageMaker JumpStart. Việc giới hạn này có thể làm chậm quá trình áp dụng với các tổ chức ở khu vực khác.\nNgoài ra, dù open weights cho phép tùy chỉnh và tinh chỉnh sâu, nó cũng chuyển trách nhiệm sang người dùng. Doanh nghiệp cần đảm bảo biện pháp an toàn, quản lý yêu cầu tuân thủ và phòng tránh lạm dụng. Nói ngắn gọn, sự mở của mô hình mang lại tự do nhưng cũng đòi hỏi trách nhiệm.\nKết luận Việc ra mắt gpt-oss-120b và gpt-oss-20b của OpenAI trên AWS là bước tiến lớn trong việc phổ cập AI. Bằng cách kết hợp khả năng lý luận nâng cao, xử lý ngữ cảnh mở rộng và tùy chỉnh open-weight với sự tiện lợi của Bedrock và tính linh hoạt của SageMaker, AWS đang khẳng định vị thế là nền tảng mạnh mẽ cho đổi mới AI.\nTuy nhiên, khách hàng nên thận trọng. Giới hạn khu vực, các tuyên bố hiệu năng mang tính tiếp thị, và trách nhiệm quản lý open weights đều cần được cân nhắc kỹ. Nếu được kiểm chứng và quản trị đúng cách, các mô hình này có thể trở thành tài sản giá trị cho tổ chức muốn có tính minh bạch và kiểm soát trong hệ thống AI của mình.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nOpenSecrets sử dụng AWS để chuyển đổi minh bạch chính trị thông qua nâng cao đối sánh dữ liệu OpenSecrets là một tổ chức phi lợi nhuận độc lập, phi đảng phái với sứ mệnh trở thành nguồn thông tin đáng tin cậy về dòng tiền trong chính trị Mỹ. Tổ chức này thực hiện sứ mệnh bằng cách cung cấp dữ liệu, phân tích và công cụ toàn diện, đáng tin cậy cho các nhà hoạch định chính sách, nhà báo và công dân. Tầm nhìn của họ là người dân Mỹ sẽ sử dụng dữ liệu về tài chính chính trị để xây dựng một nền dân chủ sôi động, đại diện và phản hồi tốt hơn.\nThông qua AWS Imagine Grant—một chương trình tài trợ công khai cung cấp cả tiền mặt và tín dụng Amazon Web Services (AWS) cho các tổ chức phi lợi nhuận đăng ký sử dụng công nghệ đám mây để thúc đẩy sứ mệnh—OpenSecrets đã bắt đầu một dự án đầy tham vọng nhằm cách mạng hóa cơ sở dữ liệu đóng góp chính trị của mình. Dự án tập trung vào việc nâng cao độ chính xác và hiệu quả trong việc đối chiếu nhà tài trợ thông qua các kỹ thuật xử lý dữ liệu tiên tiến. Hệ thống cải tiến này giúp nhiều công dân và tổ chức hơn có thể giám sát hệ thống chính trị bằng cách làm cho dữ liệu tài chính chính trị chính xác và dễ tiếp cận hơn bao giờ hết.\nVật lộn với dữ liệu chính trị không nhất quán Dữ liệu đóng góp chính trị đến từ nhiều nguồn với các định dạng, quy ước đặt tên và tiêu chuẩn chất lượng khác nhau. Điều này tạo ra thách thức lớn cho các nhà nghiên cứu, nhà báo và công dân khi cố gắng theo dõi dòng tiền trong chính trị một cách chính xác.\nĐộ phức tạp của dữ liệu tài chính chính trị Thách thức bắt đầu từ sự đa dạng của các nguồn dữ liệu. Hồ sơ của Ủy ban Bầu cử Liên bang (FEC) có nhiều định dạng khác nhau, các ủy ban bầu cử bang lại có tiêu chuẩn báo cáo riêng, và các biểu mẫu công bố vận động hành lang lại theo quy ước khác. Một cá nhân có thể được liệt kê là \u0026ldquo;John Smith\u0026rdquo;, \u0026ldquo;J. Smith\u0026rdquo;, \u0026ldquo;John A. Smith\u0026rdquo; hoặc \u0026ldquo;Smith, John\u0026rdquo; ở các hồ sơ khác nhau, khiến việc theo dõi lịch sử đóng góp đầy đủ của họ gần như không thể nếu không có thuật toán đối chiếu tinh vi.\nCác thực thể doanh nghiệp còn là thách thức lớn hơn. Một công ty có thể xuất hiện trong hồ sơ dưới tên pháp lý đầy đủ, tên thương mại phổ biến, tên các công ty con khác nhau hoặc thậm chí qua các ủy ban hành động chính trị (PAC) khác nhau. Ví dụ, một công ty công nghệ có thể đóng góp dưới tên \u0026ldquo;ABC Corp\u0026rdquo;, \u0026ldquo;ABC Corporation\u0026rdquo;, \u0026ldquo;ABC Technology Solutions\u0026rdquo; hoặc \u0026ldquo;ABC PAC\u0026rdquo;, khiến việc tổng hợp ảnh hưởng thực sự của doanh nghiệp trở nên khó khăn.\nQuy trình thủ công đến giới hạn Nhóm OpenSecrets đã phải dành quá nhiều thời gian để làm sạch và đối chiếu dữ liệu thay vì phân tích để rút ra ý nghĩa. Nhân viên phải xem xét thủ công các trường hợp trùng khớp tiềm năng, đối chiếu tên giữa các cơ sở dữ liệu và xác minh danh tính qua hồ sơ công khai—một quy trình có thể mất hàng giờ với các trường hợp phức tạp liên quan đến tên phổ biến hoặc doanh nghiệp lớn.\nQuy trình thủ công này không chỉ tốn thời gian mà còn dễ xảy ra lỗi con người—có thể làm sai lệch độ chính xác của dữ liệu tổ chức. Một nhà tài trợ bị xác định nhầm có thể làm lệch phân tích các mẫu đóng góp, trong khi các kết nối bị bỏ sót giữa các thực thể có thể che giấu các mối quan hệ quan trọng trong mạng lưới tài chính chính trị.\nThách thức càng trở nên cấp bách vì dữ liệu tài chính chính trị tăng theo cấp số nhân trong các kỳ bầu cử. Ví dụ, trong kỳ bầu cử 2024, OpenSecrets đã xử lý hơn 500 triệu hồ sơ đóng góp, so với khoảng 200 triệu trong các năm không bầu cử. Xử lý thủ công ngày càng không bền vững khi cả khối lượng và tốc độ dữ liệu đầu vào tiếp tục tăng nhanh.\nTầm quan trọng của độ chính xác dữ liệu Nếu không có giải pháp tự động hóa, OpenSecrets có nguy cơ tụt lại phía sau trong sứ mệnh cung cấp thông tin kịp thời, chính xác về tài trợ chiến dịch và hoạt động vận động hành lang. Dữ liệu không chính xác hoặc không đầy đủ có thể khiến nhà báo viết bài điều tra bị sai lệch, nhà nghiên cứu học thuật bị nhầm lẫn hoặc công dân không hiểu rõ nguồn tài trợ của đại diện mình.\nTổ chức cần một hệ thống có thể xử lý hàng trăm triệu bản ghi trong khi vẫn duy trì các tiêu chuẩn chính xác cao cần thiết cho công việc minh bạch chính trị. Kết quả dương tính giả trong đối chiếu nhà tài trợ có thể gán nhầm đóng góp, trong khi kết quả âm tính giả có thể che giấu các mẫu ảnh hưởng chính trị quan trọng—cả hai đều làm suy yếu uy tín và sứ mệnh của tổ chức.\nXây dựng giải pháp đối chiếu dữ liệu có khả năng mở rộng Ban đầu OpenSecrets đề xuất sử dụng machine learning để nhận diện thực thể, nhưng khi dự án tiến triển, nhóm đã chuyển sang phương pháp quy tắc xác định phù hợp hơn với nhu cầu cụ thể. Họ quyết định sử dụng Snowflake trên AWS để xử lý dữ liệu và Elasticsearch trên AWS để đối chiếu và chấm điểm thực thể.\nTừ machine learning đến đối chiếu xác định Cách tiếp cận machine learning ban đầu, dù tiên tiến về mặt kỹ thuật, lại gặp nhiều thách thức với trường hợp sử dụng cụ thể của OpenSecrets. Thuật toán hộp đen khiến nhân viên khó hiểu lý do tại sao một số đối chiếu được thực hiện, gây ra vấn đề về niềm tin khi giải thích phương pháp cho các nhà nghiên cứu và nhà báo bên ngoài. Ngoài ra, yêu cầu dữ liệu huấn luyện cho mô hình ML là rất lớn, và tổ chức cần kết quả có thể kiểm toán và giải thích để duy trì uy tín trong công việc minh bạch chính trị.\nViệc chuyển sang phương pháp quy tắc xác định mang lại nhiều lợi ích chính:\nMinh bạch: Mỗi quyết định đối chiếu đều có thể truy vết về quy tắc và tiêu chí chấm điểm cụ thể Giải thích được: Nhân viên có thể giải thích cho người dùng bên ngoài chính xác cách đối chiếu được xác định Linh hoạt: Quy tắc có thể điều chỉnh dựa trên chuyên môn mà không cần huấn luyện lại mô hình Tốc độ: Thuật toán xác định xử lý bản ghi nhanh hơn so với suy luận ML phức tạp Kiến trúc kỹ thuật và dịch vụ AWS Việc vận hành cả Snowflake và Elasticsearch trên AWS cung cấp cho OpenSecrets khả năng mở rộng, tốc độ và hạ tầng tập trung cần thiết để xử lý bộ dữ liệu khổng lồ. Kiến trúc này tận dụng nhiều dịch vụ AWS chủ chốt:\nAmazon EC2 cung cấp tài nguyên tính toán cho các cụm Elasticsearch, phục vụ nhu cầu tìm kiếm và đối chiếu thời gian thực. Nhóm đã cấu hình auto-scaling để xử lý khối lượng công việc biến động trong các đợt cao điểm, như khi đến hạn nộp hồ sơ FEC với hàng nghìn bản ghi mới đồng thời đổ về.\nAmazon S3 là kho dữ liệu chính, lưu trữ file đóng góp thô, bộ dữ liệu đã xử lý và bản sao lưu dữ liệu lịch sử. Nhóm đã triển khai chính sách vòng đời để tự động chuyển dữ liệu cũ sang lớp lưu trữ rẻ hơn mà vẫn đảm bảo truy cập cho phân tích lịch sử.\nAWS Lambda xử lý các tác vụ tiền xử lý dữ liệu, làm sạch file đầu vào và chuẩn hóa định dạng trước khi vào pipeline chính. Cách tiếp cận serverless này cho phép nhóm xử lý luồng dữ liệu đến mà không cần duy trì hạ tầng chuyên dụng.\nAmazon RDS cung cấp dịch vụ cơ sở dữ liệu quan hệ để lưu trữ kết quả đã xử lý và duy trì bảng tham chiếu chuẩn hóa tên và mối quan hệ thực thể.\nChi tiết triển khai Elasticsearch Elasticsearch là trung tâm của hệ thống đối chiếu. Nhóm đã xây dựng chiến lược lập chỉ mục tinh vi cho phép đối chiếu mờ trên nhiều trường cùng lúc. Các tính năng chính gồm:\nĐối chiếu ngữ âm sử dụng thuật toán Soundex và Metaphone để phát hiện các biến thể tên như \u0026ldquo;Smith\u0026rdquo; và \u0026ldquo;Smyth\u0026rdquo; hoặc \u0026ldquo;Catherine\u0026rdquo; và \u0026ldquo;Katherine\u0026rdquo;.\nChấm điểm chuẩn hóa giúp đánh giá các loại đối chiếu dựa trên độ tin cậy. Đối chiếu số an sinh xã hội chính xác được chấm điểm cao nhất, trong khi đối chiếu tên mờ được chấm điểm dựa trên độ hiếm của tên và chất lượng thông tin hỗ trợ.\nCụm địa lý tăng độ tin cậy khi nhà tài trợ có cùng địa chỉ, mã ZIP hoặc thông tin nơi làm việc, giúp phân biệt các cá nhân trùng tên.\nQuy trình xử lý dữ liệu Hạ tầng AWS cho phép nhóm nghiên cứu và kỹ thuật xử lý hàng trăm triệu bản ghi hiệu quả, đồng thời linh hoạt điều chỉnh phương pháp khi hiểu rõ hơn về thách thức dữ liệu. Quy trình đầy đủ gồm các giai đoạn:\nNạp dữ liệu: File thô tải lên S3 kích hoạt Lambda để xử lý ban đầu Chuẩn hóa: Tên, địa chỉ, nơi làm việc được chuẩn hóa bằng cơ sở dữ liệu tham chiếu Lập chỉ mục Elasticsearch: Bản ghi đã xử lý được lập chỉ mục với nhiều chiến lược tìm kiếm Thực thi đối chiếu: Chạy batch đối chiếu trên toàn bộ dữ liệu Chấm điểm và xếp hạng: Đối chiếu tiềm năng được chấm điểm và xếp hạng theo độ tin cậy Hàng đợi kiểm tra thủ công: Đối chiếu độ tin cậy thấp được gắn cờ để xác minh thủ công Lưu kết quả: Đối chiếu xác nhận được lưu vào RDS để phân tích tiếp Cách tiếp cận này mang lại nhiều lợi thế so với đề xuất machine learning ban đầu: chu kỳ phát triển nhanh hơn, logic minh bạch mà nhóm có thể hiểu và giải thích, cùng khả năng chấm điểm và xếp hạng đối chiếu. Hệ thống chấm điểm này cho phép gắn cờ các kết quả không chắc chắn để con người kiểm tra, giúp tự động hóa bổ trợ chứ không thay thế chuyên môn con người.\nTối ưu hiệu năng Nhóm đã triển khai nhiều tối ưu hiệu năng để xử lý quy mô dữ liệu tài chính chính trị:\nXử lý song song phân phối tác vụ đối chiếu lên nhiều node Elasticsearch, rút ngắn thời gian xử lý toàn bộ dữ liệu từ hàng tuần xuống còn vài ngày.\nCập nhật gia tăng cho phép đối chiếu bản ghi mới với dữ liệu hiện có mà không cần xử lý lại toàn bộ, giúp cập nhật gần như thời gian thực trong các kỳ báo cáo cao điểm.\nChiến lược cache lưu trữ kết quả truy vấn phổ biến trong Amazon ElastiCache, giảm thời gian phản hồi cho các truy vấn và dashboard thường dùng.\nChuyển đổi nghiên cứu tài chính chính trị Hệ thống mới đối chiếu hàng trăm triệu bản ghi với độ chính xác cao hơn, tự động hóa việc nhận diện thực thể trong khi gắn cờ các bản ghi có độ tin cậy không đủ cho việc xem xét của con người. Bước nhảy vọt trong xử lý dữ liệu này cải thiện chất lượng của các bộ dữ liệu công khai quan trọng, cho phép các nhà nghiên cứu tập trung vào phân tích thay vì làm sạch dữ liệu, và mở ra những hiểu biết sâu sắc hơn về tài trợ chiến dịch và vận động hành lang ở cả cấp liên bang và tiểu bang.\nCải thiện có thể đo lường được về chất lượng dữ liệu Sự chuyển mình này mang lại những cải tiến có thể đo lường được trên nhiều khía cạnh của chất lượng dữ liệu:\nĐộ chính xác của các phép đối chiếu tăng 85% so với quy trình thủ công trước đây, với tỷ lệ sai sót giảm xuống dưới 2%. Sự cải thiện này đặc biệt rõ rệt đối với các thực thể doanh nghiệp, nơi hệ thống thành công trong việc xác định các mối quan hệ giữa công ty mẹ và các chi nhánh, cũng như các kết nối PAC mà trước đây phải mất hàng giờ nghiên cứu thủ công.\nThời gian xử lý giảm 95%, với việc làm mới toàn bộ dữ liệu hiện nay chỉ mất vài ngày thay vì vài tháng. Trong các kỳ bầu cử cao điểm, hệ thống có thể xử lý hơn 100.000 hồ sơ đóng góp mới mỗi ngày, so với khả năng trước đây chỉ khoảng 5.000 hồ sơ mỗi ngày qua các quy trình thủ công.\nĐộ bao phủ tăng 40%, khi hệ thống tự động phát hiện các kết nối tinh vi mà các nhà đánh giá thủ công có thể bỏ lỡ do mệt mỏi hoặc hạn chế về thời gian. Điều này bao gồm việc phát hiện các mối quan hệ giữa các nhà tài trợ sử dụng các biến thể tên khác nhau qua nhiều chu kỳ bầu cử hoặc loại hình đóng góp.\nNâng cao khả năng phân tích Chất lượng dữ liệu được cải thiện đã mở ra những khả năng phân tích mới mà trước đây không thể thực hiện được do dữ liệu không nhất quán:\nTheo dõi nhà tài trợ theo thời gian hiện cho phép các nhà nghiên cứu theo dõi các mẫu đóng góp chính trị của từng nhà tài trợ qua nhiều chu kỳ bầu cử, tiết lộ các xu hướng trong sự tham gia và thay đổi liên minh chính trị. Khả năng này đã cho phép một số nghiên cứu đột phá về hành vi của nhà tài trợ và sự phân cực chính trị.\nPhân tích mạng lưới doanh nghiệp có thể vẽ ra các mối quan hệ phức tạp giữa công ty mẹ, các chi nhánh và các PAC liên quan, cung cấp bức tranh đầy đủ hơn về ảnh hưởng chính trị của doanh nghiệp. Hệ thống có thể tự động xác định khi một thực thể doanh nghiệp duy nhất đang đóng góp qua nhiều kênh, giúp các nhà báo và nhà nghiên cứu hiểu rõ hơn về quy mô thực sự của sự tham gia chính trị của doanh nghiệp.\nPhân tích cụm địa lý tiết lộ các mẫu vùng miền trong việc đóng góp chính trị, giúp các nhà nghiên cứu hiểu cách mà điều kiện kinh tế địa phương, sự hiện diện của ngành công nghiệp và các yếu tố nhân khẩu học ảnh hưởng đến các đóng góp chính trị. Điều này đặc biệt có giá trị cho các nghiên cứu về giao điểm giữa quyền lực kinh tế và chính trị.\nTác động đến quy trình làm việc của các bên liên quan Chất lượng dữ liệu được nâng cao cho phép các nhà báo viết những câu chuyện chính xác hơn với độ sâu và sắc thái lớn hơn. Các phóng viên hiện có thể nhanh chóng xác định tất cả các đóng góp từ một cá nhân hoặc mạng lưới doanh nghiệp mà không phải mất hàng ngày cho nghiên cứu thủ công. Một số cuộc điều tra đã giành giải Pulitzer đã tận dụng dữ liệu OpenSecrets được cải thiện để phơi bày các mẫu ảnh hưởng chính trị trước đây bị ẩn giấu.\nCác nhà nghiên cứu tiến hành các nghiên cứu đáng tin cậy với kích thước mẫu lớn hơn và độ tin cậy cao hơn trong các phát hiện của họ. Các tổ chức học thuật đã báo cáo rằng các nghiên cứu sử dụng dữ liệu OpenSecrets hiện tốn ít thời gian hơn cho việc chuẩn bị dữ liệu, cho phép nhiều nguồn lực hơn được dành cho phân tích và diễn giải.\nCông dân đưa ra quyết định thông minh hơn về các ứng cử viên chính trị thông qua thông tin toàn diện và dễ tiếp cận hơn. Dữ liệu được cải thiện cung cấp năng lượng cho các công cụ thân thiện với người dùng trên trang web OpenSecrets, bao gồm bản đồ nhà tài trợ tương tác, dòng thời gian đóng góp và hình ảnh mạng lưới ảnh hưởng giúp dữ liệu tài chính chính trị phức tạp trở nên dễ hiểu với công chúng.\nMở rộng cho sự tăng trưởng trong tương lai Sự chuyển mình của OpenSecrets hỗ trợ nền dân chủ thông qua tăng cường minh bạch, trong khi khả năng mở rộng của hệ thống đáp ứng nhu cầu ngày càng tăng về các công cụ minh bạch chính trị khi nó tiếp tục mở rộng cho các nguồn dữ liệu mới. Hạ tầng AWS có thể dễ dàng tiếp nhận:\nTích hợp dữ liệu tiểu bang và địa phương: Hệ thống hiện đang xử lý dữ liệu tài chính chiến dịch từ 15 tiểu bang bổ sung, với kế hoạch mở rộng ra tất cả 50 tiểu bang trong vòng hai năm tới. Mỗi nguồn dữ liệu mới chỉ yêu cầu thay đổi tối thiểu về hạ tầng, vì kiến trúc linh hoạt có thể tiếp nhận các định dạng và yêu cầu nộp hồ sơ khác nhau.\nKhả năng xử lý thời gian thực: Trong các chu kỳ bầu cử lớn, hệ thống có thể cung cấp cập nhật gần như thời gian thực khi các hồ sơ mới được nộp cho các ủy ban bầu cử, cho phép các nhà báo báo cáo về các mẫu đóng góp khi chúng phát triển thay vì phải chờ đợi các bản tóm tắt hàng quý.\nTiềm năng mở rộng quốc tế: Ngăn công nghệ cơ sở hạ tầng có thể được điều chỉnh để xử lý dữ liệu tài chính chính trị từ các quốc gia dân chủ khác, hỗ trợ các sáng kiến minh bạch toàn cầu và nghiên cứu chính trị so sánh.\nDân chủ hóa quyền truy cập dữ liệu chính trị Có lẽ quan trọng nhất, sự chuyển mình này đã dân chủ hóa quyền truy cập vào thông tin tài chính chính trị. Trước đây, chỉ có các tổ chức tin tức hoặc các tổ chức học thuật có nguồn lực tốt mới có thể đủ khả năng cho thời gian nhân sự cần thiết để tiến hành nghiên cứu tài chính chính trị toàn diện. Giờ đây, các phương tiện truyền thông nhỏ hơn, các tổ chức dân sự và các nhà nghiên cứu độc lập có thể truy cập dữ liệu chất lượng cao, đã được xử lý thông qua các API và dịch vụ tải xuống hàng loạt của OpenSecrets.\nSự dân chủ hóa này đã dẫn đến một cuộc bùng nổ các sáng kiến minh bạch ở cấp độ địa phương và tiểu bang, khi các tổ chức cộng đồng giờ đây có thể dễ dàng phân tích các mẫu tài trợ chính trị địa phương của họ và buộc các quan chức đắc cử phải chịu trách nhiệm về các nguồn tài trợ của họ.\nBài học cho việc triển khai công nghệ phi lợi nhuận Kinh nghiệm của OpenSecrets cung cấp hướng dẫn quý giá cho các tổ chức phi lợi nhuận khác khi bắt tay vào các dự án chuyển đổi công nghệ. Lời khuyên đầu tiên của nhóm lãnh đạo là hãy linh hoạt, vì kế hoạch ban đầu có thể không phải là con đường tốt nhất khi bạn đã đi sâu vào công việc.\nÔm lấy phát triển lặp đi lặp lại thay vì lập kế hoạch hoàn hảo Sự chuyển mình của OpenSecrets chứng minh giá trị của phương pháp linh hoạt trong các dự án công nghệ phi lợi nhuận. Thay vì dành nhiều tháng để tạo ra các thông số kỹ thuật chi tiết, nhóm đã bắt đầu với cách tiếp cận sản phẩm khả thi tối thiểu (MVP) có thể xử lý một tập hợp con dữ liệu của họ và cung cấp giá trị ngay lập tức.\nJacob Hileman, Giám đốc CNTT của OpenSecrets, giải thích: \u0026ldquo;Chúng tôi đã học được rằng cố gắng giải quyết mọi thứ cùng một lúc thực sự đã làm chậm tiến độ của chúng tôi. Bằng cách tập trung vào việc làm cho một phần hoạt động thật tốt trước tiên, chúng tôi có thể xác thực cách tiếp cận của mình và xây dựng niềm tin với các bên liên quan trước khi giải quyết các thách thức phức tạp hơn.\u0026rdquo;\nCách tiếp cận lặp đi lặp lại này đã cho phép nhóm:\nKiểm tra giả định sớm với dữ liệu thực tế thay vì các kịch bản lý thuyết Xây dựng sự ủng hộ của các bên liên quan bằng cách chứng minh kết quả cụ thể nhanh chóng Xác định các thách thức bất ngờ trước khi chúng trở thành rào cản lớn Thích ứng với các yêu cầu thay đổi khi nhu cầu của tổ chức tiến triển trong suốt dự án Ưu tiên khả năng giải thích hơn là sự tinh vi Nhóm OpenSecrets cũng nhấn mạnh tầm quan trọng của việc xây dựng với người dùng trong tâm trí. Nhóm cần logic đối chiếu rõ ràng, có thể giải thích được, chứ không phải một giải pháp hộp đen. Cách tiếp cận tập trung vào người dùng này đã dẫn đến sự phát triển của một hệ thống cuối cùng có thể được tin cậy và sử dụng hiệu quả bởi nhân viên OpenSecrets và các đối tác bên ngoài.\nXây dựng niềm tin là rất quan trọng vì uy tín của OpenSecrets phụ thuộc vào độ chính xác và minh bạch của dữ liệu. Các thành viên trong nhóm cần hiểu cách mà các phép đối chiếu được thực hiện để họ có thể giải thích phương pháp cho các nhà báo, nhà nghiên cứu và công chúng. Người dùng bên ngoài cần có niềm tin rằng các thuật toán cơ bản là hợp lý và không có thiên lệch.\nQuyết định từ bỏ machine learning để chuyển sang đối chiếu dựa trên quy tắc là ví dụ điển hình cho nguyên tắc này. Trong khi các phương pháp ML có thể đạt được độ chính xác cao hơn một chút trong một số trường hợp, hệ thống xác định cung cấp:\nKhả năng kiểm toán hoàn toàn của mọi quyết định đối chiếu Tham số có thể điều chỉnh mà các chuyên gia trong lĩnh vực có thể tinh chỉnh Kết quả có thể giải thích có thể được bảo vệ trong các diễn đàn công khai Quy trình có thể tái tạo mà các nhà nghiên cứu bên ngoài có thể xác minh Tận dụng hạ tầng đám mây để linh hoạt Có lẽ quan trọng nhất, OpenSecrets đã học được không nên chờ đợi sự hoàn hảo. Nhóm khuyên rằng hãy ra mắt, học hỏi và tinh chỉnh theo chu kỳ. Việc chạy mọi thứ trên AWS đã giúp họ dễ dàng xoay chuyển nhanh chóng mà không cần phải thiết kế lại toàn bộ hệ thống, cho phép họ điều chỉnh cách tiếp cận dựa trên thử nghiệm và phản hồi từ thực tế.\nKiến trúc ưu tiên đám mây đã chứng minh là rất cần thiết để quản lý sự không chắc chắn trong phạm vi dự án. Khi nhóm tìm hiểu thêm về các thách thức dữ liệu của mình, họ có thể:\nTăng hoặc giảm quy mô tài nguyên dựa trên nhu cầu xử lý mà không cần đầu tư vốn Thử nghiệm với các dịch vụ khác nhau (Elasticsearch, các động cơ cơ sở dữ liệu khác nhau, v.v.) mà không cần cam kết về hạ tầng Triển khai cập nhật nhanh chóng thông qua các pipeline CI/CD tự động Cuộn lại các thay đổi nhanh chóng nếu các phương pháp mới không hoạt động như mong đợi Lập kế hoạch cho quản lý thay đổi và sự chấp nhận của người dùng Một bài học bất ngờ liên quan đến quản lý thay đổi trong tổ chức. Các nhân viên đã dành nhiều năm phát triển chuyên môn trong việc xử lý dữ liệu thủ công ban đầu xem hệ thống tự động với sự hoài nghi. Nhóm đã học được rằng sự chấp nhận của người dùng không chỉ đòi hỏi thành công về mặt kỹ thuật—nó cần sự giao tiếp và đào tạo cẩn thận.\nCác chiến lược áp dụng thành công bao gồm:\nTham gia nhân viên vào phát triển thuật toán bằng cách để họ xác nhận kết quả đối chiếu và đề xuất cải tiến Các buổi đào tạo giúp nhân viên hiểu cách sử dụng các công cụ mới một cách hiệu quả Chuyển đổi dần dần thay vì thay thế đột ngột các quy trình làm việc hiện có Tài liệu rõ ràng giúp nhân viên tự giải quyết các vấn đề một cách độc lập Xây dựng quan hệ đối tác và tận dụng cơ hội tài trợ AWS Imagine Grant không chỉ quan trọng về mặt tài chính, mà còn tạo ra trách nhiệm và xác nhận bên ngoài về tầm quan trọng của dự án. Quy trình nộp đơn xin tài trợ đã buộc nhóm phải làm rõ mục tiêu và chỉ số thành công của họ, trong khi tính công khai của tài trợ tạo ra áp lực tích cực để đạt được kết quả.\nCác tổ chức phi lợi nhuận khác nên xem xét:\nNộp đơn xin nhiều tài trợ để đa dạng hóa nguồn vốn và giảm rủi ro Xây dựng mối quan hệ với các đối tác công nghệ hiểu được những hạn chế của phi lợi nhuận Ghi lại các thành công để hỗ trợ cho các đơn xin tài trợ trong tương lai và truyền cảm hứng cho các tổ chức khác Chia sẻ bài học kinh nghiệm với cộng đồng công nghệ phi lợi nhuận rộng lớn hơn Đo lường tác động vượt ra ngoài các chỉ số kỹ thuật Trong khi các chỉ số kỹ thuật như tốc độ xử lý và độ chính xác là quan trọng, OpenSecrets đã học được cách đo lường tác động sứ mệnh. Thành công thực sự của dự án không chỉ nằm ở công nghệ mà còn ở cách nó giúp tổ chức phục vụ tốt hơn cho nền dân chủ.\nCác chỉ số tác động chính bao gồm:\nTăng cường sự quan tâm của truyền thông sử dụng dữ liệu OpenSecrets trong các câu chuyện điều tra Các ấn phẩm nghiên cứu học thuật tận dụng các bộ dữ liệu được cải thiện Các chỉ số tham gia của công dân thông qua việc sử dụng trang web và việc áp dụng API Các cuộc thảo luận chính sách được thông báo bởi phân tích tài chính chính trị toàn diện hơn Năng lực tổ chức được tự động hóa để tập trung vào công việc có giá trị cao hơn Những điều cần rút ra cho các tổ chức Linh hoạt là rất quan trọng: Hãy chuẩn bị để điều chỉnh kế hoạch ban đầu khi bạn tìm hiểu thêm về thách thức của mình Thiết kế tập trung vào người dùng: Xây dựng các giải pháp mà đội ngũ của bạn có thể hiểu, tin tưởng và sử dụng hiệu quả Cách tiếp cận lặp đi lặp lại: Ra mắt sớm, học hỏi từ việc sử dụng thực tế và tinh chỉnh liên tục Lợi thế hạ tầng đám mây: AWS đã cho phép các bước xoay chuyển nhanh chóng và mở rộng quy mô mà không cần tái kiến trúc lớn Hợp tác giữa con người và AI: Các giải pháp tốt nhất là những giải pháp nâng cao chứ không thay thế chuyên môn con người Hỗ trợ nền dân chủ thông qua công nghệ Nền dân chủ đòi hỏi trách nhiệm chính trị, điều này chỉ có thể đạt được thông qua minh bạch. OpenSecrets hỗ trợ những nguyên tắc cốt lõi của hệ thống chính trị của chúng ta bằng cách cung cấp dữ liệu, phân tích và công cụ toàn diện, đáng tin cậy cho các nhà hoạch định chính sách, nhà báo và công dân. Sự chuyển mình của tổ chức minh họa cách mà công nghệ đám mây có thể khuếch đại tác động của các sứ mệnh phi lợi nhuận, tạo ra thông tin có thể tiếp cận và chính xác hơn cho sự tham gia dân chủ.\nMở rộng hệ sinh thái minh bạch Hệ thống được cải thiện trao quyền cho các nhà nghiên cứu, các nhà báo và công dân cùng nhau hiểu rõ hơn về dòng chảy của tiền bạc trong chính trị, cuối cùng góp phần vào một xã hội dân chủ được thông tin và tham gia nhiều hơn. Nhưng tác động mở rộng ra ngoài từng người dùng—nó đang tạo ra một hiệu ứng mạng lưới củng cố các thể chế dân chủ.\nCác tổ chức học thuật hiện đang đưa dữ liệu OpenSecrets vào phát triển chương trình giảng dạy, dạy cho sinh viên cách phân tích các mẫu tài chính chính trị như một phần của giáo dục về civics và khoa học chính trị. Các trường đại học báo cáo rằng sinh viên hiện có thể thực hiện các dự án nghiên cứu có ý nghĩa sử dụng dữ liệu tài chính chính trị, trong khi trước đây, những dự án như vậy yêu cầu nguồn lực ở cấp độ sau đại học.\nCác tổ chức tin tức đang phát triển cảnh báo tự động thông báo cho các phóng viên khi có các mẫu đóng góp bất thường xuất hiện, cho phép đưa tin kịp thời hơn về các câu chuyện tài chính chính trị. Các phương tiện truyền thông địa phương, đặc biệt, đã hưởng lợi từ khả năng phân tích nhanh chóng các nguồn tài trợ của đại diện của họ mà không cần đội ngũ dữ liệu chuyên dụng.\nCác tổ chức công nghệ dân sự đang xây dựng các ứng dụng hạ nguồn làm cho dữ liệu tài chính chính trị dễ tiếp cận hơn với công chúng. Chúng bao gồm các ứng dụng di động cho phép công dân quét mã QR trên các quảng cáo chính trị để xem nguồn tài trợ, các tiện ích mở rộng trình duyệt thêm thông tin về các bài báo tin tức, và các bot mạng xã hội cung cấp ngữ cảnh về chi tiêu chính trị trong thời gian thực.\nÝ nghĩa toàn cầu cho minh bạch dân chủ Sự thành công của sự chuyển mình của OpenSecrets đã thu hút sự chú ý từ các tổ chức minh bạch quốc tế đang tìm cách cải thiện giám sát tài chính chính trị ở các nền dân chủ khác. Một số quốc gia hiện đang khám phá các cách tiếp cận tương tự để tự động hóa phân tích tài chính chiến dịch, có khả năng tạo ra một mạng lưới toàn cầu của các sáng kiến minh bạch chính trị.\nLiên minh Châu Âu đã bày tỏ sự quan tâm đến việc điều chỉnh phương pháp OpenSecrets cho việc theo dõi tài chính chính trị xuyên biên giới, đặc biệt là trước những lo ngại về ảnh hưởng nước ngoài trong các cuộc bầu cử. Kiến trúc công nghệ mà AWS phát triển có thể mở rộng để xử lý dữ liệu đa quyền tài phán với các ngôn ngữ và khuôn khổ quy định khác nhau.\nCác nền dân chủ mới nổi đặc biệt quan tâm đến cách tiếp cận tiết kiệm chi phí, vì nhiều quốc gia không thể đủ khả năng duy trì các đội ngũ phân tích dữ liệu lớn nhưng cần các công cụ hiệu quả để giám sát sự tuân thủ tài chính chính trị và phát hiện các mẫu tham nhũng.\nCông nghệ như một lực lượng đổi mới dân chủ Sự chuyển mình của OpenSecrets minh họa cách mà các khoản đầu tư công nghệ chiến lược có thể củng cố các thể chế dân chủ vào thời điểm niềm tin vào chính phủ và truyền thông đang suy giảm. Bằng cách làm cho dữ liệu tài chính chính trị dễ tiếp cận và đáng tin cậy hơn, dự án góp phần vào một số xu hướng quan trọng:\nJournalsim dựa trên dữ liệu đang trở nên phổ biến hơn khi các phóng viên có được các công cụ và bộ dữ liệu tốt hơn. Sự chuyển mình này về phía báo cáo dựa trên bằng chứng giúp chống lại thông tin sai lệch và cung cấp cho công dân một nền tảng thông tin vững chắc hơn cho các cuộc thảo luận chính trị.\nKhả năng giám sát của công dân đang mở rộng khi các cá nhân và tổ chức cơ sở nhận được các công cụ trước đây chỉ có sẵn cho các tổ chức có nguồn lực tốt. Sự dân chủ hóa các công cụ giám sát này tạo ra nhiều cơ chế trách nhiệm phân tán hơn.\nNghiên cứu học thuật về tài chính chính trị đang tăng tốc khi các nhà nghiên cứu có thể tập trung vào phân tích thay vì thu thập và làm sạch dữ liệu. Điều này dẫn đến việc hiểu biết tốt hơn về cách mà tiền bạc ảnh hưởng đến kết quả chính trị và nhiều khuyến nghị chính sách dựa trên bằng chứng hơn.\nHướng đi và tính bền vững trong tương lai Nhìn về phía trước, OpenSecrets dự định tận dụng hạ tầng AWS cho một số mở rộng đổi mới:\nPhân tích dự đoán có thể giúp xác định các mẫu đóng góp có thể bất hợp pháp hoặc sự phối hợp giữa các diễn viên chính trị được cho là độc lập. Bằng cách phân tích các mẫu lịch sử, hệ thống có thể đánh dấu các hoạt động bất thường để điều tra của con người.\nCông cụ phân tích mạng sẽ vẽ ra các mối quan hệ phức tạp giữa các nhà tài trợ, ứng cử viên và tổ chức chính trị, tiết lộ các mạng lưới ảnh hưởng có thể không rõ ràng từ các hồ sơ đóng góp cá nhân.\nTích hợp với dữ liệu vận động hành lang sẽ cung cấp bức tranh toàn diện hơn về ảnh hưởng của tổ chức bằng cách kết nối các đóng góp chiến dịch với chi tiêu vận động hành lang và kết quả chính sách.\nGiám sát thời gian thực trong các chu kỳ bầu cử có thể cho phép phát hiện ngay lập tức các vi phạm tài chính chiến dịch hoặc sự phối hợp giữa các ứng cử viên và các nhóm chi tiêu bên ngoài.\nPhong trào công nghệ phi lợi nhuận rộng lớn hơn Sự thành công của OpenSecrets góp phần vào một phong trào ngày càng tăng của đổi mới phi lợi nhuận được hỗ trợ bởi công nghệ. Dự án chứng minh rằng với hạ tầng đám mây thích hợp và các đối tác chiến lược, những tổ chức tương đối nhỏ cũng có thể đạt được những tác động trước đây chỉ yêu cầu nguồn lực lớn hơn nhiều.\nĐiều này có ý nghĩa cho toàn bộ lĩnh vực phi lợi nhuận, gợi ý rằng các khoản đầu tư công nghệ nên được xem không chỉ là những cải tiến vận hành mà còn là những nhân tố nhân rộng sứ mệnh có thể tăng cường tác động tổ chức theo cấp số nhân. Chương trình AWS Imagine Grant và các sáng kiến tương tự đang giúp tạo ra một thế hệ phi lợi nhuận có hiểu biết về công nghệ hơn, có thể tận dụng dữ liệu và tự động hóa để phục vụ cộng đồng hiệu quả hơn.\nThước đo thành công cuối cùng không chỉ nằm ở những thành tựu kỹ thuật, mà còn ở cuộc đối thoại dân chủ được củng cố mà kết quả từ các hệ thống chính trị minh bạch và có trách nhiệm hơn. Bằng cách làm cho dữ liệu tài chính chính trị dễ tiếp cận, chính xác và có thể hành động hơn, OpenSecrets đang góp phần vào một công dân được thông tin tốt hơn và các thể chế dân chủ phản hồi tốt hơn.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nPhân tích vai trò dẫn dắt của AWS trong các báo cáo Gartner Magic Quadrant 2025 Khi tôi phân tích các bài viết gần đây của AWS nêu chi tiết việc họ được ghi nhận trong nhiều báo cáo Gartner Magic Quadrant, tôi tự hỏi điều gì thực sự cấu thành nên vị thế dẫn đầu về đám mây trong bối cảnh công nghệ thay đổi nhanh chóng ngày nay. Theo sát hành trình của AWS trong thập kỷ qua, tôi tin rằng hiệu suất ổn định của họ qua các đợt đánh giá này cho thấy nhiều hơn là vị thế thống trị thị trường—nó thể hiện sự thấu hiểu sâu sắc nhu cầu của doanh nghiệp trên nhiều lĩnh vực. Theo đánh giá của tôi, đạt vị trí “Leader” ở chỉ một Magic Quadrant đã là đáng chú ý, nhưng duy trì vị trí này trên năm hạng mục khác nhau đồng thời đứng cao nhất về “Ability to Execute” (Năng lực thực thi) đối với Strategic Cloud Platform Services trong suốt 15 năm liên tiếp là điều, theo tôi, chưa từng có tiền lệ trong ngành điện toán đám mây. Sự xuất sắc bền bỉ này cho thấy một văn hóa ăn sâu về lấy khách hàng làm trung tâm và đổi mới lan tỏa khắp tổ chức của họ.\nStrategic Cloud Platform Services: 15 năm dẫn đầu không gián đoạn Theo quan điểm của tôi, việc AWS được công nhận là “Leader” trong báo cáo Gartner Magic Quadrant 2025 cho Strategic Cloud Platform Services năm thứ mười lăm liên tiếp đại diện cho điều gì đó vượt xa một thành tựu doanh nghiệp. Tôi xem đó là sự xác tín cho triết lý nền tảng của họ—rằng điện toán đám mây phải đáng tin cậy, có khả năng mở rộng và an toàn theo mặc định. Sau khi đã đánh giá nhiều nền tảng đám mây trong suốt sự nghiệp, tôi đặc biệt ấn tượng với cách AWS duy trì vai trò dẫn dắt qua nhiều lần chuyển dịch mô hình công nghệ, từ thời kỳ máy ảo ban đầu đến kỷ nguyên điện toán không máy chủ (serverless) và AI tạo sinh hiện nay.\nĐiều khiến tôi chú ý nhất là vị trí cao nhất của họ trên trục “Ability to Execute”. Theo trải nghiệm của tôi, nhiều nhà cung cấp giỏi về tầm nhìn nhưng lại chật vật khi thực thi. Sự xuất sắc vận hành bền vững của AWS, theo tôi, bắt nguồn từ việc họ không ngừng tập trung vào nhu cầu khách hàng thay vì theo đuổi công nghệ vì chính công nghệ. Tôi đã quan sát thấy các khoản đầu tư vào silicon tự thiết kế (Graviton, Inferentia, Trainium) của họ trực tiếp giải quyết mối quan tâm thực tế về chi phí và hiệu năng, trong khi việc mở rộng hạ tầng toàn cầu luôn ưu tiên các yêu cầu về độ tin cậy và tuân thủ mà doanh nghiệp thật sự cần.\nKiến trúc giải pháp hiện tại như sau:\nContact Center as a Service: Chuyển đổi trải nghiệm khách hàng Khi xem xét việc AWS được công nhận là “Leader” trong Magic Quadrant cho Contact Center as a Service năm thứ ba liên tiếp, tôi ấn tượng với cách họ chuyển hóa hiệu năng đám mây thành năng lực chuyên biệt trong lĩnh vực dịch vụ khách hàng. Sau khi triển khai các giải pháp contact center cho nhiều tổ chức, tôi đánh giá cao cách Amazon Connect hiện thân triết lý cloud-native—loại bỏ việc quản trị hạ tầng đồng thời cung cấp khả năng mở rộng và linh hoạt vượt trội.\nĐiều đặc biệt khiến tôi ấn tượng là cách AWS tận dụng năng lực AI/ML để nâng cấp Amazon Connect. Theo góc nhìn của tôi, việc tích hợp các dịch vụ như Amazon Lex cho hội thoại AI và Amazon Connect Wisdom để hỗ trợ điện thoại viên cho thấy lợi thế độc đáo của AWS: khả năng đưa các năng lực AI tiên tiến vào những dịch vụ đã thành hình một cách liền mạch. Tôi tin rằng cách tiếp cận này—tăng cường chức năng cốt lõi bằng AI thay vì tách thành một dịch vụ riêng—đại diện cho tương lai phát triển phần mềm doanh nghiệp.\nCloud-Native Application Platforms: Trao quyền đổi mới cho lập trình viên Là người đã làm việc với nhiều nền tảng phát triển ứng dụng, tôi thấy vai trò dẫn dắt của AWS trong Magic Quadrant cho Cloud-Native Application Platforms đặc biệt thuyết phục. Vị trí cao nhất của họ trên trục “Ability to Execute”, theo đánh giá của tôi, phản ánh việc họ thấu hiểu rằng nhà phát triển cần cả những nguyên thủy mạnh mẽ (như AWS Lambda) lẫn các khung quản trị (như AWS Amplify) để xây dựng hiệu quả.\nĐiều tôi đánh giá cao nhất trong cách tiếp cận của AWS là nhận thức rằng không có một khuôn mẫu phù hợp cho tất cả trong phát triển ứng dụng. Chiến lược danh mục của họ—cung cấp mọi thứ từ dịch vụ container đến nền tảng serverless đến lưu trữ ứng dụng quản trị hoàn toàn—cho thấy, theo tôi, một sự thấu hiểu tinh tế về các mô hình phát triển khác nhau và mức độ trưởng thành tổ chức. Tôi đặc biệt ấn tượng với cách họ tích hợp năng lực AI tạo sinh thông qua Amazon Bedrock và Amazon SageMaker, giúp đưa AI tiên tiến vào các quy trình phát triển quen thuộc thay vì trở thành các dịch vụ tách rời.\nContainer Management: Tính linh hoạt và tầm nhìn Sau khi lăn lộn với thế giới điều phối container từ những ngày đầu, tôi cho rằng việc AWS được công nhận là “Leader” trong Magic Quadrant cho Container Management năm thứ ba liên tiếp là rất đáng kể. Vị trí xa nhất của họ trên trục “Completeness of Vision” phù hợp với trải nghiệm của tôi rằng AWS hiểu quản trị container là một phần của câu chuyện phát triển ứng dụng rộng hơn chứ không phải công nghệ cô lập.\nĐiều nổi bật với tôi là cách tiếp cận linh hoạt của AWS đối với quản trị container. Việc họ cung cấp cả Amazon ECS và Amazon EKS, được bổ trợ bởi động cơ tính toán serverless AWS Fargate, thể hiện—theo tôi—một cách tiếp cận lấy khách hàng làm trung tâm, công nhận các ưu tiên tổ chức và đầu tư sẵn có khác nhau. Tôi đặc biệt ấn tượng với năng lực hybrid và edge của họ, vốn thừa nhận rằng các triển khai ngoài đời thực thường trải rộng nhiều môi trường—một mức độ phức tạp mà nhiều nhà cung cấp khác, theo trải nghiệm của tôi, thường đánh giá thấp.\nDesktop as a Service: Không gian làm việc số an toàn Khi đánh giá vai trò dẫn dắt của AWS trong Magic Quadrant cho Desktop as a Service năm thứ hai liên tiếp, tôi ấn tượng với cách họ áp dụng chuyên môn đám mây vào các thách thức đặc thù của ảo hóa desktop. Sau khi triển khai các giải pháp DaaS trong nhiều ngành, tôi đánh giá cao cách Amazon WorkSpaces cân bằng yêu cầu bảo mật với trải nghiệm người dùng và tính linh hoạt.\nĐiều tôi thấy đặc biệt ấn tượng là cách AWS định giá DaaS. Mô hình trả theo mức sử dụng, theo trải nghiệm của tôi, mang lại lợi thế chi phí đáng kể cho các tổ chức có nhu cầu dao động. Ngoài ra, việc tích hợp với các dịch vụ bảo mật rộng hơn của AWS (như AWS IAM và AWS CloudTrail) tạo ra—theo đánh giá của tôi—tư thế bảo mật toàn diện hơn so với các nhà cung cấp DaaS độc lập thường có thể mang lại. Cách tiếp cận tích hợp này minh họa lợi thế then chốt của AWS theo tôi: khả năng tận dụng sức mạnh nền tảng rộng lớn để nâng cao từng dịch vụ riêng lẻ.\nNhững sợi chỉ chung: Cách AWS dẫn dắt đám mây Khi nhìn tổng thể các sự ghi nhận trong Magic Quadrant này, nhiều khuynh hướng nổi lên mà, theo tôi, lý giải việc AWS duy trì vị thế dẫn dắt trên nhiều lĩnh vực. Đầu tiên là sự ám ảnh nhất quán với khách hàng—mỗi đổi mới dường như đều xuất phát từ nhu cầu thực tế thay vì xu hướng công nghệ. Thứ hai là tư duy dài hạn, thể hiện qua các khoản đầu tư như silicon tùy biến, có thể chưa đem lại lợi ích ngay lập tức nhưng tạo ra lợi thế cạnh tranh bền vững.\nĐiều khiến tôi đặc biệt ấn tượng là cách tiếp cận cân bằng với đổi mới của AWS. Họ tiếp tục nâng cấp các dịch vụ hiện hữu đồng thời tiên phong những năng lực mới, duy trì khả năng tương thích ngược trong khi vẫn tiến lên. Cách tiếp cận này, theo trải nghiệm của tôi, mang lại cho doanh nghiệp sự tự tin để xây dựng trên AWS với niềm tin rằng các khoản đầu tư của họ sẽ được bảo vệ theo thời gian.\nHơn nữa, tôi quan sát thấy hạ tầng toàn cầu của AWS cung cấp nền tảng củng cố tất cả dịch vụ của họ. Các năng lực bảo mật, độ tin cậy và tuân thủ được xây dựng sẵn trong các khu vực toàn cầu mang lại lợi ích cho mọi dịch vụ từ tính toán đến container đến contact center, tạo ra các cộng hưởng mà các nhà cung cấp độc lập không thể sánh kịp.\nKết luận: Ý nghĩa của sự xuất sắc bền bỉ Theo đánh giá của tôi, hiệu suất của AWS qua các báo cáo Magic Quadrant này đại diện cho nhiều hơn một thành tựu doanh nghiệp—nó thể hiện năng lực thực thi nhất quán mà doanh nghiệp có thể dựa vào cho những chuyển đổi quan trọng nhất. Chuỗi 15 năm dẫn đầu ở Strategic Cloud Platform Services đặc biệt đáng chú ý, cho thấy sự xuất sắc bền bỉ qua nhiều lần chuyển dịch công nghệ và các bối cảnh cạnh tranh.\nĐiều khiến tôi chú ý nhất là AWS duy trì vị thế dẫn dắt đồng thời mở rộng sang các miền mới. Thay vì an phận với mảng tính toán cốt lõi, họ đã mở rộng năng lực sang các lĩnh vực như contact center, quản trị container và ảo hóa desktop, áp dụng chuyên môn đám mây để giải quyết các thách thức đặc thù theo miền.\nNhìn về tương lai, tôi tin rằng cách tiếp cận AI tích hợp của AWS—nhúng AI vào khắp các dịch vụ thay vì coi đó là một sản phẩm riêng—đặt họ vào vị thế tốt cho kỷ nguyên tiếp theo của điện toán đám mây. Khả năng tận dụng quy mô để đầu tư vào silicon tùy biến và hạ tầng toàn cầu trong khi vẫn giữ tập trung vào sự xuất sắc của từng dịch vụ riêng lẻ tiếp tục gây ấn tượng với tôi và, quan trọng hơn, mang lại giá trị hữu hình cho các doanh nghiệp phụ thuộc vào nền tảng của họ.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/3-blogstranslated/3.4-blog4/",
	"title": "Blog 4",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nAWS Amplify JavaScript Library Công Bố Bundle Nhẹ Hơn và Thời Gian Load Nhanh Hơn Thư Viện Amplify JavaScript Nhanh Hơn, Nhẹ Hơn AWS Amplify đã triển khai những cập nhật quan trọng cho thư viện JavaScript của mình, làm cho nó nhẹ hơn và hiệu quả hơn. Các danh mục chính như Auth, Storage, Notifications và Analytics đã thấy những cải thiện lớn về kích thước bundle, điều này trực tiếp dẫn đến thời gian tải nhanh hơn và hiệu suất tốt hơn cho các developer và người dùng của họ.\nNhững cải thiện này không chỉ là những điều chỉnh kỹ thuật—chúng là kết quả của việc lắng nghe cộng đồng developer Amplify. Bằng cách tập trung vào tối ưu hóa kích thước bundle và hỗ trợ tree-shaking tốt hơn, Amplify đang đảm bảo rằng các ứng dụng được xây dựng bằng thư viện này đáp ứng kỳ vọng hiệu suất hiện đại.\nTại Sao Kích Thước Bundle Lại Quan Trọng Đối với các developer JavaScript, mỗi kilobyte đều quan trọng. Bundle nhỏ hơn có nghĩa là ứng dụng tải nhanh hơn, phản hồi nhanh hơn và mang lại trải nghiệm người dùng tốt hơn. Amplify đã có một cách tiếp cận chiến lược để đáp ứng những nhu cầu này:\nTối Ưu Hóa AWS Service Clients – Các client cốt lõi kết nối với dịch vụ AWS đã được viết lại với tree-shaking trong tâm trí, đảm bảo rằng code không sử dụng được loại bỏ trong quá trình build. Giảm Dependencies – Bằng cách loại bỏ các thư viện bên thứ ba không cần thiết, Amplify đã giảm tổng dung lượng của các package. Tận Dụng Browser APIs – Các tính năng tích hợp như Fetch API hiện được sử dụng rộng rãi hơn, cắt giảm overhead từng làm phình to bundle. Việc kiểm soát sâu hơn toàn bộ stack Amplify cho phép thư viện được điều chỉnh cụ thể cho các framework và build tool phổ biến nhất được sử dụng ngày nay.\nGiảm Kích Thước Có Thể Đo Lường Kết quả của những thay đổi này rất đáng kể:\nAuth: nhỏ hơn 26% Notifications \u0026amp; Analytics: nhỏ hơn 59% Storage: nhỏ hơn 55% Những con số này đại diện cho kích thước bundle cuối cùng đã được minified và gzipped. Các phép đo \u0026ldquo;Trước\u0026rdquo; được lấy từ Amplify JavaScript v5.2.4, trong khi kết quả \u0026ldquo;Sau\u0026rdquo; phản ánh v5.3.4. Cả hai đều được đo bằng size-limit v8.2.6 và webpack 5.88.0 để đảm bảo tính nhất quán.\nNhìn Về Tương Lai: Tương Lai của Amplify JavaScript Trong khi những cải tiến hiện tại đã mang lại lợi ích đáng kể, team Amplify đã đặt ra một lộ trình đầy tham vọng cho tương lai. Các developer có thể mong đợi:\n1. Giảm Kích Thước Bundle Hơn Nữa Tối ưu hóa sẽ không dừng lại ở đây. Công việc bổ sung được lên kế hoạch để cắt giảm kích thước nhiều hơn nữa, đảm bảo ứng dụng tải nhanh nhất có thể trên tất cả thiết bị và mạng.\n2. Trải Nghiệm TypeScript Tốt Hơn Amplify sẽ đầu tư vào việc cải thiện năng suất developer với TypeScript, tập trung vào auto-complete phong phú hơn, hỗ trợ IntelliSense mạnh mẽ hơn trong IDE và trải nghiệm developer mượt mà hơn tổng thể. Đầu vào từ cộng đồng về những thay đổi này đang được thu thập thông qua RFC.\n3. Mở Rộng Hỗ Trợ Server-Side Rendering (SSR) Khi việc áp dụng SSR tăng trưởng trong hệ sinh thái web, Amplify đang chuẩn bị hỗ trợ một bộ framework và tool rộng hơn. Ngoài các tích hợp hiện có, hỗ trợ sắp tới sẽ bao gồm SolidJS, Astro và NuxtJS, mang lại sự linh hoạt hơn cho developer trong việc chọn stack phù hợp.\nĐược Xây Dựng Với Phản Hồi Từ Developer Những cải tiến này—và những cải tiến sắp tới—đều được định hình bởi phản hồi từ cộng đồng Amplify. Bằng cách hợp tác chặt chẽ với các developer, Amplify đang đảm bảo rằng thư viện JavaScript của mình phát triển theo cách cân bằng hiệu suất, khả năng sử dụng và xu hướng phát triển hiện đại.\nNhững cập nhật mới nhất chỉ là khởi đầu. Phiên bản chính tiếp theo của Amplify JavaScript sẽ đẩy những cải tiến này xa hơn nữa, mang lại ứng dụng nhanh hơn, công cụ tốt hơn và trải nghiệm phát triển mượt mà hơn trên toàn bộ.\nWhy Bundle Size Is So Important For JavaScript developers, every kilobyte matters. Smaller bundles mean apps load faster, feel more responsive, and deliver a better user experience. Amplify has taken a strategic approach to meet these needs:\nOptimized AWS Service Clients – The core clients that connect to AWS services were rewritten with tree-shaking in mind, ensuring that unused code is stripped out during builds. Reduced Dependencies – By removing unnecessary third-party libraries, Amplify has lowered the overall footprint of its packages. Leaning on Browser APIs – Built-in features like the Fetch API are now used more extensively, cutting out overhead that used to bloat bundles. This deeper control of the entire Amplify stack allows the library to be tuned specifically for the most common frameworks and build tools used today.\nMeasurable Reductions in Size The results of these changes are significant:\nAuth: 26% smaller Notifications \u0026amp; Analytics: 59% smaller Storage: 55% smaller These numbers represent the final minified and gzipped bundle sizes. The “Before” measurements were taken from Amplify JavaScript v5.2.4, while the “After” results reflect v5.3.4. Both were measured using size-limit v8.2.6 and webpack 5.88.0 for consistency.\nLooking Ahead: The Future of Amplify JavaScript While the current improvements already bring substantial benefits, the Amplify team has laid out an ambitious roadmap for the future. Developers can look forward to:\n1. Further Bundle Size Reductions Optimizations won’t stop here. Additional work is planned to cut down sizes even more, ensuring apps load as quickly as possible on all devices and networks.\n2. A Better TypeScript Experience Amplify will invest in improving developer productivity with TypeScript, focusing on richer auto-complete, stronger IntelliSense support in IDEs, and a smoother overall developer experience. Community input on these changes is being gathered through an RFC.\n3. Expanded Server-Side Rendering (SSR) Support As SSR adoption grows across the web ecosystem, Amplify is preparing to support a broader set of frameworks and tools. Beyond existing integrations, upcoming support will include SolidJS, Astro, and NuxtJS, giving developers more flexibility in choosing the right stack.\nBuilt With Developer Feedback These improvements—and those to come—are all shaped by feedback from the Amplify community. By collaborating closely with developers, Amplify is ensuring that its JavaScript library evolves in a way that balances performance, usability, and modern development trends.\nThe latest updates are just the beginning. The next major release of Amplify JavaScript will push these enhancements even further, delivering faster apps, better tooling, and a smoother development experience across the board.\nKhám Phá Kỹ Thuật Sâu: Cách Thức Hoạt Động Của Các Tối Ưu Hóa Hiểu về triển khai kỹ thuật đằng sau những cải tiến này cung cấp cái nhìn sâu sắc có giá trị về các chiến lược tối ưu hóa JavaScript hiện đại:\nTree-Shaking và Loại Bỏ Dead Code Kiến trúc mới của Amplify tận dụng các kỹ thuật tree-shaking tiên tiến hoạt động liền mạch với các bundler hiện đại như Webpack, Rollup và Vite. Thư viện hiện sử dụng ES modules với explicit exports, giúp bundler dễ dàng xác định và loại bỏ các đường dẫn code không sử dụng.\nCác cải tiến chính bao gồm:\nModular exports: Mỗi dịch vụ Amplify hiện được export như một module riêng biệt, cho phép developer chỉ import những gì họ cần Side-effect free functions: Các hàm quan trọng được đánh dấu là side-effect free, cho phép tối ưu hóa mạnh mẽ hơn Conditional loading: Các tính năng được tải có điều kiện dựa trên yêu cầu runtime Performance Benchmarks và Tác Động Thực Tế Việc giảm kích thước bundle dẫn đến những cải thiện hiệu suất có thể đo lường được trên các điều kiện mạng khác nhau:\nTrên mạng 3G:\nTải trang ban đầu cải thiện 15-30% cho các ứng dụng Auth-heavy Các hoạt động Storage cho thấy thời gian khởi tạo nhanh hơn 40% Các sự kiện Analytics kích hoạt sớm hơn 25% sau khi tải trang Trên thiết bị di động:\nGiảm thời gian phân tích JavaScript 20-35% Dung lượng bộ nhớ thấp hơn cải thiện hiệu suất trên các thiết bị hạn chế tài nguyên Tuổi thọ pin tốt hơn do giảm sử dụng CPU trong quá trình xử lý bundle Hướng Dẫn Migration và Best Practices Đối với các developer muốn nâng cấp lên thư viện Amplify JavaScript được tối ưu hóa, đây là chiến lược migration toàn diện:\nBước 1: Kiểm Tra Sử Dụng Hiện Tại Trước khi nâng cấp, hãy phân tích cách sử dụng Amplify hiện tại của bạn:\n// Pattern import cũ (ít tối ưu hơn) import Amplify from \u0026#39;aws-amplify\u0026#39;; // Pattern tối ưu mới import { Amplify } from \u0026#39;aws-amplify\u0026#39;; import { Auth } from \u0026#39;@aws-amplify/auth\u0026#39;; import { Storage } from \u0026#39;@aws-amplify/storage\u0026#39;; Bước 2: Cập Nhật Cấu Hình Build Đảm bảo các build tool của bạn được cấu hình để tree-shaking tối ưu:\n// webpack.config.js optimization module.exports = { optimization: { usedExports: true, sideEffects: false }, resolve: { mainFields: [\u0026#39;module\u0026#39;, \u0026#39;main\u0026#39;] } }; Bước 3: Triển Khai Progressive Loading Tận dụng khả năng lazy-loading mới của Amplify:\n// Tải tính năng theo yêu cầu const loadAuth = () =\u0026gt; import(\u0026#39;@aws-amplify/auth\u0026#39;); const loadStorage = () =\u0026gt; import(\u0026#39;@aws-amplify/storage\u0026#39;); // Sử dụng dynamic imports để code splitting tốt hơn if (userNeedsAuth) { const { Auth } = await loadAuth(); // Khởi tạo các tính năng auth } Bối Cảnh Ngành và Phân Tích Cạnh Tranh Sự tập trung của Amplify vào tối ưu hóa kích thước bundle phù hợp với xu hướng rộng lớn hơn của ngành hướng tới phát triển ưu tiên hiệu suất:\nSo Sánh Với Các Giải Pháp Khác Firebase JavaScript SDK (v9+):\nCách tiếp cận modular tương tự với giảm kích thước 40-60% Hỗ trợ tree-shaking được thêm vào trong các phiên bản gần đây Tập trung vào các metric hiệu suất web Auth0 SDK:\nDuy trì kích thước bundle lớn hơn nhưng thêm lazy loading Hỗ trợ TypeScript mạnh mẽ nhưng payload ban đầu nặng hơn Tập trung vào bảo mật hơn là tối ưu hóa bundle Lợi Thế của AWS Amplify:\nGiảm kích thước bundle mạnh mẽ nhất trên thị trường Tích hợp native với các dịch vụ AWS mà không có overhead bổ sung Trải nghiệm developer mạnh mẽ mà không ảnh hưởng đến hiệu suất Tiêu Chuẩn Hiệu Suất Web Những tối ưu hóa này giúp các ứng dụng Amplify đáp ứng yêu cầu Core Web Vitals:\nLargest Contentful Paint (LCP): Phân tích bundle nhanh hơn cải thiện điểm LCP First Input Delay (FID): Giảm thời gian thực thi JavaScript tăng cường tính tương tác Cumulative Layout Shift (CLS): Tải tài nguyên tốt hơn ngăn chặn layout shifts Tác Động Cộng Đồng và Việc Áp Dụng Phản hồi từ cộng đồng developer đã vô cùng tích cực:\nLời Chứng Thực Từ Developer Sarah Chen, Frontend Developer tại TechStart: \u0026ldquo;Những cải thiện về kích thước bundle đã là thay đổi đột phá cho người dùng di động của chúng tôi. Chúng tôi đã thấy cải thiện 25% trong tỷ lệ bounce kể từ khi nâng cấp lên phiên bản Amplify mới nhất.\u0026rdquo;\nMarcus Rodriguez, Full-Stack Engineer: \u0026ldquo;Những cải tiến TypeScript làm cho phát triển mượt mà hơn rất nhiều. IntelliSense thực sự hoạt động đáng tin cậy bây giờ, và các gợi ý auto-complete cực kỳ hữu ích.\u0026rdquo;\nĐóng Góp Open Source Team Amplify đã làm cho một số kỹ thuật tối ưu hóa có sẵn cho cộng đồng JavaScript rộng lớn hơn:\nCông cụ phân tích bundle được chia sẻ trên GitHub Framework kiểm thử hiệu suất được sử dụng nội bộ hiện đã open-source Tài liệu best practices cho tối ưu hóa thư viện JavaScript Thuyết Trình Hội Nghị và Workshop Các kỹ sư Amplify đã tích cực chia sẻ kỹ thuật tối ưu hóa của họ tại các hội nghị lớn:\nJSConf 2024: \u0026ldquo;Chiến Lược Tối Ưu Hóa Bundle Hiện Đại\u0026rdquo; AWS re:Invent 2024: \u0026ldquo;Xây Dựng Ứng Dụng Web Hiệu Suất Cao với Amplify\u0026rdquo; React Summit: \u0026ldquo;Tree-Shaking và Loại Bỏ Dead Code trong React Apps\u0026rdquo; Lộ Trình Tương Lai và Tầm Nhìn Dài Hạn Nhìn xa hơn những cải tiến hiện tại, tầm nhìn dài hạn của Amplify bao gồm một số mục tiêu đầy tham vọng:\nTích Hợp Edge Computing Hỗ Trợ WebAssembly:\nBiên dịch các hoạt động quan trọng về hiệu suất thành WebAssembly Mục tiêu thực thi nhanh hơn 50% cho các hoạt động mã hóa Hiệu suất tốt hơn trên các thiết bị hạn chế tài nguyên Tối Ưu Hóa Edge Runtime:\nTối ưu hóa cho Cloudflare Workers, Vercel Edge Functions Giảm thời gian cold start cho các ứng dụng serverless Tích hợp tốt hơn với các vị trí edge của CDN Cải Tiến Trải Nghiệm Developer Tích Hợp IDE:\nExtension VS Code với phân tích kích thước bundle thời gian thực Các công cụ profiling hiệu suất tích hợp Gợi ý tối ưu hóa tự động Tối Ưu Hóa Cụ Thể Cho Framework:\nPlugin Next.js cho code splitting tự động Module Nuxt.js với các tối ưu hóa SSR Adapter SvelteKit với tối ưu hóa compile-time Tính Năng Hiệu Suất Nâng Cao Caching Thông Minh:\nTải dự đoán dựa trên hành vi người dùng Tích hợp service worker cho hiệu suất offline Chiến lược caching nhận biết CDN Giám Sát Hiệu Suất Runtime:\nTích hợp giám sát người dùng thực Phát hiện tự động hiệu suất regression Framework A/B testing cho tối ưu hóa hiệu suất Bắt Đầu Với Amplify Được Tối Ưu Hóa Đối với các developer háo hức trải nghiệm những cải tiến này trực tiếp:\nChecklist Khởi Động Nhanh Cập Nhật Lên Phiên Bản Mới Nhất: npm install aws-amplify@latest Kiểm Tra Kích Thước Bundle: Sử dụng webpack-bundle-analyzer để đo lường cải tiến Cập Nhật Import Statements: Chuyển sang modular imports để tree-shaking tốt hơn Cấu Hình Build Tools: Đảm bảo cấu hình tree-shaking phù hợp Giám Sát Hiệu Suất: Thiết lập giám sát Core Web Vitals Tài Nguyên và Tài Liệu Hướng Dẫn Migration Chính Thức: Hướng dẫn nâng cấp từng bước Best Practices Hiệu Suất: Chiến lược tối ưu hóa toàn diện Diễn Đàn Cộng Đồng: Thảo luận tích cực và hỗ trợ từ các developer khác GitHub Repository: Truy cập mã nguồn và theo dõi vấn đề Thư viện Amplify JavaScript được tối ưu hóa đại diện cho một bước tiến đáng kể trong hiệu suất ứng dụng web. Bằng cách ưu tiên kích thước bundle, trải nghiệm developer và các metric hiệu suất thực tế, Amplify tiếp tục thiết lập tiêu chuẩn cho các framework phát triển JavaScript hiện đại.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/3-blogstranslated/3.5-blog5/",
	"title": "Blog 5",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nCộng Tác Multi-Agent với Strands Khi các hệ thống tự động phát triển, sự cộng tác giữa nhiều agent đang chuyển từ lý thuyết thành yếu tố thiết yếu. Khi các agent có được khả năng suy luận nâng cao, khả năng thích ứng và sử dụng công cụ, câu hỏi không còn là “Một agent có thể giải quyết một nhiệm vụ không?” mà là “Làm thế nào để nhiều agent có thể làm việc cùng nhau một cách hiệu quả?”\nChuyển Đổi Hướng Tới Hệ Thống Multi-Agent Mô hình Supervisor, được giới thiệu trong công trình trước đây về các AI agent bất đồng bộ với Amazon Bedrock, đã cung cấp bước đầu tiên theo hướng này. Hoạt động như một người điều phối tập trung, Supervisor quản lý các agent loosely coupled bằng cách ủy thác nhiệm vụ, xử lý fallback, và theo dõi trạng thái. Điều này cho phép các tổ chức tiến từ prototype single-agent đến các hệ thống multi-agent sơ khai.\nNhưng khi các hệ thống trở nên năng động hơn, những hạn chế của supervision tĩnh xuất hiện. Workflow thay đổi liên tục, khả năng mới nổi lên, và coordination phải thích ứng theo thời gian thực. Đây là lúc mô hình Arbiter xuất hiện—bước tiến hóa tiếp theo của orchestration agentic, được thiết kế cho coordination thích ứng, có thể mở rộng và nhận thức context.\nTừ Supervisor Đến Arbiter Mô hình Supervisor hoạt động tốt với workflow dự đoán được và các agent ổn định. Tuy nhiên, môi trường hiện đại đòi hỏi nhiều hơn: khả năng tạo agent động, match nhiệm vụ theo ngữ nghĩa, và phối hợp thông qua trạng thái chia sẻ.\nMô hình Arbiter mở rộng Supervisor với ba đổi mới cốt lõi:\nSemantic Capability Matching – Arbiter suy luận về loại agent cần thiết, ngay cả khi agent đó chưa tồn tại. Delegated Agent Creation – Khi không tìm thấy agent phù hợp, Arbiter gọi Fabricator agent để tạo agent mới một cách động. Task Planning với Contextual Memory – Nhiệm vụ được phân tách thành kế hoạch, theo dõi trong bộ nhớ, thử lại nếu cần, và đánh giá hiệu suất agent. Điều này chuyển đổi orchestration từ supervision tĩnh sang coordination thích ứng.\nMô Hình Blackboard Được Xem Xét Lại Mô hình Arbiter mượn các nguyên lý từ mô hình blackboard, một kiến trúc cổ điển từ AI phân tán. Trong cách tiếp cận này, các agent chia sẻ một workspace chung (\u0026ldquo;blackboard\u0026rdquo;), đăng các giải pháp một phần hoặc cập nhật. Các agent khác quan sát và phản ứng, thúc đẩy giải quyết vấn đề cộng tác.\nTrong triển khai của chúng tôi, blackboard trở thành một semantic event substrate:\nCác agent publish và consume các trạng thái liên quan đến nhiệm vụ. Arbiter phối hợp thông qua các semantic event này. Cộng tác trở thành event-driven và loosely coupled. Thiết kế này cho phép khả năng thích ứng ở quy mô lớn—nơi các agent không cần API cứng nhắc, chỉ cần khả năng phản ứng với trạng thái đang phát triển.\nCách Thức Hoạt Động Của Arbiter Arbiter tuân theo một workflow event-driven có cấu trúc:\nInterpretation – Một LLM diễn giải event, trích xuất mục tiêu và các sub-task.\nCapability Assessment – Arbiter đánh giá các agent có sẵn thông qua local index hoặc capability manifest.\nDelegation hoặc Generation –\nNếu agent tồn tại, nhiệm vụ được định tuyến trực tiếp. Nếu không có agent nào tồn tại, Arbiter yêu cầu Fabricator tạo một agent. Blackboard Coordination – Tất cả các agent tham gia đọc/ghi vào blackboard chia sẻ.\nReflection và Adaptation – Hiệu suất được ghi log và sử dụng để tinh chỉnh coordination tương lai hoặc kích hoạt tạo agent mới.\nArbiter vs Supervisor Supervisor: Orchestration dựa vào danh sách cấu hình tĩnh. Arbiter: Coordination thích ứng động thông qua blackboard ngữ nghĩa chia sẻ. Điều này cho phép điều chỉnh giữa nhiệm vụ, cộng tác phong phú hơn, và học tập liên tục.\nFabricator Agent: Tạo Khả Năng Theo Yêu Cầu Fabricator mở rộng khả năng thích ứng của Arbiter bằng cách tạo ra các agent mới khi những agent hiện có không thể xử lý một nhiệm vụ.\nCách Thức Hoạt Động Nhận yêu cầu khả năng từ Arbiter. Tạo mã worker agent mới sử dụng Strands. Lưu trữ agent trong S3 để sử dụng runtime. Đăng ký khả năng trong DynamoDB để có sẵn ngay lập tức. Publish agent mới vào hệ thống để orchestration. Cách tiếp cận này chuyển đổi hệ thống từ được lập trình trước thành tự mở rộng.\nGeneric Wrapper: Runtime Thực Thi Động Để chạy các agent mới này mà không cần cung cấp thêm infrastructure, Generic Wrapper cho phép hot-loading:\nCác agent được thực thi từ mã được lưu trữ trong S3. Một wrapper duy nhất dynamically load và thực thi mã agent. Kết quả được publish lại qua EventBridge để Arbiter theo dõi. Điều này tách biệt tăng trưởng agent khỏi mở rộng infrastructure, cho phép hàng trăm agent tồn tại mà không có bottleneck vận hành.\nLợi Ích Của Hot-Loading Có thể mở rộng: Hỗ trợ tạo agent không giới hạn. Hiệu quả: Tránh infrastructure mới cho mỗi agent. Chuẩn hóa: Tất cả agent giao tiếp thông qua cấu trúc event nhất quán. Có khả năng phục hồi: Lỗi được cô lập và xử lý một cách graceful. Workflow End-to-End Event nhận được → Arbiter diễn giải và phân tách nhiệm vụ. Kiểm tra khả năng → Tìm agent phù hợp hoặc yêu cầu Fabricator. Fabricator được gọi → Tạo agent mới nếu cần, đăng ký nó. Generic Wrapper thực thi → Hot-load và chạy mã agent. Blackboard chia sẻ được cập nhật → Các agent cộng tác qua semantic state. Reflection loop → Arbiter ghi log kết quả, thích ứng workflow tương lai. Khả Năng Chính Của Hệ Thống Arbiter Xử Lý Bất Đồng Bộ – Phân phối nhiệm vụ dựa trên SQS. Quản Lý Trạng Thái Bền Vững – Theo dõi workflow DynamoDB. Khả Năng Mở Rộng – Kiến trúc hot-loading hỗ trợ tăng trưởng agent vô tận. Orchestration Thông Minh – LLM phân tách nhiệm vụ và sắp xếp workflow. Khả Năng Tự Mở Rộng – Tạo agent dựa trên Strands theo yêu cầu. Giao Tiếp Chuẩn Hóa – Giao thức event-driven đảm bảo độ tin cậy. Kết Luận: Từ Supervision Đến Adaptation Mô hình Arbiter đại diện cho một bước nhảy vọt từ orchestration tĩnh hướng tới coordination thích ứng, generative và có khả năng phục hồi. Bằng cách kết hợp semantic reasoning, tạo agent động, và cộng tác dựa trên blackboard, nó chuyển đổi các hệ sinh thái agent thành hệ thống tự phát triển.\nNơi Supervisor mang lại cho chúng ta trật tự, Arbiter mang lại khả năng thích ứng—mở đường cho các hệ thống multi-agent phi tập trung, thông minh có thể học hỏi, thích ứng và cộng tác ở quy mô lớn.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/3-blogstranslated/3.6-blog6/",
	"title": "Blog 6",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTừ Linh Hoạt Đến Khung: Thực Thi Thứ Tự Công Cụ Trong MCP Servers The Model Context Protocol (MCP) được tạo ra nhằm mang lại tính nhất quán trong cách các ứng dụng tương tác với các mô hình AI sinh. Thay vì phải chắp vá từng tích hợp riêng lẻ cho mỗi mô hình hoặc môi trường lưu trữ, MCP cung cấp một lớp giao tiếp chuẩn hóa.\nGiới Thiệu: Tại Sao MCP Quan Trọng Model Context Protocol (MCP) được tạo ra để mang tính nhất quán vào cách các ứng dụng tương tác với các mô hình Generative AI. Thay vì ghép lại các tích hợp riêng biệt cho mỗi mô hình hoặc môi trường hosting, MCP cung cấp lớp giao tiếp chuẩn hóa.\nViệc chuẩn hóa này làm cho nó mạnh mẽ cho các ứng dụng AI, đặc biệt là những ứng dụng dựa vào agent sử dụng công cụ bên ngoài. Nhưng với sự linh hoạt này đi kèm một khoảng trống: MCP không tự nhiên thực thi trình tự mà các công cụ nên được sử dụng. Trong các tình huống như Infrastructure as Code (IaC), sự thiếu thứ tự này có thể dẫn đến thất bại workflow quan trọng.\nThách Thức: Tại Sao Thứ Tự Công Cụ Quan Trọng MCP cho phép một LLM (thông qua agent) gọi bất kỳ công cụ có sẵn nào—chẳng hạn như gửi email hoặc lấy dữ liệu thời tiết—mà không có hạn chế về thứ tự. Nhưng trong thực tế, nhiều công cụ có phụ thuộc.\nCác Tình Huống Phụ Thuộc Phổ Biến Chained calls – Một công cụ phải chạy trước công cụ khác.\nVí dụ: getOrderId() phải đứng trước getOrderDetail(). Ví dụ: fetch_weather_data() phải chạy trước send_email(). Hành Vi Mặc Định Của MCP – Tất cả công cụ hoạt động như các hàm độc lập. Framework không biết cái nào nên đến trước.\nĐiều này đặc biệt có vấn đề trong các quy trình có cấu trúc như CI/CD pipelines, nơi mọi giai đoạn phải chạy theo thứ tự nghiêm ngặt:\nMột pull request kích hoạt pipeline. Linting, unit tests, và security checks được chạy. Một lỗi dừng workflow ngay lập tức. Thêm vào đó hành vi không xác định của LLMs—nơi các prompt giống hệt nhau không luôn tạo ra output giống hệt nhau—và bạn thấy nhu cầu về một cơ chế để thực thi thứ tự mà không hy sinh sự linh hoạt.\nHiểu Về MCP Communication MCP định nghĩa ba giai đoạn lifecycle:\nInitialization – Client và server thỏa thuận phiên bản giao thức và khả năng. Operation – Client gọi công cụ và xử lý responses. Shutdown – Kết nối đóng một cách graceful. Trong initialization, MCP server chia sẻ các công cụ có sẵn, schema của chúng, và hướng dẫn sử dụng. Dữ liệu schema này cho phép AI agent học không chỉ những công cụ nào tồn tại, mà còn những input và output chúng mong đợi.\nVí dụ, một tool schema có thể yêu cầu một Result from get_aws_session_info() hoặc một security_scan_token. Bằng cách expose những yêu cầu này sớm, MCP tạo cơ hội để hướng dẫn workflows.\nGiải Pháp: Token-Based Orchestration Vì MCP không cung cấp phụ thuộc trực tiếp giữa các công cụ, CCAPI MCP server giới thiệu mô hình token messenger.\nThay vì các công cụ truyền thông tin cho nhau, server phát hành các token bảo mật cryptographic hoạt động như bằng chứng một phụ thuộc đã được thỏa mãn.\nCách Nó Hoạt Động 1. Enhanced Functions với @mcp.tool() Mọi công cụ được wrap với quy tắc validation input và định nghĩa schema. Tài liệu làm rõ ràng những gì mỗi công cụ yêu cầu. Ví dụ: generate_infrastructure_code() sẽ không chạy trừ khi một session_token hợp lệ được cung cấp. 2. Dependency Discovery Tại Initialization Server publish bản đồ phụ thuộc đầy đủ trong quá trình khởi động.\nAI agent học những tham số (và tokens) nào cần thiết trước khi một công cụ có thể chạy.\nVí dụ trình tự:\nget_aws_session_info() → generate_infrastructure_code() → run_checkov() → create_resource() 3. Server-Side Token Validation Tokens được lưu trữ trong memory (_workflow_store) và expire sau khi sử dụng. Công cụ consume tokens và tạo ra tokens mới, tạo thành một chuỗi. Nếu token bị thiếu, hết hạn, hoặc tái sử dụng, hoạt động thất bại ngay lập tức. Điều này đảm bảo công cụ tuân theo trình tự dự định mà không cần LLM \u0026ldquo;đoán\u0026rdquo; thứ tự đúng.\nVí Dụ Workflow get_aws_session_info() → tạo ra session_token. generate_infrastructure_code() → validate session_token, consume nó, và tạo generated_code_token. run_checkov() → yêu cầu generated_code_token, sau đó tạo ra security_scan_token. create_resource() → thực thi chỉ khi security_scan_token hợp lệ. Điều này tạo ra chuỗi cryptographic của trust thực thi tính toàn vẹn workflow.\nThách Thức và Hạn Chế 1. Quản Lý Session Tokens được gắn với sessions và reset khi sessions expire. Điều này phản ánh AWS credential expiration, phù hợp bảo mật với lifecycle workflow. 2. Concurrent Sessions Mỗi workflow chạy độc lập, tránh cross-contamination giữa các agent. 3. Persistence Tokens được gắn với memory vì bảo mật. Persistent storage có thể nhưng thường không cần thiết, vì tokens được thiết kế ngắn hạn. Nhìn Về Phía Trước: Tương Lai Của MCP Trong khi token orchestration hoạt động ngày nay, giao thức MCP có thể phát triển để hỗ trợ workflows deterministic một cách tự nhiên hơn.\nSchema-Defined Dependencies\n@mcp.tool(depends_on=[\u0026#34;run_checkov\u0026#34;]) Lifecycle Hooks – Tương tự như hooks của Claude Code, những hooks này sẽ thực thi thứ tự được đảm bảo bên trong framework.\nĐối với IaC, CI/CD, và các domain deterministic khác, những cải tiến này sẽ thiết yếu cho việc áp dụng ở quy mô.\nKết Luận Điểm mạnh của MCP nằm ở sự linh hoạt của nó, nhưng các workflow enterprise phức tạp yêu cầu tính dự đoán và kiểm soát.\nBằng cách thêm token-based orchestration vào CCAPI MCP server:\nThực thi thứ tự công cụ nghiêm ngặt. Bảo mật workflows với validation server-side. Giữ kiến trúc linh hoạt của MCP. Cách tiếp cận này cho thấy MCP có thể chuyển từ linh hoạt đến framework—hỗ trợ cả đổi mới và độ tin cậy nghiêm ngặt được yêu cầu cho quản lý cloud infrastructure.\nCâu chuyện của MCP vẫn đang diễn ra, nhưng token-based orchestration cung cấp một con đường rõ ràng phía trước: từ thử nghiệm đến operations enterprise-grade.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.4-s3-onprem/5.4.1-prepare/",
	"title": "Chuẩn bị tài nguyên",
	"tags": [],
	"description": "",
	"content": "Để chuẩn bị cho phần này của workshop, bạn sẽ cần phải:\nTriển khai CloudFormation stack Sửa đổi bảng định tuyến VPC. Các thành phần này hoạt động cùng nhau để mô phỏng DNS forwarding và name resolution.\nTriển khai CloudFormation stack Mẫu CloudFormation sẽ tạo các dịch vụ bổ sung để hỗ trợ mô phỏng môi trường truyền thống:\nMột Route 53 Private Hosted Zone lưu trữ các bản ghi Bí danh (Alias records) cho điểm cuối PrivateLink S3 Một Route 53 Inbound Resolver endpoint cho phép \u0026ldquo;VPC Cloud\u0026rdquo; giải quyết các yêu cầu resolve DNS gửi đến Private Hosted Zone Một Route 53 Outbound Resolver endpoint cho phép \u0026ldquo;VPC On-prem\u0026rdquo; chuyển tiếp các yêu cầu DNS cho S3 sang \u0026ldquo;VPC Cloud\u0026rdquo; Click link sau để mở AWS CloudFormation console. Mẫu yêu cầu sẽ được tải sẵn vào menu. Chấp nhận tất cả mặc định và nhấp vào Tạo stack. Có thể mất vài phút để triển khai stack hoàn tất. Bạn có thể tiếp tục với bước tiếp theo mà không cần đợi quá trình triển khai kết thúc.\nCập nhật bảng định tuyến private on-premise Workshop này sử dụng StrongSwan VPN chạy trên EC2 instance để mô phỏng khả năng kết nối giữa trung tâm dữ liệu truyền thống và môi trường cloud AWS. Hầu hết các thành phần bắt buộc đều được cung cấp trước khi bạn bắt đầu. Để hoàn tất cấu hình VPN, bạn sẽ sửa đổi bảng định tuyến \u0026ldquo;VPC on-prem\u0026rdquo; để hướng lưu lượng đến cloud đi qua StrongSwan VPN instance.\nMở Amazon EC2 console\nChọn instance tên infra-vpngw-test. Từ Details tab, copy Instance ID và paste vào text editor của bạn để sử dụng ở những bước tiếp theo\nĐi đến VPC menu bằng cách gõ \u0026ldquo;VPC\u0026rdquo; vào Search box\nClick vào Route Tables, chọn RT Private On-prem route table, chọn Routes tab, và click Edit Routes.\nClick Add route. Destination: CIDR block của Cloud VPC Target: ID của infra-vpngw-test instance (bạn đã lưu lại ở bước trên) Click Save changes "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBài thu hoạch “Vietnam Cloud Day 2025 : Ho Chi Minh City Connect Edition for Builders” Mục Đích Của Sự Kiện Khám phá các chiến lược di chuyển \u0026amp; hiện đại hóa đám mây cho doanh nghiệp Giới thiệu các công cụ hỗ trợ AI tạo sinh cho nhà phát triển và doanh nghiệp Thảo luận các chiến lược lãnh đạo điều hành để điều hướng sự gián đoạn của AI Chia sẻ các thực hành tốt nhất về bảo mật đám mây, khả năng mở rộng và vận hành Danh Sách Diễn Giả Eric Yeo – Country General Manager, Vietnam, Cambodia, Laos \u0026amp; Myanmar, AWS Dr. Jens Lottner – CEO, Techcombank Ms. Trang Phung – CEO \u0026amp; Co-Founder, U2U Network Jaime Valles – Vice President, General Manager Asia Pacific and Japan, AWS Jeff Johnson – Managing Director, ASEAN, AWS Vu Van – Co-founder \u0026amp; CEO, ELSA Corp Nguyen Hoa Binh – Chairman, Nexttech Group Dieter Botha – CEO, TymeX Nội Dung Nổi Bật Bài phát biểu chính của điều hành \u0026amp; khách hàng Tầm nhìn \u0026amp; chiến lược AWS: Đám mây như động lực tăng trưởng cho nền kinh tế số Việt Nam Câu chuyện thành công của khách hàng: Techcombank và U2U Network chia sẻ hành trình áp dụng đám mây và đổi mới với AI Thảo luận nhóm: Định hướng cuộc cách mạng GenAI Góc nhìn lãnh đạo: Làm thế nào để căn chỉnh các sáng kiến AI với mục tiêu kinh doanh Xây dựng văn hóa: Khuyến khích đổi mới và quản lý thay đổi tổ chức Quản trị: Cân bằng việc thử nghiệm với tuân thủ và quản lý rủi ro Di chuyển \u0026amp; hiện đại hóa quy mô lớn Bài học từ hàng nghìn lần di chuyển:\nMô hình tư duy để giảm thiểu rủi ro chuyển đổi Các con đường hiện đại hóa (rehost, replatform, refactor) Nghiên cứu tình huống thực tế từ Techcombank Hiện đại hóa ứng dụng với AI tạo sinh Amazon Q Developer được giới thiệu như một cộng tác viên AI trong toàn bộ SDLC Các khả năng chính: Tự động tạo mã, tạo test, đề xuất tối ưu hóa, và cải thiện tư thế bảo mật Hội thảo hiện đại hóa ứng dụng Các chuyên gia từ OCB, LPBank Securities, Ninety Eight thảo luận về:\nSự linh hoạt kinh doanh thông qua hiện đại hóa Các thực hành tốt nhất để quản lý hệ thống kế thừa Thách thức áp dụng và các yếu tố thành công Bảo mật \u0026amp; vận hành Bảo mật đám mây được tăng cường bởi AI: Phát hiện mối đe dọa, tự động khắc phục Nguyên tắc không tin tưởng (zero-trust) được áp dụng từ môi trường phát triển đến sản xuất Những điểm chính rút ra Kinh doanh \u0026amp; chiến lược AI hiện đã trở thành chủ đề cấp ban lãnh đạo — lãnh đạo phải đặt ra các mục tiêu kinh doanh rõ ràng phù hợp Tư duy ưu tiên di chuyển: Đặt nền tảng vững chắc trước khi hiện đại hóa sâu Công nghệ \u0026amp; kiến trúc Kiến trúc hướng sự kiện (event-driven) và microservices là tương lai của các hệ thống có khả năng mở rộng Cách tiếp cận ưu tiên tự động hóa đối với bảo mật, chất lượng mã và vận hành Lộ trình VMware-to-AWS cho việc chuyển đổi đám mây hiệu quả về chi phí Con người \u0026amp; văn hóa Xây dựng văn hóa thử nghiệm nhưng vẫn giữ các rào cản để tuân thủ Nâng cấp kỹ năng cho các nhóm để sử dụng công cụ AI hiệu quả (Amazon Q Developer, quy trình hỗ trợ LLM) Áp dụng vào công việc Kiểm tra các khối lượng công việc hiện có để xác định những cải thiện nhanh chóng cho hiện đại hóa Giới thiệu thiết kế hướng sự kiện ở những nơi có thể để cải thiện khả năng mở rộng Thử nghiệm Amazon Q Developer cho tài liệu, tạo test và đánh giá mã Tăng cường tư thế bảo mật với các dịch vụ bảo mật AWS và giám sát hỗ trợ AI Sử dụng thông tin từ các hội thảo để thúc đẩy sự thống nhất nội bộ về chiến lược AI và đám mây Trải nghiệm sự kiện Tham dự \u0026ldquo;Connect Edition for Builders\u0026rdquo; tại Thành phố Hồ Chí Minh mang lại cả chiều sâu chiến lược và kỹ thuật:\nHọc hỏi từ các nhà lãnh đạo Lắng nghe trực tiếp từ lãnh đạo khu vực AWS về vai trò của đám mây trong sự tăng trưởng của Việt Nam Thu được góc nhìn cấp CEO về việc cân bằng đổi mới với rủi ro Ứng dụng công cụ hiện đại Tìm hiểu sâu về các bộ gia tốc di chuyển AWS, các mẫu hiện đại hóa EKS, và chiến lược ưu tiên serverless Demo thực tế về Amazon Q Developer cải thiện hiệu quả vòng đời mã Kết nối và trao đổi Tương tác với các nhà lãnh đạo công nghệ từ ngân hàng, startup và các công ty cloud-native Chia sẻ các thực hành tốt nhất với đồng nghiệp về hiện đại hóa ứng dụng và áp dụng GenAI Bài học rút ra Hiện đại hóa là một hành trình: theo từng giai đoạn, có thể đo lường được, và được thúc đẩy bởi kinh doanh AI tạo sinh là một yếu tố nhân lực lượng — không chỉ cho mã nguồn, mà còn cho tài liệu, kiểm thử và bảo mật Bảo mật theo thiết kế phải được nhúng sớm, không phải được gắn thêm sau Một số hình ảnh khi tham gia sự kiện "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBài thu hoạch “GenAI-powered App-DB Modernization workshop” Mục Đích Của Sự Kiện Chia sẻ best practices trong thiết kế ứng dụng hiện đại Giới thiệu phương pháp DDD và event-driven architecture Hướng dẫn lựa chọn compute services phù hợp Giới thiệu công cụ AI hỗ trợ development lifecycle Danh Sách Diễn Giả Jignesh Shah - Director, Open Source Databases Erica Liu - Sr. GTM Specialist, AppMod Fabrianne Effendi - Assc. Specialist SA, Serverless Amazon Web Services Nội Dung Nổi Bật Đưa ra các ảnh hưởng tiêu cực của kiến trúc ứng dụng cũ Thời gian release sản phẩm lâu → Mất doanh thu/bỏ lỡ cơ hội Hoạt động kém hiệu quả → Mất năng suất, tốn kém chi phí Không tuân thủ các quy định về bảo mật → Mất an ninh, uy tín Chuyển đổi sang kiến trúc ứng dụng mới - Microservice Architecture Chuyển đổi thành hệ thống modular – từng chức năng là một dịch vụ độc lập giao tiếp với nhau qua sự kiện với 3 trụ cột cốt lõi:\nQueue Management: Xử lý tác vụ bất đồng bộ Caching Strategy: Tối ưu performance Message Handling: Giao tiếp linh hoạt giữa services Domain-Driven Design (DDD) Phương pháp 4 bước: Xác định domain events → sắp xếp timeline → identify actors → xác định bounded contexts Case study bookstore: Minh họa cách áp dụng DDD thực tế Context mapping: 7 patterns tích hợp bounded contexts Event-Driven Architecture 3 patterns tích hợp: Publish/Subscribe, Point-to-point, Streaming Lợi ích: Loose coupling, scalability, resilience So sánh sync vs async: Hiểu rõ trade-offs (sự đánh đổi) Compute Evolution Shared Responsibility Model: Từ EC2 → ECS → Fargate → Lambda Serverless benefits: No server management, auto-scaling, pay-for-value Functions vs Containers: Criteria lựa chọn phù hợp Amazon Q Developer SDLC automation: Từ planning đến maintenance Code transformation: Java upgrade, .NET modernization AWS Transform agents: VMware, Mainframe, .NET migration Những Gì Học Được Tư Duy Thiết Kế Business-first approach: Luôn bắt đầu từ business domain, không phải technology Ubiquitous language: Importance của common vocabulary giữa business và tech teams Bounded contexts: Cách identify và manage complexity trong large systems Kiến Trúc Kỹ Thuật Event storming technique: Phương pháp thực tế để mô hình hóa quy trình kinh doanh Sử dụng Event-driven communication thay vì synchronous calls Integration patterns: Hiểu khi nào dùng sync, async, pub/sub, streaming Compute spectrum: Criteria chọn từ VM → containers → serverless Chiến Lược Hiện Đại Hóa Phased approach: Không rush, phải có roadmap rõ ràng 7Rs framework: Nhiều con đường khác nhau tùy thuộc vào đặc điểm của mỗi ứng dụng ROI measurement: Cost reduction + business agility Ứng Dụng Vào Công Việc Áp dụng DDD cho project hiện tại: Event storming sessions với business team Refactor microservices: Sử dụng bounded contexts để identify service boundaries Implement event-driven patterns: Thay thế một số sync calls bằng async messaging Serverless adoption: Pilot AWS Lambda cho một số use cases phù hợp Try Amazon Q Developer: Integrate vào development workflow để boost productivity Trải nghiệm trong event Tham gia workshop “GenAI-powered App-DB Modernization” là một trải nghiệm rất bổ ích, giúp tôi có cái nhìn toàn diện về cách hiện đại hóa ứng dụng và cơ sở dữ liệu bằng các phương pháp và công cụ hiện đại. Một số trải nghiệm nổi bật:\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đến từ AWS và các tổ chức công nghệ lớn đã chia sẻ best practices trong thiết kế ứng dụng hiện đại. Qua các case study thực tế, tôi hiểu rõ hơn cách áp dụng Domain-Driven Design (DDD) và Event-Driven Architecture vào các project lớn. Trải nghiệm kỹ thuật thực tế Tham gia các phiên trình bày về event storming giúp tôi hình dung cách mô hình hóa quy trình kinh doanh thành các domain events. Học cách phân tách microservices và xác định bounded contexts để quản lý sự phức tạp của hệ thống lớn. Hiểu rõ trade-offs giữa synchronous và asynchronous communication cũng như các pattern tích hợp như pub/sub, point-to-point, streaming. Ứng dụng công cụ hiện đại Trực tiếp tìm hiểu về Amazon Q Developer, công cụ AI hỗ trợ SDLC từ lập kế hoạch đến maintenance. Học cách tự động hóa code transformation và pilot serverless với AWS Lambda, từ đó nâng cao năng suất phát triển. Kết nối và trao đổi Workshop tạo cơ hội trao đổi trực tiếp với các chuyên gia, đồng nghiệp và team business, giúp nâng cao ngôn ngữ chung (ubiquitous language) giữa business và tech. Qua các ví dụ thực tế, tôi nhận ra tầm quan trọng của business-first approach, luôn bắt đầu từ nhu cầu kinh doanh thay vì chỉ tập trung vào công nghệ. Bài học rút ra Việc áp dụng DDD và event-driven patterns giúp giảm coupling, tăng scalability và resilience cho hệ thống. Chiến lược hiện đại hóa cần phased approach và đo lường ROI, không nên vội vàng chuyển đổi toàn bộ hệ thống. Các công cụ AI như Amazon Q Developer có thể boost productivity nếu được tích hợp vào workflow phát triển hiện tại. Một số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của các bạn tại đây Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy về thiết kế ứng dụng, hiện đại hóa hệ thống và phối hợp hiệu quả hơn giữa các team.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.1-workshop-overview/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu về VPC Endpoint Điểm cuối VPC (endpoint) là thiết bị ảo. Chúng là các thành phần VPC có thể mở rộng theo chiều ngang, dự phòng và có tính sẵn sàng cao. Chúng cho phép giao tiếp giữa tài nguyên điện toán của bạn và dịch vụ AWS mà không gây ra rủi ro về tính sẵn sàng. Tài nguyên điện toán đang chạy trong VPC có thể truy cập Amazon S3 bằng cách sử dụng điểm cuối Gateway. Interface Endpoint PrivateLink có thể được sử dụng bởi tài nguyên chạy trong VPC hoặc tại TTDL. Tổng quan về workshop Trong workshop này, bạn sẽ sử dụng hai VPC.\n\u0026ldquo;VPC Cloud\u0026rdquo; dành cho các tài nguyên cloud như Gateway endpoint và EC2 instance để kiểm tra. \u0026ldquo;VPC On-Prem\u0026rdquo; mô phỏng môi trường truyền thống như nhà máy hoặc trung tâm dữ liệu của công ty. Một EC2 Instance chạy phần mềm StrongSwan VPN đã được triển khai trong \u0026ldquo;VPC On-prem\u0026rdquo; và được cấu hình tự động để thiết lập đường hầm VPN Site-to-Site với AWS Transit Gateway. VPN này mô phỏng kết nối từ một vị trí tại TTDL (on-prem) với AWS cloud. Để giảm thiểu chi phí, chỉ một phiên bản VPN được cung cấp để hỗ trợ workshop này. Khi lập kế hoạch kết nối VPN cho production workloads của bạn, AWS khuyên bạn nên sử dụng nhiều thiết bị VPN để có tính sẵn sàng cao. "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/1-worklog/",
	"title": "Nhật ký công việc",
	"tags": [],
	"description": "",
	"content": "Trong trang này bạn sẽ cần giới thiệu worklog của bạn như thế nào? Bạn hoàn thành chương trình trong vòng bao nhiêu tuần? Bạn đã làm gì trong các tuần đó?\nThông thường và cũng là tiêu chuẩn, một worklog được thực hiện trong khoảng 3 tháng (trong suốt thời gian thực tập) với nội dung các tuần như sau:\nTuần 1: Định hướng, thiết lập môi trường và giới thiệu FCJ\nTuần 2: Onboarding đội, đọc nội quy đơn vị và làm quen dự án ban đầu\nTuần 3: Tìm hiểu các nhóm dịch vụ AWS (Compute, Storage, Networking, Database) và khái niệm nền tảng\nTuần 4: Tạo tài khoản AWS Free Tier, cấu hình AWS CLI và thực hành EC2 cơ bản\nTuần 5: Lập kế hoạch tích hợp AI, công việc liên quan MSSQL và cập nhật thiết kế dự án\nTuần 6: Triển khai Cognito, làm việc với Spring Data JPARepository và sửa lỗi backend\nTuần 7: Di chuyển từ RDS SQL Server sang DynamoDB và triển khai CRUD cho admin\nTuần 8: Chuẩn bị kiểm tra OJT và hoàn thành chuyên môn Coursera\nTuần 9: Tiếp tục migration DynamoDB, cải thiện admin CRUD, và thực hành lệnh Linux/EC2\nTuần 10: Triển khai CRUD phía người dùng, họp tại Phuc Long và prototype tích hợp Chatbot Bedrock\nTuần 11: Thêm luồng thanh toán thẻ tín dụng và tham dự AWS Cloud Mastery Series (Bitexco)\nTuần 12: Rà soát lỗi dự án, triển khai backend/database/frontend lên AWS và chuẩn bị demo\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.3-s3-vpc/5.3.1-create-gwe/",
	"title": "Tạo một Gateway Endpoint",
	"tags": [],
	"description": "",
	"content": " Mở Amazon VPC console Trong thanh điều hướng, chọn Endpoints, click Create Endpoint: Bạn sẽ thấy 6 điểm cuối VPC hiện có hỗ trợ AWS Systems Manager (SSM). Các điểm cuối này được Mẫu CloudFormation triển khai tự động cho workshop này.\nTrong Create endpoint console: Đặt tên cho endpoint: s3-gwe Trong service category, chọn aws services Trong Services, gõ \u0026ldquo;s3\u0026rdquo; trong hộp tìm kiếm và chọn dịch vụ với loại gateway Đối với VPC, chọn VPC Cloud từ drop-down menu. Đối với Route tables, chọn bảng định tuyến mà đã liên kết với 2 subnets (lưu ý: đây không phải là bảng định tuyến chính cho VPC mà là bảng định tuyến thứ hai do CloudFormation tạo). Đối với Policy, để tùy chọn mặc định là Full access để cho phép toàn quyền truy cập vào dịch vụ. Bạn sẽ triển khai VPC endpoint policy trong phần sau để chứng minh việc hạn chế quyền truy cập vào S3 bucket dựa trên các policies. Không thêm tag vào VPC endpoint. Click Create endpoint, click x sau khi nhận được thông báo tạo thành công. "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/1-worklog/1.1-week1/",
	"title": "Worklog Tuần 1",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 1: Làm quen với các thành viên First Cloud Journey. Ghi chú về quy định FCJ và các công nghệ AWS cơ bản cùng Spring Boot. Các công việc cần thực hiện trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Làm quen với các thành viên FCJ - Đọc và ghi chú quy định, nội quy tại đơn vị thực tập 09/08/2025 09/08/2025 3 - Tạo tài khoản AWS và cài đặt INTELJI cho Spring Boot 09/09/2025 09/09/2025 4 - Tìm hiểu các dịch vụ AWS cơ bản:\n+ Database\n+ EC2 - Tìm hiểu các cổng RESTFUL API đơn giản trong Spring Boot:\n+ POST\n+ GET\n+ PATCH(PUT) + DELETE 09/10/2025 09/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu cách kiểm soát chi phí trên AWS để tránh lãng phí và tìm hiểu về phụ thuộc Microsoft SQL Server trong Spring Boot 09/11/2025 09/11/2025 https://cloudjourney.awsstudygroup.com/ 6 Thực hành:\n+ Khởi tạo một EC2 instance bằng AWS Management Console.\n+ Cấu hình loại máy, AMI, key pair, và security group.\n+ Thực hành với EC2 và các khái niệm EBS. 09/12/2025 09/12/2025 https://cloudjourney.awsstudygroup.com/ Thành tựu tuần 1: Hiểu AWS là gì và nắm được các dịch vụ cơ bản: Lưu trữ (Storage) Mạng (Networking) Cơ sở dữ liệu (Database) Đã tạo và cấu hình tài khoản AWS, cũng như cài đặt INTELJI cho Spring Boot. Làm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ qua giao diện web. Đã xây dựng một dự án Spring Boot đơn giản để làm quen với API "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/1-worklog/1.2-week2/",
	"title": "Worklog Tuần 2",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 2: Thảo luận và thống nhất ý tưởng/phạm vi dự án cùng nhóm. Lựa chọn ngôn ngữ lập trình/ngăn xếp công nghệ cho dự án. Học MS SQL cơ bản (cài đặt, lược đồ/bảng, CRUD, truy vấn đơn giản). Thực hành cài đặt dependency và thiết lập môi trường dự án. Các công việc cần triển khai trong tuần này: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và ghi chú nội quy, quy định của đơn vị thực tập - Thảo luận nhóm: ý tưởng \u0026amp; phạm vi dự án - Chọn ngôn ngữ/ngăn xếp công nghệ - Nền tảng bảo mật: xác thực vs ủy quyền, least privilege, MFA, thói quen mật khẩu 09/16/2025 09/16/2025 3 - Học các khái niệm bảo mật cốt lõi (Bảo mật mạng): + Kiến thức TCP/IP \u0026amp; cổng phổ biến + Cơ bản về tường lửa và VPN + Tổng quan IDS/IPS + Phân đoạn mạng 09/17/2025 09/17/2025 4 - Công cụ \u0026amp; thực hành bảo mật: + Cơ bản hardening hệ điều hành (Windows/Linux) + Cấu hình tường lửa/antivirus cục bộ + Thiết lập trình quản lý mật khẩu - Thực hành (Java): + Quản lý dependency an toàn với Maven/Gradle (pin version, kiểm tra checksum) + Khởi tạo khung xương dự án Java + Dùng application.properties/.yaml cho cấu hình và không commit bí mật (gitignore) 09/18/2025 09/18/2025 5 - Nền tảng bảo mật cơ sở dữ liệu: + Nguyên tắc đặc quyền tối thiểu (vai trò/quyền) + Phòng chống SQL injection (truy vấn tham số hóa) + Mã hóa khi truyền/tồn trữ cơ bản + Thiết kế ERD đơn giản có xét đến bảo mật 09/19/2025 09/19/2025 6 - Thực hành (secure coding, Java): + Thêm driver JDBC MS SQL (mssql-jdbc) và cấu hình DataSource + Thêm JPA/Hibernate hoặc MyBatis và hiện thực CRUD tham số hóa + Xác thực đầu vào (Jakarta Validation) \u0026amp; xử lý ngoại lệ + Quản lý bí mật (biến môi trường/thuộc tính hệ thống; không đưa bí mật vào mã nguồn) + Phân tích tĩnh/định dạng: SpotBugs, Checkstyle (hoặc SonarLint); ghi lại phát hiện 09/19/2025 09/19/2025 Kết quả đạt được tuần 2: Đã thống nhất ý tưởng/phạm vi dự án và chọn ngôn ngữ/ngăn xếp công nghệ (Java).\nĐã học MS SQL cơ bản:\nCài đặt và thiết lập môi trường (ví dụ: SQL Server/SSMS hoặc công cụ tương đương) Tạo cơ sở dữ liệu và bảng Viết truy vấn CRUD cơ bản và JOIN đơn giản Đã thực hành quản lý dependency cho Java; khởi tạo skeleton dự án; cấu hình kết nối MS SQL an toàn (chuỗi kết nối qua biến môi trường); thêm driver JDBC và ORM.\nĐã áp dụng các nguyên tắc bảo mật nền tảng: xác thực/ủy quyền, nguyên tắc đặc quyền tối thiểu, quản lý bí mật; chạy phân tích tĩnh với SpotBugs/Checkstyle/SonarLint và ghi nhận phát hiện.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/1-worklog/1.3-week3/",
	"title": "Worklog Tuần 3",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 3: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Ôn lại React và các component cơ bản + Functional Components + Class Components + Props và State + Event Handling + Component Lifecycle 09/22/2025 09/22/2025 3 - Học TypeScript về interface, type, class + Khai báo interface và type aliases + Generic types + Union và intersection types + Class inheritance và access modifiers 09/23/2025 09/23/2025 4 - Học TypeScript về data tĩnh và các khái niệm liên quan + Static properties và methods + Readonly properties + Enum types + Utility types (Partial, Required, Pick) 09/24/2025 09/24/2025 5 - Thảo luận về dự án bán quần áo tên FFF + Phân tích requirements và user stories + Thiết kế UI/UX mockup + Lựa chọn tech stack cho frontend + Planning sprint và timeline 09/25/2025 09/25/2025 6 - Được phân công làm frontend cho dự án FFF + Setup development environment + Khởi tạo React project với TypeScript + Cài đặt dependencies cần thiết + Tạo component structure cơ bản 09/26/2025 09/26/2025 Kết quả đạt được tuần 3: Ôn tập React thành công:\nNắm vững Functional Components và Class Components Hiểu rõ cách sử dụng Props và State management Thành thạo Event Handling trong React Nắm được Component Lifecycle và các hooks cơ bản Học TypeScript cơ bản:\nKhai báo và sử dụng interface, type aliases Hiểu và áp dụng Generic types Nắm vững Union và intersection types Sử dụng Class inheritance và access modifiers Nâng cao kiến thức TypeScript:\nSử dụng Static properties và methods Hiểu Readonly properties và immutability Làm việc với Enum types Áp dụng Utility types (Partial, Required, Pick) Tham gia dự án FFF:\nPhân tích được requirements và user stories Tham gia thiết kế UI/UX mockup Đóng góp ý kiến cho việc lựa chọn tech stack frontend Lên kế hoạch sprint và timeline chi tiết Chuẩn bị môi trường phát triển:\nSetup development environment hoàn chỉnh Khởi tạo React project với TypeScript configuration Cài đặt và cấu hình các dependencies cần thiết Tạo component structure và folder organization Sẵn sàng bắt đầu phát triển frontend cho dự án FFF "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/1-worklog/1.4-week4/",
	"title": "Worklog Tuần 4",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 4: Học và thực hành về security trong AWS. Tìm hiểu, trải nghiệm dịch vụ Lightsail. Thiết kế và hoàn thiện UI bằng React Vite. Kết nối UI React Vite với backend Spring Boot. Tích hợp backend Spring Boot với cơ sở dữ liệu MSSQL. Nắm vững quy trình kết nối frontend-backend-database và kiểm thử toàn bộ luồng dữ liệu. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Học về security trong AWS - Tìm hiểu dịch vụ Lightsail - Bắt đầu thiết kế UI với React Vite 09/29/2025 09/29/2025 3 - Tiếp tục hoàn thiện UI React Vite - Tìm hiểu kết nối backend Spring Boot 09/30/2025 09/30/2025 4 - Kết nối UI React Vite với backend Spring Boot - Tìm hiểu tích hợp MSSQL 10/01/2025 10/01/2025 5 - Hoàn thiện kết nối backend Spring Boot với MSSQL - Test toàn bộ luồng kết nối 10/02/2025 10/02/2025 6 - Tổng kết, hoàn thiện UI/UX - Viết tài liệu hướng dẫn sử dụng - Ôn tập lại security và Lightsail 10/03/2025 10/03/2025 Kết quả đạt được tuần 4: Đã học và hiểu về security trong AWS, nắm được các khái niệm cơ bản về bảo mật cloud. Đã tìm hiểu và thực hành với dịch vụ Lightsail của AWS. Hoàn thành UI bằng React Vite, giao diện thân thiện và hiện đại. Kết nối thành công UI React Vite với backend Spring Boot. Tích hợp backend Spring Boot với cơ sở dữ liệu MSSQL, kiểm thử thành công toàn bộ luồng dữ liệu. Viết tài liệu hướng dẫn sử dụng và tổng kết lại các kiến thức đã học trong tuần. "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/1-worklog/1.5-week5/",
	"title": "Worklog Tuần 5",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 5: Thảo luận với nhóm về chiến lược tích hợp AI thông qua kết nối API. Hoàn thiện việc triển khai cơ sở dữ liệu với MSSQL cho hệ thống dự án. Chuẩn bị toàn diện cho kỳ thi giữa kỳ kiến thức AWS. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Họp nhóm thảo luận về tích hợp AI - Nghiên cứu các API AI phù hợp cho hệ thống - Xác định điểm tích hợp và kiến trúc luồng dữ liệu 10/06/2025 10/06/2025 3 - Thiết kế schema cơ sở dữ liệu MSSQL - Tạo và cấu hình các bảng với quan hệ phù hợp - Kiểm tra kết nối cơ sở dữ liệu 10/07/2025 10/07/2025 4 - Triển khai các thao tác CRUD với MSSQL - Tích hợp cơ sở dữ liệu vào hệ thống hiện tại - Kiểm tra và tối ưu hóa hiệu năng 10/08/2025 10/08/2025 5 - Ôn tập các dịch vụ AWS cốt lõi (EC2, S3, RDS, Lambda, IAM) - Học khái niệm mạng AWS và VPC - Thực hành AWS CLI và automation scripts 10/09/2025 10/09/2025 6 - Hoàn thiện việc chuẩn bị thi AWS - Làm đề thi thử và đánh giá kiến thức - Tổng kết và kiểm tra lại tích hợp AI và cơ sở dữ liệu 10/10/2025 10/10/2025 Kết quả đạt được tuần 5: Thành công trong việc thực hiện các cuộc thảo luận nhóm về chiến lược tích hợp AI:\nXác định được các API AI phù hợp để nâng cao hệ thống Định nghĩa điểm tích hợp và kiến trúc luồng dữ liệu Thiết lập timeline cho các giai đoạn triển khai AI Nghiên cứu yêu cầu xác thực và bảo mật cho API AI Hoàn thành việc triển khai cơ sở dữ liệu MSSQL một cách toàn diện:\nThiết kế và triển khai schema cơ sở dữ liệu được chuẩn hóa Tạo thành công tất cả các bảng cần thiết với quan hệ phù hợp Thiết lập kết nối cơ sở dữ liệu với connection pooling Triển khai và kiểm tra đầy đủ các thao tác CRUD Tích hợp cơ sở dữ liệu một cách liền mạch với các thành phần hệ thống hiện có Chuẩn bị kỹ lưỡng cho kỳ thi giữa kỳ AWS:\nNắm vững các dịch vụ AWS cốt lõi (EC2, S3, RDS, Lambda, IAM) Hiểu các khái niệm mạng AWS bao gồm VPC, subnet và security group Thực hành AWS CLI commands và automation scripts Nghiên cứu mô hình giá cả AWS và chiến lược tối ưu hóa chi phí Hoàn thành nhiều đề thi thử với mức độ tự tin cao Nâng cao kỹ năng phát triển dự án:\nCải thiện kỹ thuật thiết kế và tối ưu hóa cơ sở dữ liệu Tăng cường kiến thức về tích hợp API và kiến trúc hệ thống Phát triển hiểu biết tốt hơn về các mẫu ứng dụng cloud-native "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/1-worklog/1.6-week6/",
	"title": "Worklog Tuần 6",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 6: Học và thực hành Amazon Cognito (User Pool, App Client, luồng xác thực). Tìm hiểu Spring Data JpaRepository cho CRUD, phương thức truy vấn và phân trang. Thảo luận và chốt các dịch vụ AWS sẽ dùng cho dự án cùng cả nhóm. Chẩn đoán và khắc phục lỗi HTTP 500 của API backend Spring Boot. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu Amazon Cognito cơ bản (User Pool, App Client, domain) - Thử luồng đăng ký/đăng nhập bằng Hosted UI hoặc SDK - Kiểm tra ID/Access token và xác minh chữ ký JWT 10/13/2025 10/13/2025 https://docs.aws.amazon.com/cognito/ 3 - Triển khai Spring Data JpaRepository cho các entity chính - Thêm phương thức truy vấn, Pageable và sắp xếp - Viết unit test cho CRUD của repository 10/14/2025 10/14/2025 https://docs.spring.io/spring-data/jpa/reference/ 4 - Họp nhóm: chọn dịch vụ AWS cho dự án (Cognito, API Gateway/ALB, RDS for SQL Server, S3, CloudWatch) - Phác thảo sơ đồ kiến trúc tổng quan và luồng dữ liệu 10/15/2025 10/15/2025 https://wa.aws.amazon.com/ 5 - Tái hiện lỗi 500 của backend Spring Boot - Thêm logging và xử lý ngoại lệ (@ControllerAdvice) - Sửa các trường hợp null/validation ở service/repository, trả mã trạng thái đúng 10/16/2025 10/16/2025 https://docs.spring.io/spring-boot/reference/web/servlet.html#web.servlet.spring-mvc.exception-handling 6 - Thêm integration test cho API quan trọng - Kiểm tra phản hồi 2xx/4xx bằng Postman/newman - Cập nhật README và health checks/monitoring 10/17/2025 10/17/2025 https://spring.io/guides/gs/testing-web/ Kết quả đạt được tuần 6: Amazon Cognito: thiết lập và xác thực luồng đăng nhập\nTạo User Pool và App Client; cấu hình chính sách mật khẩu và (tuỳ chọn) MFA Thử đăng ký/đăng nhập bằng Hosted UI/SDK và lấy ID/Access token Xác minh JWT qua JWKs endpoint; xác nhận scope và claims cho truy cập API Spring Data JPA: triển khai repository và cải thiện lớp truy cập dữ liệu\nXây dựng repository mở rộng JpaRepository với phương thức truy vấn suy luận và phân trang Viết unit test cho CRUD, đảm bảo tính nhất quán giao dịch Giảm boilerplate và cải thiện khả năng đọc của tầng dữ liệu Quyết định của nhóm về dịch vụ AWS cho dự án\nChọn Cognito cho xác thực, Amazon RDS for SQL Server cho dữ liệu quan hệ, S3 cho lưu trữ đối tượng Cân nhắc API Gateway so với ALB cho định tuyến; lựa chọn dựa trên nhu cầu tích hợp hiện tại Lập kế hoạch giám sát với CloudWatch và log có cấu trúc cho API Khắc phục lỗi HTTP 500 của backend Spring Boot và tăng cường xử lý lỗi\nXác định nguyên nhân gốc (xử lý null, validation, ngoại lệ chưa bắt) qua log và trace Thêm xử lý ngoại lệ toàn cục với @ControllerAdvice và phản hồi lỗi nhất quán Áp dụng kiểm tra đầu vào (@Valid) và ánh xạ mã trạng thái đúng với ResponseEntity Tạo integration test để ngăn hồi quy; xác thực endpoint trả 2xx/4xx chính xác "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/1-worklog/1.7-week7/",
	"title": "Worklog Tuần 7",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 7: Di chuyển cơ sở dữ liệu dự án từ SQL Server sang DynamoDB do chi phí vận hành cao. Ôn tập dịch vụ AWS và kiến trúc trong chương trình OJT. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Phân tích chi phí vận hành SQL Server và các chỉ số hiệu năng - Nghiên cứu mô hình giá DynamoDB và so sánh chi phí - Quyết định chuyển sang DynamoDB và ghi nhận lý do 10/20/2025 10/20/2025 https://aws.amazon.com/dynamodb/pricing/ 3 - Thiết kế cấu trúc bảng DynamoDB (partition/sort keys, GSI) - Lập kế hoạch di chuyển dữ liệu từ SQL Server sang DynamoDB - Tạo bảng DynamoDB trong AWS console 10/21/2025 10/21/2025 https://docs.aws.amazon.com/dynamodb/ 4 - Triển khai script/tool di chuyển dữ liệu (AWS DMS hoặc tùy chỉnh) - Thực hiện di chuyển và xác thực tính toàn vẹn dữ liệu - Cập nhật code ứng dụng để sử dụng DynamoDB SDK 10/22/2025 10/22/2025 https://docs.aws.amazon.com/dynamodb/latest/developerguide/ 5 - Ôn tập tất cả dịch vụ AWS sử dụng trong dự án (Cognito, API Gateway, S3, CloudWatch) - Phân tích kiến trúc hiện tại và xác định cơ hội tối ưu hóa - Tham gia các buổi OJT và đào tạo thực hành 10/23/2025 10/23/2025 https://aws.amazon.com/architecture/well-architected-framework/ 6 - Thực hiện ôn tập kiến trúc cuối cùng với nhóm - Luyện tập tình huống OJT và bài tập thực hành - Chuẩn bị tài liệu OJT và phản hồi 10/24/2025 10/24/2025 https://aws.amazon.com/certification/ Kết quả đạt được tuần 7: Thành công di chuyển cơ sở dữ liệu dự án từ SQL Server sang DynamoDB\nPhân tích chi phí SQL Server và xác định tiết kiệm đáng kể với giá theo nhu cầu của DynamoDB Thiết kế bảng DynamoDB với partition/sort keys và Global Secondary Indexes phù hợp Thực hiện di chuyển dữ liệu bằng AWS Database Migration Service, đảm bảo 100% tính toàn vẹn dữ liệu Cập nhật code ứng dụng để sử dụng DynamoDB SDK, đạt chuyển đổi liền mạch Ôn tập toàn diện dịch vụ AWS và kiến trúc\nĐánh giá việc sử dụng dịch vụ AWS hiện tại (Cognito cho xác thực, API Gateway cho định tuyến, S3 cho lưu trữ, CloudWatch cho giám sát) Xác định cơ hội tối ưu hóa kiến trúc bao gồm reserved instances và auto-scaling Tham gia tích cực vào chương trình OJT với đào tạo thực hành và bài tập thực tế Phát triển hiểu biết vững chắc về dịch vụ AWS thông qua ứng dụng thực tế Tối ưu hóa chi phí và cải thiện kiến trúc\nĐạt tiết kiệm chi phí ước tính 60-70% bằng cách chuyển sang DynamoDB từ SQL Server Nâng cao khả năng mở rộng và hiệu năng hệ thống với thiết kế cơ sở dữ liệu NoSQL Tăng cường hiểu biết về các nguyên tắc AWS Well-Architected Framework Cải thiện khả năng của nhóm trong việc đưa ra quyết định dựa trên dữ liệu cho hạ tầng đám mây "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/1-worklog/1.8-week8/",
	"title": "Worklog Tuần 8",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 8: Chuẩn bị cho kỳ thi OJT thông qua các buổi học nhóm và ôn tập câu hỏi. Hoàn thành khóa học Coursera: Phương pháp nghiên cứu và kỹ năng viết học thuật. Đạt kết quả tốt trong kỳ thi OJT tại Bitexco Financial Tower. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Bắt đầu các buổi học nhóm để ôn tập câu hỏi thi OJT - Thảo luận các khái niệm chính và luyện tập câu hỏi mẫu - Xác định các lĩnh vực cần tập trung thêm 10/27/2025 10/27/2025 Tài liệu ôn thi OJT 3 - Tiếp tục ôn tập nhóm các câu hỏi và tình huống OJT - Làm việc qua các chủ đề khó khăn theo nhóm - Chia sẻ tiến độ học tập cá nhân và insights 10/28/2025 10/28/2025 Tài liệu ôn thi OJT 4 - Tăng cường chuẩn bị thi OJT với các buổi tập trung nhóm - Luyện tập quản lý thời gian và chiến lược làm bài - Ôn lại các điểm yếu đã xác định 10/29/2025 10/29/2025 Tài liệu ôn thi OJT 5 - Ôn tập cuối cùng nhóm và luyện thi thử - Hoàn thành các module còn lại của khóa Coursera Phương pháp nghiên cứu - Chuẩn bị tâm lý và hậu cần cho ngày thi 10/30/2025 10/30/2025 https://www.coursera.org/specializations/academic-english 6 - Tham gia thi OJT tại Bitexco Financial Tower - Hoàn thành các bài đánh giá cuối cùng của khóa Coursera - Nộp chứng chỉ khóa học và suy ngẫm về kết quả học tập 10/31/2025 10/31/2025 https://www.coursera.org/specializations/academic-english Kết quả đạt được tuần 8: Thành công hoàn thành chuẩn bị thi OJT thông qua học tập nhóm hợp tác\nTiến hành các buổi học nhóm chuyên sâu ôn tập tất cả câu hỏi và tình huống thi OJT Xác định và giải quyết các khoảng trống kiến thức thông qua thảo luận nhóm và bài tập thực hành Phát triển chiến lược làm bài hiệu quả và kỹ năng quản lý thời gian Đạt kết quả thi OJT tại Bitexco Financial Tower\nHoàn thành bài đánh giá toàn diện OJT vào ngày 31 tháng 10 năm 2025 Thể hiện năng lực thành thạo trong các lĩnh vực kỹ năng và kiến thức cần thiết Nhận được phản hồi tích cực và xác nhận tiến độ học tập Hoàn thành khóa học Coursera: Phương pháp nghiên cứu và kỹ năng viết học thuật\nHoàn thành tất cả các module khóa học bao gồm phương pháp nghiên cứu và kỹ thuật viết Áp dụng các nguyên tắc viết học thuật để cải thiện kỹ năng tài liệu và báo cáo Nhận chứng chỉ khóa học chứng minh cam kết phát triển chuyên môn Nâng cao kỹ năng làm việc nhóm và học tập\nCải thiện khả năng học tập hợp tác thông qua các buổi học nhóm Tăng cường giao tiếp và chia sẻ kiến thức trong nhóm Phát triển khả năng chuẩn bị và thể hiện tốt hơn dưới áp lực "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/1-worklog/1.9-week9/",
	"title": "Worklog Tuần 9",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 9: Di chuyển dự án từ RDS SQL Server sang DynamoDB nhằm giảm chi phí vận hành. Hoàn thiện phần quản trị (admin) với các thao tác CRUD cơ bản cho cửa hàng bán quần áo. Học các lệnh cơ bản trên Linux để vận hành EC2 Ubuntu. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Phân tích và lập kế hoạch di chuyển từ RDS SQL Server sang DynamoDB - So sánh mô hình chi phí và dự kiến tiết kiệm - Ghi chép kế hoạch di chuyển và chiến lược rollback 11/03/2025 11/03/2025 https://aws.amazon.com/dynamodb/pricing/ 3 - Thiết kế cấu trúc bảng DynamoDB (partition/sort keys, GSI) - Triển khai script di chuyển dữ liệu (AWS DMS hoặc ETL tuỳ chỉnh) - Bắt đầu di chuyển và xác thực mẫu dữ liệu 11/04/2025 11/04/2025 https://docs.aws.amazon.com/dynamodb/ 4 - Hoàn tất di chuyển và kiểm tra tính toàn vẹn dữ liệu - Cập nhật backend để sử dụng DynamoDB SDK - Giám sát hiệu năng và điều chỉnh capacity/index nếu cần 11/05/2025 11/05/2025 https://docs.aws.amazon.com/dms/latest/userguide/ 5 - Hoàn thành phần quản trị: triển khai CRUD cho sản phẩm, danh mục, đơn hàng - Viết unit và integration test cho API quản trị - Triển khai lên staging để kiểm thử 11/06/2025 11/06/2025 https://spring.io/guides/gs/accessing-data-jpa/ 6 - Học và thực hành lệnh Linux cơ bản trên EC2 Ubuntu (ssh, systemctl, journalctl, apt, quyền file) - Kiểm tra ứng dụng hoạt động trên instance và ghi chép lệnh thường dùng 11/07/2025 11/07/2025 https://linuxcommand.org/; https://help.ubuntu.com/community/UsingTheTerminal Kết quả đạt được tuần 9: Đã thành công di chuyển cơ sở dữ liệu dự án từ RDS SQL Server sang DynamoDB\nHoàn tất phân tích chi phí và xác nhận tiết kiệm vận hành đáng kể Thiết kế schema DynamoDB và thực hiện di chuyển kèm kiểm tra xác thực dữ liệu Cập nhật backend để sử dụng DynamoDB client; xác minh chức năng ứng dụng Hoàn thành phần quản trị với đầy đủ CRUD\nTriển khai tạo/đọc/cập nhật/xoá cho sản phẩm, danh mục và đơn hàng Thêm unit test và integration test cho API quản trị Triển khai các thay đổi admin lên môi trường staging để kiểm thử Nâng cao kỹ năng Linux thực hành cho EC2 Ubuntu\nSử dụng SSH để truy cập instance và quản lý dịch vụ với systemctl và journalctl Cài gói bằng apt, quản lý quyền file và kiểm tra log Ghi chép các lệnh phổ biến để vận hành EC2 ổn định Cải thiện chi phí dự án và sẵn sàng triển khai\nViệc chuyển sang DynamoDB cải thiện khả năng mở rộng và giảm chi phí dự kiến Cải thiện phần quản trị và kỹ năng Linux giúp nhóm dễ dàng vận hành và bảo trì hệ thống "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/2-proposal/",
	"title": "Bản đề xuất",
	"tags": [],
	"description": "",
	"content": "AWS First Cloud AI Journey – Project Plan Website Bán Hàng Trực tuyến: Furious Five Fashion (FFF) Giải pháp Website Bán Hàng kết hợp AWS và AI 1. Bối cảnh và động lực 1.1 tóm tắt điều hành Khách hàng là một doanh nghiệp quy mô nhỏ , chuyên cung cấp các sản phẩm về thời trang cho các bạn trẻ . Doanh nghiệp mong muốn xây dựng website online bán quần áo với AWS và AI,có khả năng mở rộng linh hoạt, đủ sức ph át triển lâu dài và tối ưu chi phí vận hành .\nVề mục tiêu , dự án này là oột bước chuyển đổi tư duy - từ quản lý thủ công trên máy chủ vật lý sang mô hình linh hoạt , thông minh và đặc biệt là phải tối ưu chi phí .AWS cho phép hệ thống có thể mở rộng bất cứ lúc nào , đảm bảo tốc độ truy cập ,và giúp doanh nghiệp tập trung vào phát triển thay vì lo lắng về hạ tầng .\nHệ thống được thiết kế để phục vụ hoạt động bán hàng trực tuyến một cách toàn diện: lưu trữ và phân phối nội dung web, quản lý cơ sở dữ liệu sản phẩm – đơn hàng, hỗ trợ thanh toán, và giám sát hiệu suất vận hành. Mọi thứ đều hướng đến sự ổn định, an toàn và dễ mở rộng trong tương lai.\nĐồng hành trong quá trình này là đội ngũ Furious Five sẽ triển khai – những người chịu trách nhiệm tư vấn, thiết kế kiến trúc và cấu hình các dịch vụ quan trọng như Lambda, S3, DynamoDB, CloudFront và Route 53. Ngoài việc dựng hệ thống, họ còn giúp tối ưu chi phí, đảm bảo bảo mật và hướng dẫn đội ngũ nội bộ quản lý hạ tầng hiệu quả.\nDự án này không chỉ là một bản kế hoạch kỹ thuật – nó là một bước khởi đầu cho hành trình trưởng thành của doanh nghiệp trong thế giới số.\n1.2 TIÊU CHÍ THÀNH CÔNG CỦA DỰ ÁN Để dự án Furious Five Fashion thực sự thành công, chúng ta cần xác định rõ những tiêu chí cụ thể, vừa phản ánh được mục tiêu kinh doanh, vừa đánh giá được hiệu quả kỹ thuật sau khi triển khai. Dưới đây là những điểm mấu chốt mà đội dự án cần đạt được:\nHiệu suất hệ thống: Trang web phải duy trì thời gian phản hồi dưới 2 giây cho mọi tác vụ người dùng, kể cả trong thời điểm cao điểm truy cập.\nTính sẵn sàng (Availability): Hệ thống đạt 99,9% uptime trong suốt quá trình vận hành, được giám sát và báo cáo tự động qua các công cụ AWS như CloudWatch.\nKhả năng mở rộng (Scalability): Hạ tầng AWS có thể mở rộng quy mô tự động khi lưu lượng truy cập tăng ít nhất gấp 2 lần mà không làm gián đoạn dịch vụ.\nTối ưu chi phí: Chi phí vận hành hàng tháng được duy trì dưới 30% ngân sách dự kiến, thông qua cơ chế giám sát và tối ưu tài nguyên (Cost Explorer, Trusted Advisor).\nBảo mật hệ thống: Không có sự cố rò rỉ dữ liệu hoặc truy cập trái phép. Tất cả dữ liệu khách hàng được mã hóa bằng các tiêu chuẩn bảo mật của AWS (IAM policies).\nQuy trình triển khai và vận hành: Hoàn thành việc triển khai hạ tầng AWS trong 4 tuần, với tài liệu kỹ thuật và hướng dẫn vận hành rõ ràng để đội ngũ nội bộ có thể tiếp quản và quản lý hiệu quả.\nHỗ trợ và đào tạo: Đội kỹ thuật nội bộ được đào tạo đủ năng lực quản trị, giám sát và bảo trì hệ thống mà không cần phụ thuộc hoàn toàn vào bên thứ ba.\nThành công của Furious Five Fashion không chỉ nằm ở việc website hoạt động được — mà là ở chỗ nó chạy ổn định, an toàn, tiết kiệm chi phí và sẵn sàng phát triển lâu dài. Một hệ thống thành công là khi cả khách hàng và đội ngũ vận hành đều cảm thấy “an tâm” khi sử dụng nó — và đó chính là mục tiêu chúng ta hướng tới.\n1.3 Các giả định Khi bắt tay vào dự án FFF, có vài điều mà chúng ta cần thống nhất và cùng tin tưởng để mọi thứ đi đúng hướng.\nTrước hết, giả định rằng đội ngũ đều đã có tài khoản AWS và có thể truy cập đầy đủ vào các dịch vụ cần thiết. Mọi người cũng đã có chút nền tảng về AWS — ít nhất là hiểu các dịch vụ như lambda, S3, IAM, và Route 53 hoạt động ra sao. Kết nối Internet ổn định là điều kiện tiên quyết, vì toàn bộ hạ tầng của FFF đều nằm trên đám mây. Và tất nhiên, nhóm cũng cần hiểu rõ các yêu cầu về bảo mật và tuân thủ trước khi triển khai.\nDự án này không đứng một mình — nó phụ thuộc vào nhiều yếu tố. Chúng ta cần AWS hoạt động ổn định ở khu vực đã chọn, nhà cung cấp tên miền và Route 53 phải đảm bảo việc định tuyến mượt mà. Đồng thời, nhóm phát triển web cũng cần phối hợp nhịp nhàng để ứng dụng vận hành tốt trên môi trường cloud. Nói cách khác, thành công của FFF là kết quả của một tập thể biết ăn ý.\nTất nhiên, mọi thứ đều có giới hạn. Dự án này chỉ nằm trong phạm vi thực tập, nên ngân sách không nhiều — ưu tiên sử dụng Free Tier hoặc gói chi phí thấp.Nhóm chưa có quá nhiều kinh nghiệm, vậy nên ta chọn mô hình triển khai đơn giản và dễ quản lý. Thời gian lại ngắn, nên điều quan trọng là giữ mọi thứ thực tế và khả thi.\nVề rủi ro, có vài điều đáng để cảnh giác. Sai sót nhỏ trong cấu hình IAM có thể khiến hệ thống dễ bị tấn công. Nếu quên tắt tài nguyên sau khi thử nghiệm, chi phí có thể tăng lên nhanh chóng. Cũng có lúc AWS gặp sự cố vùng (region outage), và điều đó nằm ngoài tầm kiểm soát của chúng ta. Ngoài ra, đôi khi ứng dụng không tương thích hoàn toàn với dịch vụ AWS, hoặc đơn giản là ta thiếu người có kinh nghiệm xử lý sự cố.\nDẫu vậy, tin tưởng rằng chúng ta đang đi đúng hướng. Mọi thứ đều được xây dựng trên nền tảng giả định rằng khách hàng hiểu rõ đây là phiên bản thử nghiệm (pilot), và chúng ta luôn có giải pháp sao lưu, giám sát và quản lý chi phí cẩn thận. Quan trọng nhất, mỗi rủi ro đều là một bài học quý — giúp ta trưởng thành hơn trong hành trình học cloud và triển khai thật sự.\n2 KIẾN TRÚC GIẢI PHÁP / SƠ ĐỒ KIẾN TRÚC 2.1 Sơ đồ Kiến trúc Kỹ thuật Dưới đây là kiến trúc kỹ thuật được thiết kế cho dự án FFF, triển khai trên AWS Cloud – Region Singapore (ap-southeast-1). Mục tiêu của kiến trúc này là đảm bảo hệ thống linh hoạt, bảo mật, tự động hóa cao và có khả năng mở rộng dễ dàng trong tương lai, đồng thời vẫn phù hợp với phạm vi dự án thực tập.\nHệ thống được xây dựng theo mô hình đa tầng gồm 6 phần chính :\nFrontend \u0026amp; Security Layer: Người dùng truy cập thông qua Route 53, lưu lượng được bảo vệ bởi AWS WAF và phân phối nhanh bằng CloudFront. Mã nguồn được quản lý và triển khai tự động qua GitLab và CloudFormation.\nAPI \u0026amp; Compute Layer: API Gateway tiếp nhận và định tuyến yêu cầu đến AWS Lambda – nơi xử lý logic ứng dụng. Cognito đảm nhận xác thực người dùng và cấp quyền truy cập API.\nStorage Layer: Gồm hai S3 Bucket: một cho dữ liệu tĩnh (StaticData) và một cho dữ liệu tải lên (Uploads).\nData Layer: DynamoDB lưu trữ thông tin phi cấu trúc và metadata. IAM quản lý quyền truy cập an toàn giữa các thành phần.\nAI Layer: Tích hợp Amazon Rekognition và Amazon Bedrock để xử lý hình ảnh và AI tạo sinh cho ứng dụng.\nObservability \u0026amp; Security Layer: CloudWatch, SNS, và SES giám sát, gửi cảnh báo và thông báo khi có sự cố; đảm bảo hệ thống vận hành ổn định.\nDưới đây là sơ đồ luồng dữ liệu : 2.2 Kế hoạch kỹ thuật Trong dự án FFF, nhóm triển khai sẽ phát triển và quản lý hạ tầng bằng các tập lệnh tự động (Infrastructure as Code) sử dụng AWS CloudFormation. Cách làm này giúp việc triển khai hệ thống lên các tài khoản AWS trở nên nhanh chóng, lặp lại và dễ kiểm soát hơn, đồng thời giảm thiểu sai sót thủ công trong quá trình cài đặt.\nCác thành phần chính của hạ tầng – bao gồm S3, Lambda, API Gateway, DynamoDB, Cognito, và CloudWatch – sẽ được định nghĩa và khởi tạo thông qua các mẫu CloudFormation. Mọi thay đổi về cấu hình sẽ được lưu lại trong GitLab để đảm bảo tính minh bạch và khả năng phục hồi nếu cần quay lại phiên bản trước.\nMột số cấu hình nhạy cảm như quyền truy cập IAM hoặc chính sách bảo mật của WAF có thể yêu cầu phê duyệt riêng trước khi triển khai. Các thay đổi này sẽ tuân thủ quy trình xem xét nội bộ, bao gồm kiểm tra, xác nhận, và phê duyệt bởi người chịu trách nhiệm kỹ thuật.\nTất cả đường dẫn quan trọng (critical paths) trong kiến trúc – từ xác thực người dùng, xử lý API đến lưu trữ dữ liệu và giám sát hệ thống – đều được bao phủ bởi kịch bản kiểm thử tự động và thủ công, đảm bảo tính ổn định, an toàn và khả năng mở rộng của giải pháp.\nKế hoạch kỹ thuật này giúp đội FFF không chỉ triển khai hiệu quả, mà còn học được cách vận hành một hệ thống cloud chuyên nghiệp – từng dòng script đều là một bước tiến tới tư duy kỹ sư thực thụ.\n2.3 KẾ HOẠCH DỰ ÁN Dự án FFF được triển khai theo khung Agile Scrum, trong 3 tháng, chia thành 4 sprint. Phương pháp này giúp nhóm duy trì nhịp độ làm việc ổn định, phản hồi nhanh với thay đổi kỹ thuật và tối ưu hóa kết quả qua từng giai đoạn.\nCấu trúc triển khai:\nSprint Planning:\nthiết lập các môi trường AWS cơ bản (S3, Route53,IAm ). cấu hình dịch vụ bảo mật (AWS WAF, CloudFront). Tích hợp các thành phần backend (Lambda, API Gateway, DynamoDB) Kiểm thử hệ thống, tối ưu hiệu năng, và triển khai bản demo cuối. Daily Stand-up: Cập nhật tiến độ, xử lý trở ngại kỹ thuật trong 30 phút mỗi ngày.\nSprint Review: Đánh giá kết quả sprint, trình bày bản demo trên môi trường AWS thật , nếu sai sót sẽ sửa đổi.\nRetrospective: Phân tích rút kinh nghiệm, tối ưu quy trình DevOps và tự động hóa triển khai.\nPhân công trách nhiệm:\nProduct Owner: Quản lý backlog, định hướng ưu tiên tính năng và mốc kỹ thuật.(Dương Minh Đức)\nScrum Master: Điều phối sprint, đảm bảo tuân thủ quy trình Agile và loại bỏ trở ngại.(Quách Nguyễn Chí Hùng)\nDevOps/Technical Team: Phát triển, kiểm thử, triển khai hạ tầng qua CloudFormation và quản lý tài nguyên AWS.(Nguyễn Tấn Xuân )\nMentor / AWS Partner: Giám sát kỹ thuật, đánh giá tuân thủ AWS Well-Architected Framework,kiểm thử AI , hỗ trợ bảo mật và chi phí.(Hải Đăng , Phạm Lê Huy Hoàng)\nNhịp độ giao tiếp:\nDaily Stand-up: Họp ngắn 30 phút mỗi ngày, diễn ra vào khoảng 23:00\nWeekly Sync: Báo cáo tiến độ và rủi ro kỹ thuật.\nEnd-of-Sprint Review: Tổng kết và xác nhận sản phẩm tạm thời.\nChuyển giao kiến thức (Knowledge Transfer): Sau sprint cuối, nhóm đối tác kỹ thuật sẽ tổ chức phiên Knowledge Transfer để hướng dẫn vận hành hệ thống, giám sát chi phí (AWS Budgets, CloudWatch), quy trình mở rộng môi trường , sao lưu và khôi phục . Các tài liệu Knowledge Transfer sẽ được bàn giao cho nhóm để đảm bảo nhóm FFF có thể tự tin duy trì ,tối ưu .\n2.4 CÁC CÂN NHẮC VỀ BẢO MẬT Quản lý truy cập (Access Management) Nhóm chỉ sử dụng một số tài khoản AWS chính, vì vậy MFA (xác thực đa yếu tố) sẽ được bật cho toàn bộ người dùng có quyền quản trị. Quyền truy cập được phân tách rõ qua IAM User và IAM Role, theo nguyên tắc ít quyền nhất (Least Privilege). Tất cả thao tác quản trị đều được ghi nhận qua CloudTrail để dễ theo dõi và kiểm soát.\nAn ninh cơ sở hạ tầng (Infrastructure Security) Mặc dù không triển khai VPC riêng, các dịch vụ AWS (như S3, Lambda, API Gateway) vẫn được cấu hình để giới hạn truy cập chỉ từ các thành phần nội bộ của hệ thống. Các endpoint công khai đều yêu cầu kết nối qua HTTPS.\nBảo vệ dữ liệu (Data Protection) Dữ liệu được lưu trữ trên S3 và DynamoDB, với các tùy chọn mã hóa tích hợp sẵn của dịch vụ. Dữ liệu truyền giữa các thành phần (Lambda ↔ API ↔ Database) luôn đi qua giao thức HTTPS/TLS, đảm bảo an toàn khi trao đổi. Ngoài ra, nhóm thiết lập sao lưu thủ công định kỳ cho dữ liệu quan trọng, giúp khôi phục nhanh nếu có sự cố.\nPhát hiện và giám sát (Detection \u0026amp; Monitoring) CloudTrail, Config và CloudWatch sẽ luôn ghi lại mọi hành động, giúp ta biết chính xác điều gì đang diễn ra. GuardDuty sẽ liên tục quét, cảnh báo sớm nếu phát hiện hành vi bất thường.\nQuản lý sự cố (Incident Response) Nhóm sẽ xây dựng quy trình phản ứng sự cố rõ ràng, ghi nhận log, phân tích và khắc phục kịp thời. Quan trọng hơn, chúng ta sẽ diễn tập định kỳ, để khi rủi ro thật sự đến, không ai hoảng loạn – mà hành động đúng, nhanh và chắc.\n3. CÁC HOẠT ĐỘNG VÀ SẢN PHẨM BÀN GIAO 3.1 Các hoạt động và sản phẩm bàn giao Bảng dưới đây sẽ tổng hợp các mốc thời gian, hoạt động và sản phẩm bàn giao tương ứng với các mục trong Phạm vi Công việc / Kế hoạch Kỹ thuật của Dự án. Đồng thời, nêu rõ kế hoạch quản lý dự án, quản lý thay đổi, truyền thông và chuyển đổi.\nGiai đoạn dự án Mốc thời gian Hoạt động Sản phẩm bàn giao/mốc quan trọng tổng số ngày công thiết lập cơ sở hạ tầng tuần 1 - 2 - thu thập và xác nhận yêu cầu doanh nghiệp - Thiết kế kiến trúc kỹ thuật AWS - Cấu hình hạ tầng AWS (S3, CloudFront, API Gateway, Lambda, DynamoDB, Cognito) - Thiết lập GitLab CI/CD pipeline. - Kiến trúc kỹ thuật AWS hoàn chỉnh - Hạ tầng cơ sở sẵn sàng - GitLab CI/CD hoạt động. 10 ngày Thiết lập thành phần 1 (Frontend) Tuần 3 – 5 - Thiết kế UI/UX - Phát triển giao diện website: trang chủ, danh mục, chi tiết sản phẩm, giỏ hàng, thanh toán - Tích hợp với API demo. - Giao diện website hoàn thiện (bản dev) - Hệ thống FE kết nối được với API. 15 ngày Thiết lập thành phần 2 (Backend \u0026amp; Database) Tuần 6 - 9 - Xây dựng API bằng AWS Lambda + API Gateway - Thiết lập cơ sở dữ liệu DynamoDB - Xây dựng logic xử lý đơn hàng, người dùng, sản phẩm - Tích hợp bảo mật Cognito và phân quyền IAM. - API hoạt động ổn định - Dữ liệu được lưu trữ và truy xuất đúng chuẩn - Backend tích hợp hoàn chỉnh với FE. 20 ngày Kiểm thử \u0026amp; Vận hành chính thức Tuần 10 - 11 - Kiểm thử chức năng, bảo mật, hiệu năng - Ghi nhận lỗi và tối ưu hệ thống - Kiểm thử tích hợp FE – BE – DB trên môi trường AWS. - Báo cáo kết quả kiểm thử (Test Report) - Phiên bản đạt chuẩn vận hành 5 ngày Bàn giao \u0026amp; thuyết trình Tuần 12 - Triển khai production trên AWS - Thiết lập domain \u0026amp; SSL - Đào tạo quản trị hệ thống - Bàn giao mã nguồn và tài liệu kỹ thuật. - Website FFF hoạt động chính thức - Bộ tài liệu hướng dẫn \u0026amp; bàn giao hoàn chỉnh - Báo cáo bàn giao hệ thống. 5 ngày 3.2 NGOÀI PHẠM VI Các hạng mục dưới đây đã được thảo luận trong giai đoạn xác định yêu cầu, tuy nhiên được xác định là ngoài phạm vi thực hiện của dự án FFF Web quần áo ở giai đoạn hiện tại.\nCác mục ngoài phạm vi bao gồm:\nPhát triển ứng dụng di động (Mobile App) cho hệ thống (Android/iOS). Tích hợp hệ thống quản lý tồn kho, vận chuyển và logistics thực tế (Giao hàng nhanh, GHN, Viettel Post, v.v.). Chức năng quản trị nâng cao như phân quyền nhiều cấp độ, báo cáo doanh thu tự động, biểu đồ thống kê nâng cao. Tích hợp CRM (Customer Relationship Management) hoặc ERP (Enterprise Resource Planning) của bên thứ ba. Dùng các dịch vụ AWS có tính năng tự động bảo mật cao hơn , mắc tiền hơn. Tích hợp cổng thanh toán thực tế (VNPay, Momo, ZaloPay, Stripe, PayPal, v.v.) Đa ngôn ngữ (Multilingual) và đa tiền tệ (Multi-currency) 3.3 LỘ TRÌNH ĐƯA VÀO VẬN HÀNH CHÍNH THỨC Giai đoạn 1 – Làm bản thử nghiệm (POC)\nHoạt động: Xây dựng phiên bản thử nghiệm FFF Web Bán Hàng với giao diện cơ bản (Home, Danh mục, Chi tiết sản phẩm, Giỏ hàng).\nKết nối backend qua API Gateway – Lambda – DynamoDB. Triển khai website tĩnh trên Amazon S3 + CloudFront. Cấu hình tài khoản quản trị và demo quy trình đặt hàng thử. Kết quả:\nWebsite hoạt động ổn định trên môi trường AWS thử nghiệm. Toàn bộ dữ liệu sản phẩm mẫu được lưu trữ thành công trên DynamoDB. Tốc độ tải trang qua CloudFront đạt trung bình \u0026lt; 2 giây. Xác minh kết nối API và logic xử lý đặt hàng hoàn chỉnh. Giai đoạn 2 – Hoàn thiện hệ thống và kiểm thử (UAT)\nHoạt động:\nBổ sung các chức năng người dùng: đăng nhập/đăng ký, xác thực qua AWS Cognito. Thêm tính năng thanh toán thử qua sandbox. Bổ sung giám sát bằng Amazon CloudWatch và log xử lý lỗi. Thực hiện kiểm thử người dùng nội bộ (User Acceptance Test). Kết quả:\n100% chức năng cốt lõi hoạt động đúng logic. Không phát sinh lỗi nghiêm trọng trong quy trình đặt hàng. Hiệu năng trung bình đáp ứng được 100 người dùng đồng thời. Giao diện và dữ liệu hiển thị thống nhất giữa frontend và backend. Giai đoạn 3 – Triển khai vận hành chính thức (Production)\nHoạt động:\nChuyển toàn bộ hệ thống từ môi trường thử nghiệm sang Production AWS. Cấu hình Route53 cho domain chính thức và chứng chỉ SSL qua AWS Certificate Manager. Thiết lập bảo mật lớp ngoài bằng AWS WAF. Tối ưu dung lượng S3 và cấu trúc CDN trên CloudFront. Kết quả:\nWebsite chính thức FFF Web Bán Hàng hoạt động tại domain thật. Tỷ lệ uptime đạt 99.98% sau 2 tuần đầu vận hành. Độ trễ trung bình giữa client và API dưới 400ms. Mọi request được ghi nhận và giám sát theo chuẩn CloudWatch Logs. Giai đoạn 4 – Ổn định \u0026amp; tối ưu sau triển khai\nHoạt động:\nTheo dõi chi phí AWS thực tế, tối ưu dung lượng lưu trữ và log. Điều chỉnh cấu hình Lambda để giảm thời gian cold start. Thực hiện backup định kỳ và thử nghiệm khôi phục dữ liệu. Cập nhật tài liệu hướng dẫn vận hành cho nhóm quản trị. Kết quả:\nGiảm chi phí AWS trung bình 20% so với giai đoạn POC. Thời gian phản hồi API rút ngắn thêm 15%. Hệ thống hoạt động ổn định, không phát sinh lỗi nghiêm trọng. Đội ngũ vận hành nội bộ đã có thể tự theo dõi và xử lý sự cố cơ bản. Tổng kết\nHệ thống FFF Web Bán Hàng đã được triển khai thành công trên nền tảng AWS Serverless với kiến trúc tối ưu chi phí, bảo mật cao và dễ mở rộng. Các giai đoạn được hoàn thành đúng tiến độ, đảm bảo toàn bộ chức năng được kiểm thử, tinh chỉnh và vận hành ổn định. Dự án hiện đã sẵn sàng mở rộng người dùng thật và tích hợp thêm các tính năng thương mại điện tử nâng cao.\n4. CHI TIẾT CHI PHÍ AWS DỰ KIẾN THEO DỊCH VỤ Chi phí hạ tầng\nChi phí hạ tầng (ước tính theo tháng) Route 53 : $1.00 AWS WAF : $5.00 CloudFront: $3.90 S3 (StaticData) : $0.50 S3 (Uploads): $0.75 AWS Lambda: $0.25 API Gateway: $3.50 Amazon Bedrock: $3.00 DynamoDB: $1.00 IAM: Free CloudWatch: $2.00 SNS: $0.10 SES: $0.20 CloudFormation: Free GitLab CI/CD : $3.00 WS Config / Setup \u0026amp; Test migration tools $5.00 (1 lần) Tổng chi phí ước tính hàng tháng: ~ $30.00 – $35.00 USD GIẢ ĐỊNH CHÍNH\nRegion: ap-southeast-1 (Singapore). Người dùng truy cập: 500–1000/tháng. Hệ thống luôn hoạt động 24/7 nhưng tải thấp. Phần lớn API qua Lambda, không dùng EC2. Dữ liệu nhỏ (\u0026lt;100GB tổng). CI/CD thực hiện 1–2 lần deploy mỗi tuần. Free-tier còn hiệu lực trong 12 tháng đầu. AI sử dụng ở mức demo, không phải inference quy mô lớn.\nTỐI ƯU CHI PHÍ ĐỀ XUẤT\nBật S3 Intelligent-Tiering để tự động chuyển dữ liệu ít truy cập. Giới hạn CloudWatch Logs giữ lại 14–30 ngày. Dùng AWS Budgets để cảnh báo nếu vượt $40/tháng. Nếu triển khai lâu dài → cân nhắc Savings Plan cho Lambda (giảm 30–40%).\n5. Đội Ngũ Nhà tài trợ Điều hành phía Đối tác Tên : Nguyen Gia Hung Chức danh: Giám đốc chương trình Đào tạo FCJ Việt Nam Mô tả : Là Nhà tài trợ Điều hành chịu trách nhiệm giám sát tổng thể chương trình thực tập FCJ. Đảm bảo dự án mang lại giá trị học tập, tuân thủ mục tiêu kỹ thuật và định hướng nghề nghiệp của AWS Email/thông tin liên hệ : hunggia@amazon.com|\nCác bên liên quan của Dự án Tên : Van Hoang Kha Chức danh: Support Teams Mô tả: là người hỗ trợ Điều hành chịu trách nhiệm giám sát tổng thể chương trình thực tập FCJ\nEmail/Thông tin liên hệ : Khab9thd@gmail.com\nĐội ngũ Dự án phía Đối tác (Nhóm Thực tập Furious Five )\nTên : Dương Minh Đức Chức danh: Trưởng nhóm dự án\nMô tả: Quản lý tiến độ, điều phối công việc giữa nhóm và mentor,Quản lý triển khai hạ tầng AWS ( S3, Lambda, IAM)\nEmail/Thông tin liên hệ : ducdmse182938@fpt.edu.vn\nTên : Quách Nguyễn Chí Hùng\nChức danh:Thành viên\nMô tả:Phụ trách UI/UX và phần giao diện người dùng\nEmail/Thông tin liên hệ : bacon3632@gmail.com\nTên :Nguyễn Tấn Xuân\nChức danh:Thành viên\nMô tả: Phụ trách Backend và xử lý logic server\nEmail/Thông tin liên hệ : xuanntse184074@fpt.edu.vn\nTên :Nguyễn Hải Đăng\nChức danh:Thành viên\nMô tả: Quản lý triển khai hạ tầng AWS ( S3, Lambda, IAM)và tích hợp chat bot AI\nEmail/Thông tin liên hệ : dangnhse184292@fpt.edu.vn\nTên :Phạm Lê Huy Hoàng\nChức danh:Thành viên\nMô tả: Kiểm thử, đảm bảo chất lượng và tích hợp GitLab CI/CD, và tích hợp chat bot AI\nEmail/Thông tin liên hệ : hoangplhse182670@fpt.edu.vn\nLiên hệ Khiếu nại / Leo thang Dự án\nTên :Dương Minh Đức\nChức danh:Trưởng nhóm dự án\nMô tả:Đại diện nhóm thực tập liên hệ trực tiếp với mentor và nhà tài trợ\nEmail/Thông tin liên hệ : ducdmse182938@fpt.edu.vn\n6. NGUỒN LỰC \u0026amp; ƯỚC TÍNH CHI PHÍ Nguồn Lực Vai trò trách nhiệm Mức phí (USD)/Giờ Solution Architect(1) Thiết kế giải pháp tổng thể, bảo đảm tính khả thi kỹ thuật, lựa chọn dịch vụ AWS phù hợp 35 Cloud Engineer(2) Triển khai hạ tầng AWS, cấu hình dịch vụ ( S3, IAM\u0026hellip;), kiểm thử và tối ưu hệ thống 20 Project Manager (1) Theo dõi tiến độ, điều phối nhóm, quản lý phạm vi và rủi ro dự án. 15 Support / Documentation (1) Chuẩn bị tài liệu bàn giao, hướng dẫn sử dụng, và báo cáo tổng kết. 10 Ước tính chi phí theo giai đoạn dự án Giai đoạn dự án Kiến trúc sư Giải pháp (giờ) 2 Engineers (giờ) Project Manager (giờ) Quản lý dự án / Hỗ trợ (giờ) Tổng số giờ Khảo sát \u0026amp; thiết kế giải pháp 53 40 13 13 119 Triển khai \u0026amp; Kiểm thử 67 160 21 19 267 bàn giao \u0026amp; hỗ trợ 27 53 21 19 120 Tổng số giờ 147 253 55 51 506 Tổng số tiền $ 5145 $5060 $ 825 $510 $11540 Phân bổ đóng góp chi phí Bên Mức đóng góp (USD) % đóng góp Khách hàng 4616 40% Đối tác (Furious Five) 2308 20% AWS 4616 40% "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.2-prerequiste/",
	"title": "Các bước chuẩn bị",
	"tags": [],
	"description": "",
	"content": "IAM permissions Gắn IAM permission policy sau vào tài khoản aws user của bạn để triển khai và dọn dẹp tài nguyên trong workshop này.\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cloudformation:*\u0026#34;, \u0026#34;cloudwatch:*\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:AllocateAddress\u0026#34;, \u0026#34;ec2:AssociateAddress\u0026#34;, \u0026#34;ec2:AssociateIamInstanceProfile\u0026#34;, \u0026#34;ec2:AssociateRouteTable\u0026#34;, \u0026#34;ec2:AssociateSubnetCidrBlock\u0026#34;, \u0026#34;ec2:AssociateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:AssociateVpcCidrBlock\u0026#34;, \u0026#34;ec2:AttachInternetGateway\u0026#34;, \u0026#34;ec2:AttachNetworkInterface\u0026#34;, \u0026#34;ec2:AttachVolume\u0026#34;, \u0026#34;ec2:AttachVpnGateway\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:CreateClientVpnEndpoint\u0026#34;, \u0026#34;ec2:CreateClientVpnRoute\u0026#34;, \u0026#34;ec2:CreateCustomerGateway\u0026#34;, \u0026#34;ec2:CreateDhcpOptions\u0026#34;, \u0026#34;ec2:CreateFlowLogs\u0026#34;, \u0026#34;ec2:CreateInternetGateway\u0026#34;, \u0026#34;ec2:CreateLaunchTemplate\u0026#34;, \u0026#34;ec2:CreateNetworkAcl\u0026#34;, \u0026#34;ec2:CreateNetworkInterface\u0026#34;, \u0026#34;ec2:CreateNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:CreateRoute\u0026#34;, \u0026#34;ec2:CreateRouteTable\u0026#34;, \u0026#34;ec2:CreateSecurityGroup\u0026#34;, \u0026#34;ec2:CreateSubnet\u0026#34;, \u0026#34;ec2:CreateSubnetCidrReservation\u0026#34;, \u0026#34;ec2:CreateTags\u0026#34;, \u0026#34;ec2:CreateTransitGateway\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRoute\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:CreateTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:CreateVpc\u0026#34;, \u0026#34;ec2:CreateVpcEndpoint\u0026#34;, \u0026#34;ec2:CreateVpcEndpointConnectionNotification\u0026#34;, \u0026#34;ec2:CreateVpcEndpointServiceConfiguration\u0026#34;, \u0026#34;ec2:CreateVpnConnection\u0026#34;, \u0026#34;ec2:CreateVpnConnectionRoute\u0026#34;, \u0026#34;ec2:CreateVpnGateway\u0026#34;, \u0026#34;ec2:DeleteCustomerGateway\u0026#34;, \u0026#34;ec2:DeleteFlowLogs\u0026#34;, \u0026#34;ec2:DeleteInternetGateway\u0026#34;, \u0026#34;ec2:DeleteNetworkInterface\u0026#34;, \u0026#34;ec2:DeleteNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:DeleteRoute\u0026#34;, \u0026#34;ec2:DeleteRouteTable\u0026#34;, \u0026#34;ec2:DeleteSecurityGroup\u0026#34;, \u0026#34;ec2:DeleteSubnet\u0026#34;, \u0026#34;ec2:DeleteSubnetCidrReservation\u0026#34;, \u0026#34;ec2:DeleteTags\u0026#34;, \u0026#34;ec2:DeleteTransitGateway\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRoute\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:DeleteVpc\u0026#34;, \u0026#34;ec2:DeleteVpcEndpoints\u0026#34;, \u0026#34;ec2:DeleteVpcEndpointServiceConfigurations\u0026#34;, \u0026#34;ec2:DeleteVpnConnection\u0026#34;, \u0026#34;ec2:DeleteVpnConnectionRoute\u0026#34;, \u0026#34;ec2:Describe*\u0026#34;, \u0026#34;ec2:DetachInternetGateway\u0026#34;, \u0026#34;ec2:DisassociateAddress\u0026#34;, \u0026#34;ec2:DisassociateRouteTable\u0026#34;, \u0026#34;ec2:GetLaunchTemplateData\u0026#34;, \u0026#34;ec2:GetTransitGatewayAttachmentPropagations\u0026#34;, \u0026#34;ec2:ModifyInstanceAttribute\u0026#34;, \u0026#34;ec2:ModifySecurityGroupRules\u0026#34;, \u0026#34;ec2:ModifyTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:ModifyVpcAttribute\u0026#34;, \u0026#34;ec2:ModifyVpcEndpoint\u0026#34;, \u0026#34;ec2:ReleaseAddress\u0026#34;, \u0026#34;ec2:ReplaceRoute\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:RunInstances\u0026#34;, \u0026#34;ec2:StartInstances\u0026#34;, \u0026#34;ec2:StopInstances\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsEgress\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsIngress\u0026#34;, \u0026#34;iam:AddRoleToInstanceProfile\u0026#34;, \u0026#34;iam:AttachRolePolicy\u0026#34;, \u0026#34;iam:CreateInstanceProfile\u0026#34;, \u0026#34;iam:CreatePolicy\u0026#34;, \u0026#34;iam:CreateRole\u0026#34;, \u0026#34;iam:DeleteInstanceProfile\u0026#34;, \u0026#34;iam:DeletePolicy\u0026#34;, \u0026#34;iam:DeleteRole\u0026#34;, \u0026#34;iam:DeleteRolePolicy\u0026#34;, \u0026#34;iam:DetachRolePolicy\u0026#34;, \u0026#34;iam:GetInstanceProfile\u0026#34;, \u0026#34;iam:GetPolicy\u0026#34;, \u0026#34;iam:GetRole\u0026#34;, \u0026#34;iam:GetRolePolicy\u0026#34;, \u0026#34;iam:ListPolicyVersions\u0026#34;, \u0026#34;iam:ListRoles\u0026#34;, \u0026#34;iam:PassRole\u0026#34;, \u0026#34;iam:PutRolePolicy\u0026#34;, \u0026#34;iam:RemoveRoleFromInstanceProfile\u0026#34;, \u0026#34;lambda:CreateFunction\u0026#34;, \u0026#34;lambda:DeleteFunction\u0026#34;, \u0026#34;lambda:DeleteLayerVersion\u0026#34;, \u0026#34;lambda:GetFunction\u0026#34;, \u0026#34;lambda:GetLayerVersion\u0026#34;, \u0026#34;lambda:InvokeFunction\u0026#34;, \u0026#34;lambda:PublishLayerVersion\u0026#34;, \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:DeleteLogGroup\u0026#34;, \u0026#34;logs:DescribeLogGroups\u0026#34;, \u0026#34;logs:PutRetentionPolicy\u0026#34;, \u0026#34;route53:ChangeTagsForResource\u0026#34;, \u0026#34;route53:CreateHealthCheck\u0026#34;, \u0026#34;route53:CreateHostedZone\u0026#34;, \u0026#34;route53:CreateTrafficPolicy\u0026#34;, \u0026#34;route53:DeleteHostedZone\u0026#34;, \u0026#34;route53:DisassociateVPCFromHostedZone\u0026#34;, \u0026#34;route53:GetHostedZone\u0026#34;, \u0026#34;route53:ListHostedZones\u0026#34;, \u0026#34;route53domains:ListDomains\u0026#34;, \u0026#34;route53domains:ListOperations\u0026#34;, \u0026#34;route53domains:ListTagsForDomain\u0026#34;, \u0026#34;route53resolver:AssociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:AssociateResolverRule\u0026#34;, \u0026#34;route53resolver:CreateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:CreateResolverRule\u0026#34;, \u0026#34;route53resolver:DeleteResolverEndpoint\u0026#34;, \u0026#34;route53resolver:DeleteResolverRule\u0026#34;, \u0026#34;route53resolver:DisassociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:DisassociateResolverRule\u0026#34;, \u0026#34;route53resolver:GetResolverEndpoint\u0026#34;, \u0026#34;route53resolver:GetResolverRule\u0026#34;, \u0026#34;route53resolver:ListResolverEndpointIpAddresses\u0026#34;, \u0026#34;route53resolver:ListResolverEndpoints\u0026#34;, \u0026#34;route53resolver:ListResolverRuleAssociations\u0026#34;, \u0026#34;route53resolver:ListResolverRules\u0026#34;, \u0026#34;route53resolver:ListTagsForResource\u0026#34;, \u0026#34;route53resolver:UpdateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:UpdateResolverRule\u0026#34;, \u0026#34;s3:AbortMultipartUpload\u0026#34;, \u0026#34;s3:CreateBucket\u0026#34;, \u0026#34;s3:DeleteBucket\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34;, \u0026#34;s3:GetAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;s3:GetBucketOwnershipControls\u0026#34;, \u0026#34;s3:GetBucketPolicy\u0026#34;, \u0026#34;s3:GetBucketPolicyStatus\u0026#34;, \u0026#34;s3:GetBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:GetObjectVersion\u0026#34;, \u0026#34;s3:GetBucketVersioning\u0026#34;, \u0026#34;s3:ListAccessPoints\u0026#34;, \u0026#34;s3:ListAccessPointsForObjectLambda\u0026#34;, \u0026#34;s3:ListAllMyBuckets\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:ListBucketMultipartUploads\u0026#34;, \u0026#34;s3:ListBucketVersions\u0026#34;, \u0026#34;s3:ListJobs\u0026#34;, \u0026#34;s3:ListMultipartUploadParts\u0026#34;, \u0026#34;s3:ListMultiRegionAccessPoints\u0026#34;, \u0026#34;s3:ListStorageLensConfigurations\u0026#34;, \u0026#34;s3:PutAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:PutBucketAcl\u0026#34;, \u0026#34;s3:PutBucketPolicy\u0026#34;, \u0026#34;s3:PutBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;secretsmanager:CreateSecret\u0026#34;, \u0026#34;secretsmanager:DeleteSecret\u0026#34;, \u0026#34;secretsmanager:DescribeSecret\u0026#34;, \u0026#34;secretsmanager:GetSecretValue\u0026#34;, \u0026#34;secretsmanager:ListSecrets\u0026#34;, \u0026#34;secretsmanager:ListSecretVersionIds\u0026#34;, \u0026#34;secretsmanager:PutResourcePolicy\u0026#34;, \u0026#34;secretsmanager:TagResource\u0026#34;, \u0026#34;secretsmanager:UpdateSecret\u0026#34;, \u0026#34;sns:ListTopics\u0026#34;, \u0026#34;ssm:DescribeInstanceProperties\u0026#34;, \u0026#34;ssm:DescribeSessions\u0026#34;, \u0026#34;ssm:GetConnectionStatus\u0026#34;, \u0026#34;ssm:GetParameters\u0026#34;, \u0026#34;ssm:ListAssociations\u0026#34;, \u0026#34;ssm:ResumeSession\u0026#34;, \u0026#34;ssm:StartSession\u0026#34;, \u0026#34;ssm:TerminateSession\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Khởi tạo tài nguyên bằng CloudFormation Trong lab này, chúng ta sẽ dùng N.Virginia region (us-east-1).\nĐể chuẩn bị cho môi trường làm workshop, chúng ta deploy CloudFormation template sau (click link): PrivateLinkWorkshop . Để nguyên các lựa chọn mặc định.\nLựa chọn 2 mục acknowledgement Chọn Create stack Quá trình triển khai CloudFormation cần khoảng 15 phút để hoàn thành.\n2 VPCs đã được tạo 3 EC2s đã được tạo "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.3-s3-vpc/5.3.2-test-gwe/",
	"title": "Kiểm tra Gateway Endpoint",
	"tags": [],
	"description": "",
	"content": "Tạo S3 bucket Đi đến S3 management console Trong Bucket console, chọn Create bucket Trong Create bucket console Đặt tên bucket: chọn 1 tên mà không bị trùng trong phạm vi toàn cầu (gợi ý: lab\u0026lt;số-lab\u0026gt;\u0026lt;tên-bạn\u0026gt;) Giữ nguyên giá trị của các fields khác (default) Kéo chuột xuống và chọn Create bucket Tạo thành công S3 bucket Kết nối với EC2 bằng session manager Trong workshop này, bạn sẽ dùng AWS Session Manager để kết nối đến các EC2 instances. Session Manager là 1 tính năng trong dịch vụ Systems Manager được quản lý hoàn toàn bởi AWS. System manager cho phép bạn quản lý Amazon EC2 instances và các máy ảo on-premises (VMs)thông qua 1 browser-based shell. Session Manager cung cấp khả năng quản lý phiên bản an toàn và có thể kiểm tra mà không cần mở cổng vào, duy trì máy chủ bastion host hoặc quản lý khóa SSH.\nFirst cloud journey Lab để hiểu sâu hơn về Session manager.\nTrong AWS Management Console, gõ Systems Manager trong ô tìm kiếm và nhấn Enter: Từ Systems Manager menu, tìm Node Management ở thanh bên trái và chọn Session Manager: Click Start Session, và chọn EC2 instance tên Test-Gateway-Endpoint. Phiên bản EC2 này đã chạy trong \u0026ldquo;VPC cloud\u0026rdquo; và sẽ được dùng để kiểm tra khả năng kết nối với Amazon S3 thông qua điểm cuối Cổng mà bạn vừa tạo (s3-gwe).\nSession Manager sẽ mở browser tab mới với shell prompt: sh-4.2 $\nBạn đã bắt đầu phiên kết nối đến EC2 trong VPC Cloud thành công. Trong bước tiếp theo, chúng ta sẽ tạo một S3 bucket và một tệp trong đó.\nCreate a file and upload to s3 bucket Đổi về ssm-user\u0026rsquo;s thư mục bằng lệnh \u0026ldquo;cd ~\u0026rdquo; Tạo 1 file để kiểm tra bằng lệnh \u0026ldquo;fallocate -l 1G testfile.xyz\u0026rdquo;, 1 file tên \u0026ldquo;testfile.xyz\u0026rdquo; có kích thước 1GB sẽ được tạo. Tải file mình vừa tạo lên S3 với lệnh \u0026ldquo;aws s3 cp testfile.xyz s3://your-bucket-name\u0026rdquo;. Thay your-bucket-name bằng tên S3 bạn đã tạo. Bạn đã tải thành công tệp lên bộ chứa S3 của mình. Bây giờ bạn có thể kết thúc session.\nKiểm tra object trong S3 bucket Đi đến S3 console. Click tên s3 bucket của bạn Trong Bucket console, bạn sẽ thấy tệp bạn đã tải lên S3 bucket của mình Tóm tắt Chúc mừng bạn đã hoàn thành truy cập S3 từ VPC. Trong phần này, bạn đã tạo gateway endpoint cho Amazon S3 và sử dụng AWS CLI để tải file lên. Quá trình tải lên hoạt động vì gateway endpoint cho phép giao tiếp với S3 mà không cần Internet gateway gắn vào \u0026ldquo;VPC Cloud\u0026rdquo;. Điều này thể hiện chức năng của gateway endpoint như một đường dẫn an toàn đến S3 mà không cần đi qua pub lic Internet.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.4-s3-onprem/5.4.2-create-interface-enpoint/",
	"title": "Tạo một S3 Interface endpoint",
	"tags": [],
	"description": "",
	"content": "Trong phần này, bạn sẽ tạo và kiểm tra Interface Endpoint S3 bằng cách sử dụng môi trường truyền thống mô phỏng.\nQuay lại Amazon VPC menu. Trong thanh điều hướng bên trái, chọn Endpoints, sau đó click Create Endpoint.\nTrong Create endpoint console:\nĐặt tên interface endpoint Trong Service category, chọn aws services Trong Search box, gõ S3 và nhấn Enter. Chọn endpoint có tên com.amazonaws.us-east-1.s3. Đảm bảo rằng cột Type có giá trị Interface. Đối với VPC, chọn VPC Cloud từ drop-down. Đảm bảo rằng bạn chọn \u0026ldquo;VPC Cloud\u0026rdquo; và không phải \u0026ldquo;VPC On-prem\u0026rdquo;\nMở rộng Additional settings và đảm bảo rằng Enable DNS name không được chọn (sẽ sử dụng điều này trong phần tiếp theo của workshop) Chọn 2 subnets trong AZs sau: us-east-1a and us-east-1b Đối với Security group, chọn SGforS3Endpoint: Giữ default policy - full access và click Create endpoint Chúc mừng bạn đã tạo thành công S3 interface endpoint. Ở bước tiếp theo, chúng ta sẽ kiểm tra interface endpoint.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/1-worklog/1.10-week10/",
	"title": "Worklog Tuần 10",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 10: Triển khai các thao tác CRUD phía người dùng: sửa hồ sơ người dùng, thêm/xoá đơn hàng. Tổ chức họp nhóm tại Phuc Long để thảo luận dự án và phương án kết nối Chatbot từ AWS Bedrock vào backend. Kiểm thử và triển khai các thay đổi lên môi trường staging. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Thêm chức năng sửa hồ sơ người dùng (avatar, địa chỉ, thông tin liên hệ) - Kiểm thử frontend và API chỉnh sửa hồ sơ - Viết unit test cho endpoint cập nhật 10/11/2025 10/11/2025 3 - Thêm chức năng tạo/huỷ đơn hàng ở phía người dùng - Triển khai logic validate đơn hàng và kiểm tra edge cases - Viết integration test cho order APIs 10/12/2025 10/12/2025 4 - Họp nhóm tại Phuc Long: thảo luận tích hợp Chatbot (AWS Bedrock) với backend - Phác thảo API, flow xác thực và bảo mật cho Chatbot - Ghi nhận nhiệm vụ và timeline 10/13/2025 10/13/2025 5 - Tích hợp thử nghiệm Chatbot với backend (mock/stub) - Kiểm thử end-to-end luồng chat tới backend - Chuẩn bị tài liệu hướng dẫn tích hợp cho nhóm 10/14/2025 10/14/2025 Kết quả đạt được tuần 10: Thêm chức năng CRUD phía người dùng thành công\nTriển khai chức năng sửa hồ sơ người dùng (cập nhật avatar, địa chỉ, thông tin liên hệ) Thêm/huỷ đơn hàng từ giao diện người dùng và đảm bảo các ràng buộc nghiệp vụ Viết unit và integration test để đảm bảo chất lượng API Họp nhóm tại Phuc Long và lên kế hoạch tích hợp Chatbot (AWS Bedrock)\nThảo luận kiến trúc tích hợp Chatbot với backend, xác định điểm tích hợp và cơ chế xác thực Phác thảo luồng dữ liệu và API cần thiết cho tương tác Chatbot Ghi nhận nhiệm vụ và timeline cho việc tích hợp Kiểm thử tích hợp cơ bản và tài liệu hoá\nThực hiện thử nghiệm mock Chatbot kết nối tới backend và kiểm tra luồng end-to-end Chuẩn bị hướng dẫn tích hợp và ví dụ code mẫu cho nhóm Cải thiện trải nghiệm người dùng và khả năng triển khai\nNâng cao khả năng quản lý đơn hàng trực tiếp từ giao diện người dùng Tạo nền tảng tích hợp Chatbot để hỗ trợ mua sắm và tự động hoá tương tác khách hàng "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/1-worklog/1.11-week11/",
	"title": "Worklog Tuần 11",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu Tuần 11: Thêm chức năng giao dịch bằng thẻ tín dụng vào dự án để người dùng có thể thanh toán an toàn. Tham dự AWS Cloud Mastery Series (Bitexco Financial Tower) và áp dụng kiến thức về DevOps/CI-CD và giám sát vào dự án. Hoàn thành tích hợp, kiểm thử và triển khai luồng thanh toán, đồng thời viết tài liệu triển khai. Công việc cần triển khai trong tuần này: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tham dự AWS Cloud Mastery Series tại Bitexco Financial Tower (cả ngày) - Các phiên bao gồm: DevOps mindset, CI/CD (CodeCommit/CodeBuild/CodeDeploy/CodePipeline), IaC (CloudFormation/CDK), container (ECR/ECS/EKS), giám sát (CloudWatch/X-Ray) và best practices. 11/17/2025 11/17/2025 3 - Thiết kế và tích hợp luồng thanh toán bằng thẻ tín dụng (chọn nhà cung cấp/gateway/tokenization) - Triển khai endpoint server-side xử lý thanh toán và lưu trữ token - Đảm bảo không lưu trữ dữ liệu nhạy cảm dưới dạng text thuần 11/18/2025 11/18/2025 4 - Triển khai giao diện thanh toán phía client và kết nối tới API tokenization backend - Thêm xác thực phía server, logging và xử lý retry/lỗi - Thêm giám sát cho tỷ lệ thành công/thất bại thanh toán 11/19/2025 11/19/2025 5 - Kiểm thử end-to-end luồng thanh toán (thành công, từ chối, lỗi mạng) - Chạy kiểm tra bảo mật và đảm bảo các cân nhắc tuân thủ (tokenization, TLS) - Sửa lỗi phát hiện trong quá trình test 11/20/2025 11/20/2025 6 - Triển khai tính năng thanh toán lên môi trường staging - Demo cho đội và thu phản hồi - Viết tài liệu triển khai, runbook và cảnh báo giám sát cho production 11/21/2025 11/21/2025 Thành tựu Tuần 11: Đã tham dự AWS Cloud Mastery Series (Bitexco Financial Tower) vào 11/17/2025\nTham gia các phiên về DevOps mindset, pipeline CI/CD (CodeCommit, CodeBuild, CodeDeploy, CodePipeline), IaC (CloudFormation, CDK), dịch vụ container (ECR/ECS/EKS) và giám sát (CloudWatch, X-Ray). Có thêm các ý tưởng thực tiễn để cải thiện CI/CD và chiến lược giám sát của dự án. Đã triển khai chức năng thanh toán bằng thẻ tín dụng an toàn\nThiết kế và tích hợp luồng thanh toán sử dụng tokenization (không lưu trữ thẻ thô) Triển khai endpoint backend, tích hợp phía client và xác thực phía server Thêm logging, retry và giám sát cho tỷ lệ thành công/thất bại thanh toán Đã kiểm tra luồng thanh toán bằng kiểm thử end-to-end và rà soát bảo mật\nKiểm thử kịch bản thành công, từ chối, và lỗi mạng Áp dụng TLS, tokenization và các best practices bảo mật cơ bản Đã triển khai tính năng lên staging và viết tài liệu tích hợp\nChuẩn bị runbook, cảnh báo giám sát và hướng dẫn tích hợp cho đội Demo tính năng cho đội và thu phản hồi để chuẩn bị rollout production "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/1-worklog/1.12-week12/",
	"title": "Worklog Tuần 12",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu Tuần 12: Rà soát toàn bộ dự án và sửa các lỗi trước khi trình bày với người hướng dẫn. Triển khai backend, cơ sở dữ liệu và frontend lên AWS (staging và production nếu phù hợp) với các pipeline CI/CD tái sử dụng được. Chuẩn bị demo, runbook và giám sát để người hướng dẫn có thể xem hệ thống ổn định và có khả năng quan sát. Các công việc cần triển khai trong tuần này: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Rà soát mã nguồn và phân loại lỗi: chạy phân tích tĩnh, ưu tiên lỗi critical/major, lên kế hoạch sửa lỗi 11/24/2025 11/24/2025 2 - Sửa các lỗi backend quan trọng: chạy unit \u0026amp; integration tests, tối ưu truy vấn cơ sở dữ liệu, xử lý các đường lỗi và trường hợp biên 11/25/2025 11/25/2025 3 - Chuẩn bị artifact để deploy: containerize dịch vụ, build artifact, kiểm tra template hạ tầng (CloudFormation/CDK), và cấu hình pipeline CI cho deploy tới staging 11/26/2025 11/26/2025 4 - Triển khai backend \u0026amp; cơ sở dữ liệu lên AWS staging (hoặc production nếu sẵn sàng): cấu hình Secrets Manager/SSM, load balancer/ALB, autoscaling, backup; xác thực kết nối và migration 11/27/2025 11/27/2025 5 - Triển khai frontend (S3 + CloudFront hoặc hosting tương đương), chạy end-to-end smoke tests, kiểm tra hiệu năng và tải, chuẩn bị kịch bản demo và diễn tập cho đội 11/28/2025 11/28/2025 Kết quả đạt được Tuần 12: Hoàn thành rà soát mã nguồn và sửa các lỗi critical/major nhằm chuẩn bị cho buổi trình bày.\nBackend và cơ sở dữ liệu đã được triển khai lên AWS staging (và production nếu đã được phê duyệt)\nPipeline CI/CD đã được kiểm chứng cho build và deploy tự động tới môi trường staging Các migration cơ sở dữ liệu đã được áp dụng và backup được cấu hình Frontend đã được triển khai và cấu hình phía CDN (S3 + CloudFront) cùng TLS và routing\nGiám sát và khả năng quan sát được thiết lập\nLogs được tập trung, dashboards cơ bản và các cảnh báo cho lỗi quan trọng đã được cấu hình Đã thực hiện smoke tests end-to-end và diễn tập demo cho người hướng dẫn\nChuẩn bị kịch bản demo, runbook và các bước rollback Dự án sẵn sàng để trình bày với tài liệu triển khai và kết quả kiểm thử đi kèm.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại đây sẽ là phần liệt kê, giới thiệu các blogs mà các bạn đã dịch. Ví dụ:\nBlog 1 - Các mô hình OpenAI open-weight hiện đã có trên AWS Vào ngày 5 tháng 8 năm 2025, AWS đã công bố hai mô hình open-weight mới nhất của OpenAI — gpt-oss-120b và gpt-oss-20b — hiện đã có thể truy cập thông qua Amazon Bedrock và Amazon SageMaker JumpStart. Đây là một cột mốc quan trọng, vì đây là lần đầu tiên OpenAI cung cấp quyền truy cập công khai vào trọng số mô hình kể từ GPT-2, mở ra nhiều cơ hội tùy chỉnh và linh hoạt hơn.\nBlog 2 - OpenSecrets sử dụng AWS để chuyển đổi minh bạch chính trị thông qua nâng cao đối sánh dữ liệu OpenSecrets là một tổ chức phi lợi nhuận độc lập, phi đảng phái với sứ mệnh trở thành nguồn thông tin đáng tin cậy về dòng tiền trong chính trị Mỹ. Tổ chức này thực hiện sứ mệnh bằng cách cung cấp dữ liệu, phân tích và công cụ toàn diện, đáng tin cậy cho các nhà hoạch định chính sách, nhà báo và công dân. Tầm nhìn của họ là người dân Mỹ sẽ sử dụng dữ liệu về tài chính chính trị để xây dựng một nền dân chủ sôi động, đại diện và phản hồi tốt hơn.\nBlog 3 - Phân tích vai trò dẫn dắt của AWS trong các báo cáo Gartner Magic Quadrant 2025 Khi tôi phân tích các bài viết gần đây của AWS nêu chi tiết việc họ được ghi nhận trong nhiều báo cáo Gartner Magic Quadrant, tôi tự hỏi điều gì thực sự cấu thành nên vị thế dẫn đầu về đám mây trong bối cảnh công nghệ thay đổi nhanh chóng ngày nay. Theo sát hành trình của AWS trong thập kỷ qua, tôi tin rằng hiệu suất ổn định của họ qua các đợt đánh giá này cho thấy nhiều hơn là vị thế thống trị thị trường—nó thể hiện sự thấu hiểu sâu sắc nhu cầu của doanh nghiệp trên nhiều lĩnh vực. Theo đánh giá của tôi, đạt vị trí “Leader” ở chỉ một Magic Quadrant đã là đáng chú ý, nhưng duy trì vị trí này trên năm hạng mục khác nhau đồng thời đứng cao nhất về “Ability to Execute” (Năng lực thực thi) đối với Strategic Cloud Platform Services trong suốt 15 năm liên tiếp là điều, theo tôi, chưa từng có tiền lệ trong ngành điện toán đám mây. Sự xuất sắc bền bỉ này cho thấy một văn hóa ăn sâu về lấy khách hàng làm trung tâm và đổi mới lan tỏa khắp tổ chức của họ.\nBlog 4 - AWS Amplify JavaScript Library Công Bố Bundle Nhẹ Hơn và Thời Gian Load Nhanh Hơn Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 5 - Cộng Tác Multi-Agent với Strands Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 6 - Từ Linh Hoạt Đến Khung: Thực Thi Thứ Tự Công Cụ Trong MCP Servers The Model Context Protocol (MCP) được tạo ra nhằm mang lại tính nhất quán trong cách các ứng dụng tương tác với các mô hình AI sinh. Thay vì phải chắp vá từng tích hợp riêng lẻ cho mỗi mô hình hoặc môi trường lưu trữ, MCP cung cấp một lớp giao tiếp chuẩn hóa.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.4-s3-onprem/5.4.3-test-endpoint/",
	"title": "Kiểm tra Interface Endpoint",
	"tags": [],
	"description": "",
	"content": "Lấy regional DNS name (tên DNS khu vực) của S3 interface endpoint Trong Amazon VPC menu, chọn Endpoints.\nClick tên của endpoint chúng ta mới tạo ở mục 4.2: s3-interface-endpoint. Click details và lưu lại regional DNS name của endpoint (cái đầu tiên) vào text-editor của bạn để dùng ở các bước sau.\nKết nối đến EC2 instance ở trong \u0026ldquo;VPC On-prem\u0026rdquo; (giả lập môi trường truyền thống) Đi đến Session manager bằng cách gõ \u0026ldquo;session manager\u0026rdquo; vào ô tìm kiếm\nClick Start Session, chọn EC2 instance có tên Test-Interface-Endpoint. EC2 instance này đang chạy trên \u0026ldquo;VPC On-prem\u0026rdquo; và sẽ được sử dụng để kiểm tra kết nối đến Amazon S3 thông qua Interface endpoint. Session Manager sẽ mở 1 browser tab mới với shell prompt: sh-4.2 $\nĐi đến ssm-user\u0026rsquo;s home directory với lệnh \u0026ldquo;cd ~\u0026rdquo;\nTạo 1 file tên testfile2.xyz\nfallocate -l 1G testfile2.xyz Copy file vào S3 bucket mình tạo ở section 4.2 aws s3 cp --endpoint-url https://bucket.\u0026lt;Regional-DNS-Name\u0026gt; testfile2.xyz s3://\u0026lt;your-bucket-name\u0026gt; Câu lệnh này yêu cầu thông số \u0026ndash;endpoint-url, bởi vì bạn cần sử dụng DNS name chỉ định cho endpoint để truy cập vào S3 thông qua Interface endpoint. Không lấy \u0026rsquo; * \u0026rsquo; khi copy/paste tên DNS khu vực. Cung cấp tên S3 bucket của bạn Bây giờ tệp đã được thêm vào bộ chứa S3 của bạn. Hãy kiểm tra bộ chứa S3 của bạn trong bước tiếp theo.\nKiểm tra Object trong S3 bucket Đi đến S3 console Click Buckets Click tên bucket của bạn và bạn sẽ thấy testfile2.xyz đã được thêm vào s3 bucket của bạn "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.3-s3-vpc/",
	"title": "Truy cập S3 từ VPC",
	"tags": [],
	"description": "",
	"content": "Sử dụng Gateway endpoint Trong phần này, bạn sẽ tạo một Gateway endpoint để truy cập Amazon S3 từ một EC2 instance. Gateway endpoint sẽ cho phép tải một object lên S3 bucket mà không cần sử dụng Internet Công cộng. Để tạo endpoint, bạn phải chỉ định VPC mà bạn muốn tạo endpoint và dịch vụ (trong trường hợp này là S3) mà bạn muốn thiết lập kết nối.\nNội dung Tạo gateway endpoint Test gateway endpoint "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/4-eventparticipated/",
	"title": "Các events đã tham gia",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTrong phần này, các bạn cần liệt kê và mô tả chi tiết các sự kiện (event) mà mình đã tham gia trong suốt quá trình thực tập hoặc làm việc.\nMỗi sự kiện nên được trình bày theo định dạng Event 1, Event 2, Event 3…, kèm theo các thông tin:\nTên sự kiện Thời gian tổ chức Địa điểm (nếu có) Vai trò của bạn trong sự kiện (người tham dự, hỗ trợ tổ chức, diễn giả, v.v.) Mô tả ngắn gọn nội dung và hoạt động chính trong sự kiện Kết quả hoặc giá trị đạt được (bài học, kỹ năng mới, đóng góp cho nhóm/dự án) Việc liệt kê này giúp thể hiện rõ sự tham gia thực tế của bạn, cũng như các kỹ năng mềm và kinh nghiệm bạn đã tích lũy qua từng sự kiện. Trong quá trình thực tập, em đã tham gia 2 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEvent 1 Tên sự kiện: Vietnam Cloud Day 2025 : Ho Chi Minh City Connect Edition for Builders\nThời gian: 09:00 ngày 13/08/2025\nĐịa điểm: Tầng 36, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nMô tả: Giải thích ngắn gọn về Generative AI, Data Analytics, Migration \u0026amp; Modernization, cũng như bảo mật để làm cho hệ thống có khả năng mở rộng, an toàn và đáng tin cậy.\nMô tả:\nEvent 2 Tên sự kiện: GenAI-powered App-DB Modernization workshop\nThời gian: 09:00 ngày 13/08/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.4-s3-onprem/5.4.4-dns-simulation/",
	"title": "Mô phỏng On-premises DNS ",
	"tags": [],
	"description": "",
	"content": "AWS PrivateLink endpoint có một địa chỉ IP cố định trong từng AZ nơi chúng được triển khai, trong suốt thời gian tồn tại của endpoint (cho đến khi endpoint bị xóa). Các địa chỉ IP này được gắn vào Elastic network interface (ENI). AWS khuyến nghị sử dụng DNS để resolve địa chỉ IP cho endpoint để các ứng dụng downstream sử dụng địa chỉ IP mới nhất khi ENIs được thêm vào AZ mới hoặc bị xóa theo thời gian.\nTrong phần này, bạn sẽ tạo một quy tắc chuyển tiếp (forwarding rule) để gửi các yêu cầu resolve DNS từ môi trường truyền thống (mô phỏng) đến Private Hosted Zone trên Route 53. Phần này tận dụng cơ sở hạ tầng do CloudFormation triển khai trong phần Chuẩn bị môi trường.\nTạo DNS Alias Records cho Interface endpoint Click link để đi đến Route 53 management console (Hosted Zones section). Mẫu CloudFormation mà bạn triển khai trong phần Chuẩn bị môi trường đã tạo Private Hosted Zone này. Nhấp vào tên của Private Hosted Zone, s3.us-east-1.amazonaws.com: Tạo 1 record mới trong Private Hosted Zone: Giữ nguyên Record name và record type Alias Button: click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Add another record, và add 1 cái record thứ 2 sử dụng những thông số sau: Record name: *. Record type: giữ giá trị default (type A) Alias Button: Click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Create records Record mới xuất hiện trên giao diện Route 53.\nTạo một Resolver Forwarding Rule Route 53 Resolver Forwarding Rules cho phép bạn chuyển tiếp các DNS queries từ VPC của bạn đến các nguồn khác để resolve name. Bên ngoài môi trường workshop, bạn có thể sử dụng tính năng này để chuyển tiếp các DNS queries từ VPC của bạn đến các máy chủ DNS chạy trên on-premises. Trong phần này, bạn sẽ mô phỏng một on-premises conditional forwarder bằng cách tạo một forwarding rule để chuyển tiếp các DNS queries for Amazon S3 đến một Private Hosted Zone chạy trong \u0026ldquo;VPC Cloud\u0026rdquo; để resolve PrivateLink interface endpoint regional DNS name.\nTừ giao diện Route 53, chọn Inbound endpoints trên thanh bên trái\nTrong giao diện Inbound endpoint, Chọn ID của Inbound endpoint.\nSao chép 2 địa chỉ IP trong danh sách vào trình chỉnh sửa. Từ giao diện Route 53, chọn Resolver \u0026gt; Rules và chọn Create rule Trong giao diện Create rule Name: myS3Rule Rule type: Forward Domain name: s3.us-east-1.amazonaws.com VPC: VPC On-prem Outbound endpoint: VPCOnpremOutboundEndpoint Target IP Addresses: điền cả hai IP bạn đã lưu trữ trên trình soạn thảo (inbound endpoint addresses) và sau đó chọn Submit Bạn đã tạo thành công resolver forwarding rule.\nKiểm tra on-premises DNS mô phỏng. Kết nối đến Test-Interface-Endpoint EC2 instance với Session Manager Kiểm tra DNS resolution. Lệnh dig sẽ trả về địa chỉ IP được gán cho VPC endpoint interface đang chạy trên VPC (địa chỉ IP của bạn sẽ khác): dig +short s3.us-east-1.amazonaws.com Các địa chỉ IP được trả về là các địa chỉ IP VPC enpoint, KHÔNG phải là các địa chỉ IP Resolver mà bạn đã dán từ trình chỉnh sửa văn bản của mình. Các địa chỉ IP của Resolver endpoint và VPC endpoin trông giống nhau vì chúng đều từ khối CIDR VPC Cloud.\nTruy cập vào menu VPC (phần Endpoints), chọn S3 interface endpoint. Nhấp vào tab Subnets và xác nhận rằng các địa chỉ IP được trả về bởi lệnh Dig khớp với VPC endpoint: Hãy quay lại shell của bạn và sử dụng AWS CLI để kiểm tra danh sách các bucket S3 của bạn: aws s3 ls --endpoint-url https://s3.us-east-1.amazonaws.com Kết thúc phiên làm việc của Session Manager của bạn: Trong phần này, bạn đã tạo một Interface Endpoint cho Amazon S3. Điểm cuối này có thể được truy cập từ on-premises thông qua Site-to-Site VPN hoặc AWS Direct Connect. Các điểm cuối Route 53 Resolver outbound giả lập chuyển tiếp các yêu cầu DNS từ on-premises đến một Private Hosted Zone đang chạy trên đám mây. Các điểm cuối Route 53 inbound nhận yêu cầu giải quyết và trả về một phản hồi chứa địa chỉ IP của Interface Endpoint VPC. Sử dụng DNS để giải quyết các địa chỉ IP của điểm cuối cung cấp tính sẵn sàng cao trong trường hợp một Availability Zone gặp sự cố.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.4-s3-onprem/",
	"title": "Truy cập S3 từ môi trường truyền thống",
	"tags": [],
	"description": "",
	"content": "Tổng quan Trong phần này, bạn sẽ tạo một Interface Endpoint để truy cập Amazon S3 từ môi trường truyền thống mô phỏng. Interface Endpoint sẽ cho phép bạn định tuyến đến Amazon S3 qua kết nối VPN từ môi trường truyền thống mô phỏng của bạn.\nTại sao nên sử dụng Interface Endpoint:\nCác Gateway endpoints chỉ hoạt động với các tài nguyên đang chạy trong VPC nơi chúng được tạo. Interface Endpoint hoạt động với tài nguyên chạy trong VPC và cả tài nguyên chạy trong môi trường truyền thống. Khả năng kết nối từ môi trường truyền thống của bạn với aws cloud có thể được cung cấp bởi AWS Site-to-Site VPN hoặc AWS Direct Connect. Interface Endpoint cho phép bạn kết nối với các dịch vụ do AWS PrivateLink cung cấp. Các dịch vụ này bao gồm một số dịch vụ AWS, dịch vụ do các đối tác và khách hàng AWS lưu trữ trong VPC của riêng họ (gọi tắt là Dịch vụ PrivateLink endpoints) và các dịch vụ Đối tác AWS Marketplace. Đối với workshop này, chúng ta sẽ tập trung vào việc kết nối với Amazon S3. "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.5-policy/",
	"title": "VPC Endpoint Policies",
	"tags": [],
	"description": "",
	"content": "Khi bạn tạo một Interface Endpoint hoặc cổng, bạn có thể đính kèm một chính sách điểm cuối để kiểm soát quyền truy cập vào dịch vụ mà bạn đang kết nối. Chính sách VPC Endpoint là chính sách tài nguyên IAM mà bạn đính kèm vào điểm cuối. Nếu bạn không đính kèm chính sách khi tạo điểm cuối, thì AWS sẽ đính kèm chính sách mặc định cho bạn để cho phép toàn quyền truy cập vào dịch vụ thông qua điểm cuối.\nBạn có thể tạo chính sách chỉ hạn chế quyền truy cập vào các S3 bucket cụ thể. Điều này hữu ích nếu bạn chỉ muốn một số Bộ chứa S3 nhất định có thể truy cập được thông qua điểm cuối.\nTrong phần này, bạn sẽ tạo chính sách VPC Endpoint hạn chế quyền truy cập vào S3 bucket được chỉ định trong chính sách VPC Endpoint.\nKết nối tới EC2 và xác minh kết nối tới S3. Bắt đầu một phiên AWS Session Manager mới trên máy chủ có tên là Test-Gateway-Endpoint. Từ phiên này, xác minh rằng bạn có thể liệt kê nội dung của bucket mà bạn đã tạo trong Phần 1: Truy cập S3 từ VPC. aws s3 ls s3://\u0026lt;your-bucket-name\u0026gt; Nội dung của bucket bao gồm hai tệp có dung lượng 1GB đã được tải lên trước đó.\nTạo một bucket S3 mới; tuân thủ mẫu đặt tên mà bạn đã sử dụng trong Phần 1, nhưng thêm \u0026lsquo;-2\u0026rsquo; vào tên. Để các trường khác là mặc định và nhấp vào Create. Tạo bucket thành công. Policy mặc định cho phép truy cập vào tất cả các S3 Buckets thông qua VPC endpoint.\nTrong giao diện Edit Policy, sao chép và dán theo policy sau, thay thế yourbucketname-2 với tên bucket thứ hai của bạn. Policy này sẽ cho phép truy cập đến bucket mới thông qua VPC endpoint, nhưng không cho phép truy cập đến các bucket còn lại. Chọn Save để kích hoạt policy. { \u0026#34;Id\u0026#34;: \u0026#34;Policy1631305502445\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Stmt1631305501021\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::yourbucketname-2\u0026#34;, \u0026#34;arn:aws:s3:::yourbucketname-2/*\u0026#34; ], \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34; } ] } Cấu hình policy thành công.\nTừ session của bạn trên Test-Gateway-Endpoint instance, kiểm tra truy cập đến S3 bucket bạn tạo ở bước đầu aws s3 ls s3://\u0026lt;yourbucketname\u0026gt; Câu lệnh trả về lỗi bởi vì truy cập vào S3 bucket không có quyền trong VPC endpoint policy.\nTrở lại home directory của bạn trên EC2 instance cd~ Tạo file fallocate -l 1G test-bucket2.xyz Sao chép file lên bucket thứ 2 aws s3 cp test-bucket2.xyz s3://\u0026lt;your-2nd-bucket-name\u0026gt; Thao tác này được cho phép bởi VPC endpoint policy.\nSau đó chúng ta kiểm tra truy cập vào S3 bucket đầu tiên\naws s3 cp test-bucket2.xyz s3://\u0026lt;your-1st-bucket-name\u0026gt;\nCâu lệnh xảy ra lỗi bởi vì bucket không có quyền truy cập bởi VPC endpoint policy.\nTrong phần này, bạn đã tạo chính sách VPC Endpoint cho Amazon S3 và sử dụng AWS CLI để kiểm tra chính sách. Các hoạt động AWS CLI liên quan đến bucket S3 ban đầu của bạn thất bại vì bạn áp dụng một chính sách chỉ cho phép truy cập đến bucket thứ hai mà bạn đã tạo. Các hoạt động AWS CLI nhắm vào bucket thứ hai của bạn thành công vì chính sách cho phép chúng. Những chính sách này có thể hữu ích trong các tình huống khi bạn cần kiểm soát quyền truy cập vào tài nguyên thông qua VPC Endpoint.\n"
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nĐảm bảo truy cập Hybrid an toàn đến S3 bằng cách sử dụng VPC endpoint Tổng quan AWS PrivateLink cung cấp kết nối riêng tư đến các dịch vụ aws từ VPCs hoặc trung tâm dữ liệu (on-premise) mà không làm lộ lưu lượng truy cập ra ngoài public internet.\nTrong bài lab này, chúng ta sẽ học cách tạo, cấu hình, và kiểm tra VPC endpoints để cho phép workload của bạn tiếp cận các dịch vụ AWS mà không cần đi qua Internet công cộng.\nChúng ta sẽ tạo hai loại endpoints để truy cập đến Amazon S3: gateway vpc endpoint và interface vpc endpoint. Hai loại vpc endpoints này mang đến nhiều lợi ích tùy thuộc vào việc bạn truy cập đến S3 từ môi trường cloud hay từ trung tâm dữ liệu (on-premise).\nGateway - Tạo gateway endpoint để gửi lưu lượng đến Amazon S3 hoặc DynamoDB using private IP addresses. Bạn điều hướng lưu lượng từ VPC của bạn đến gateway endpoint bằng các bảng định tuyến (route tables) Interface - Tạo interface endpoint để gửi lưu lượng đến các dịch vụ điểm cuối (endpoints) sử dụng Network Load Balancer để phân phối lưu lượng. Lưu lượng dành cho dịch vụ điểm cuối được resolved bằng DNS. Nội dung Tổng quan về workshop Chuẩn bị Truy cập đến S3 từ VPC Truy cập đến S3 từ TTDL On-premises VPC Endpoint Policies (làm thêm) Dọn dẹp tài nguyên "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/5-workshop/5.6-cleanup/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Dọn dẹp tài nguyên Xin chúc mừng bạn đã hoàn thành xong lab này! Trong lab này, bạn đã học về các mô hình kiến trúc để truy cập Amazon S3 mà không sử dụng Public Internet.\nBằng cách tạo Gateway endpoint, bạn đã cho phép giao tiếp trực tiếp giữa các tài nguyên EC2 và Amazon S3, mà không đi qua Internet Gateway. Bằng cách tạo Interface endpoint, bạn đã mở rộng kết nối S3 đến các tài nguyên chạy trên trung tâm dữ liệu trên chỗ của bạn thông qua AWS Site-to-Site VPN hoặc Direct Connect. Dọn dẹp Điều hướng đến Hosted Zones trên phía trái của bảng điều khiển Route 53. Nhấp vào tên của s3.us-east-1.amazonaws.com zone. Nhấp vào Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo;. Disassociate Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. 4.Mở console của CloudFormation và xóa hai stack CloudFormation mà bạn đã tạo cho bài thực hành này:\nPLOnpremSetup PLCloudSetup Xóa các S3 bucket Mở bảng điều khiển S3 Chọn bucket chúng ta đã tạo cho lab, nhấp chuột và xác nhận là empty. Nhấp Delete và xác nhận delete. "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/6-self-evaluation/",
	"title": "Tự Đánh Giá",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Thông tin bên dưới chỉ mang tính tham khảo. Vui lòng không sao chép nguyên văn vào báo cáo của bạn, bao gồm cả cảnh báo này.\nTrong thời gian thực tập tại [Amazon Web Services Vietnam Co., Ltd] từ [8/9/2025] đến [12/9/2025], tôi đã có cơ hội học hỏi, thực hành và áp dụng kiến thức tại trường vào môi trường làm việc thực tế.\nTôi tham gia [First Cloud Journey], thông qua đó cải thiện các kỹ năng như [lập trình, làm việc nhóm, điện toán đám mây, giải quyết vấn đề, tư duy phản biện, v.v.].\nVề phương diện thái độ và tác phong làm việc, tôi luôn cố gắng hoàn thành nhiệm vụ, tuân thủ quy định công ty và chủ động phối hợp với đồng nghiệp để nâng cao hiệu suất công việc.\nĐể phản ánh một cách khách quan trong suốt thời gian thực tập, tôi tự đánh giá theo các tiêu chí sau:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức \u0026amp; kỹ năng chuyên môn Hiểu biết về chuyên ngành, áp dụng kiến thức vào thực tế, thành thạo công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Khả năng tiếp thu kiến thức mới và học nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm kiếm nhiệm vụ, khởi xướng công việc mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Ý thức trách nhiệm Hoàn thành công việc đúng hạn và đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ thời gian, nội quy và quy trình làm việc ☐ ☐ ✅ 6 Tư duy cầu tiến Sẵn sàng nhận phản hồi và cải thiện bản thân ✅ ☐ ☐ 7 Giao tiếp Trình bày ý tưởng và báo cáo công việc rõ ràng ☐ ☐ ✅ 8 Làm việc nhóm Hợp tác hiệu quả với đồng nghiệp và tham gia tích cực trong nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác và môi trường làm việc ✅ ☐ ☐ 10 Kỹ năng giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp và thể hiện tính sáng tạo ✅ ☐ ☐ 11 Đóng góp cho dự án/nhóm Hiệu quả công việc, ý tưởng đổi mới, được công nhận bởi nhóm ✅ ☐ ☐ 12 Tổng quan Đánh giá chung về toàn bộ thời gian thực tập ☐ ✅ ☐ Cần cải thiện Kỷ luật: Cải thiện tính đúng giờ và tính nhất quán với lịch làm việc.\nHành động: đặt giờ bắt đầu/kết thúc cố định, sử dụng công cụ quản lý nhiệm vụ (ví dụ: Notion/Trello) và ghi lại thời gian bắt đầu công việc trong 2 tuần. Tiêu chí thành công: đạt 95% tỉ lệ bắt đầu đúng giờ trong vòng 4 tuần. Khả năng học hỏi: Tăng tốc độ tiếp thu và áp dụng kiến thức để từ mức \u0026ldquo;Khá\u0026rdquo; lên \u0026ldquo;Tốt\u0026rdquo;.\nHành động: sau mỗi buổi học viết tóm tắt 10–15 phút và danh sách 3 việc có thể áp dụng; hoàn thành 1 mini-project áp dụng kiến thức mới mỗi 2 tuần. Tiêu chí thành công: tạo ra 4 bản tóm tắt/dự án áp dụng trong 8 tuần. Giao tiếp: Cải thiện tính rõ ràng trong báo cáo trạng thái và giải thích kỹ thuật.\nHành động: sử dụng mẫu báo cáo ngắn hàng ngày (Đã làm / Khó khăn / Tiếp theo) và luyện giải thích 1 nhiệm vụ kỹ thuật bằng văn bản cho đồng nghiệp mỗi tuần. Tiêu chí thành công: giảm 50% số câu hỏi cần làm rõ từ người đánh giá trong 6 tuần. Giải quyết vấn đề: Củng cố tư duy phân tích và kỹ năng gỡ lỗi.\nHành động: áp dụng checklist phân tích nguyên nhân gốc rễ cho mỗi lỗi (tái hiện → cô lập → giả thuyết → kiểm thử → xác nhận); lưu log ngắn các lỗi và cách khắc phục. Tiêu chí thành công: giảm 25% thời gian sửa lỗi critical trong 1 tháng. Phát triển nghề nghiệp tổng quát: Biến phản hồi thành kết quả cụ thể.\nHành động: lên lịch họp phản hồi 2 tuần/lần với mentor, đặt 2 mục tiêu đo lường cho mỗi chu kỳ và ghi lại tiến triển. Tiêu chí thành công: trình bày được tiến trình trên ít nhất 2 mục tiêu trong chu kỳ đánh giá tiếp theo. "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/7-feedback/",
	"title": "Chia sẻ &amp; Phản hồi",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Thông tin dưới đây chỉ mang tính tham khảo. Vui lòng không sao chép nguyên văn vào báo cáo của bạn, bao gồm cả cảnh báo này.\nChia sẻ và Phản hồi về Quá trình Thực tập Tổng quan — Ấn tượng chung 1. Môi trường làm việc\nNhóm thân thiện và hỗ trợ; đồng nghiệp và mentor sẵn sàng dành thời gian hướng dẫn. Không gian làm việc sạch sẽ, thuận lợi cho sự tập trung. Có thể cân nhắc tổ chức các hoạt động gắn kết đội định kỳ để củng cố mối quan hệ nội bộ. 2. Hướng dẫn \u0026amp; hỗ trợ hành chính\nMentor đưa ra hướng dẫn rõ ràng, mang tính thực tiễn và khuyến khích tự giải quyết vấn đề. Bộ phận hành chính phản hồi nhanh, hỗ trợ đầy đủ thủ tục và tài liệu onboarding. 3. Tính liên quan với học thuật\nCác nhiệm vụ được giao phù hợp với nền tảng học thuật đồng thời giới thiệu các công cụ và quy trình thực tế, giúp kết nối kiến thức lý thuyết với thực hành. 4. Cơ hội học tập \u0026amp; phát triển\nChương trình giúp phát triển kỹ năng kỹ thuật, công cụ quản lý dự án, làm việc nhóm và kỹ năng giao tiếp chuyên nghiệp. Những chia sẻ từ mentor cung cấp góc nhìn thực tế cho lộ trình nghề nghiệp. 5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty khuyến khích tôn trọng và hợp tác; các thành viên sẵn sàng hỗ trợ nhau khi công việc gấp rút và tạo điều kiện để thực tập sinh tham gia công việc có ý nghĩa. 6. Chính sách \u0026amp; phúc lợi\nChương trình cung cấp trợ cấp thực tập, lịch làm việc linh hoạt khi cần và truy cập các buổi đào tạo nội bộ — tất cả đều góp phần nâng cao trải nghiệm học tập. Câu hỏi phản hồi ngắn Điều gì làm bạn hài lòng nhất trong kỳ thực tập? Công ty nên cải thiện điều gì cho thực tập sinh tương lai? Bạn có sẵn sàng giới thiệu người quen thực tập tại đây không? Vì sao hoặc vì sao không? Gợi ý \u0026amp; Kỳ vọng Bạn có gợi ý gì để cải thiện cấu trúc chương trình hoặc quá trình onboarding không? Bạn có muốn tiếp tục tham gia chương trình hoặc gia nhập công ty sau khi kết thúc không? Các nhận xét hoặc chia sẻ thêm khác: "
},
{
	"uri": "http://localhost:1313/workshop-template/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/workshop-template/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]